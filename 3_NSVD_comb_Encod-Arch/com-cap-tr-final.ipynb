{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7617478,"sourceType":"datasetVersion","datasetId":4223935}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":112.313155,"end_time":"2024-01-17T08:49:50.020008","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-17T08:47:57.706853","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport json\nimport os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":6.254485,"end_time":"2024-01-17T08:48:08.569103","exception":false,"start_time":"2024-01-17T08:48:02.314618","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.317481Z","iopub.execute_input":"2024-02-13T13:28:15.318524Z","iopub.status.idle":"2024-02-13T13:28:15.323515Z","shell.execute_reply.started":"2024-02-13T13:28:15.318483Z","shell.execute_reply":"2024-02-13T13:28:15.322451Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"TOTAL_ITER = 5000\n#TOTAL_ITER = 200\n#VALID_EVE = 50\nVALID_EVE = 1000","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:28:15.325248Z","iopub.execute_input":"2024-02-13T13:28:15.325526Z","iopub.status.idle":"2024-02-13T13:28:15.335947Z","shell.execute_reply.started":"2024-02-13T13:28:15.325496Z","shell.execute_reply":"2024-02-13T13:28:15.335053Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def invertDict(_dict):\n    return {v: k for k, v in _dict.items()}","metadata":{"papermill":{"duration":0.015689,"end_time":"2024-01-17T08:48:08.593349","exception":false,"start_time":"2024-01-17T08:48:08.577660","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.337245Z","iopub.execute_input":"2024-02-13T13:28:15.337820Z","iopub.status.idle":"2024-02-13T13:28:15.347197Z","shell.execute_reply.started":"2024-02-13T13:28:15.337789Z","shell.execute_reply":"2024-02-13T13:28:15.346295Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"class ClevrDialogDataset(Dataset):\n    def __init__(self, dataPath, vocabPath, split, indStart=0, indEnd=-1):\n        super(ClevrDialogDataset, self).__init__()\n        self.data = h5py.File(dataPath, \"r\")\n        with open(vocabPath, \"r\") as f:\n            self.vocab = json.load(f)\n        self.vocab[\"idx_text_to_token\"] = invertDict(self.vocab[\"text_token_to_idx\"])\n        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n        self.lenVocabText = len(self.vocab[\"text_token_to_idx\"])\n        self.lenVocabProg = len(self.vocab[\"prog_token_to_idx\"])\n\n        self.split = split\n        self.indStart = indStart\n        self.indEnd = indEnd\n        self.maxSamples = indEnd - indStart\n        self.maxLenProg = 6\n\n    def __len__(self):\n        raise NotImplementedError\n\n    def __getitem__(self, index):\n        raise NotImplementedError","metadata":{"papermill":{"duration":0.018564,"end_time":"2024-01-17T08:48:08.620015","exception":false,"start_time":"2024-01-17T08:48:08.601451","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.349091Z","iopub.execute_input":"2024-02-13T13:28:15.349394Z","iopub.status.idle":"2024-02-13T13:28:15.358366Z","shell.execute_reply.started":"2024-02-13T13:28:15.349370Z","shell.execute_reply":"2024-02-13T13:28:15.357445Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class ClevrDialogCaptionDataset(ClevrDialogDataset):\n    def __init__(self, dataPath, vocabPath, split, name, indStart=0, indEnd=-1):\n        super(ClevrDialogCaptionDataset, self).__init__(dataPath, vocabPath, split, indStart=indStart, indEnd=indEnd)\n        self.captions = torch.LongTensor(np.asarray(self.data[\"captions\"], dtype=np.int64)[indStart: indEnd])\n        self.captionsPrgs = torch.LongTensor(np.asarray(self.data[\"captionProgs\"], dtype=np.int64)[indStart: indEnd])\n        self.name = name\n\n    def __len__(self):\n        return len(self.captions)\n\n    def __getitem__(self, idx):\n        assert idx < len(self)\n        caption = self.captions[idx][:16]\n        captionPrg = self.captionsPrgs[idx]\n        return caption, captionPrg","metadata":{"papermill":{"duration":0.017492,"end_time":"2024-01-17T08:48:08.645664","exception":false,"start_time":"2024-01-17T08:48:08.628172","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.359458Z","iopub.execute_input":"2024-02-13T13:28:15.359726Z","iopub.status.idle":"2024-02-13T13:28:15.374731Z","shell.execute_reply.started":"2024-02-13T13:28:15.359692Z","shell.execute_reply":"2024-02-13T13:28:15.373903Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import torch\nimport math\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"papermill":{"duration":0.014684,"end_time":"2024-01-17T08:48:08.668453","exception":false,"start_time":"2024-01-17T08:48:08.653769","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.375706Z","iopub.execute_input":"2024-02-13T13:28:15.375980Z","iopub.status.idle":"2024-02-13T13:28:15.388414Z","shell.execute_reply.started":"2024-02-13T13:28:15.375958Z","shell.execute_reply":"2024-02-13T13:28:15.387609Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"class FC(nn.Module):\n    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n        super(FC, self).__init__()\n        self.dropout_r = dropout_r\n        self.use_relu = use_relu\n\n        self.linear = nn.Linear(in_size, out_size)\n\n        if use_relu:\n            self.relu = nn.ReLU(inplace=True)\n\n        if dropout_r > 0:\n            self.dropout = nn.Dropout(dropout_r)\n\n    def forward(self, x):\n        x = self.linear(x)\n\n        if self.use_relu:\n            x = self.relu(x)\n\n        if self.dropout_r > 0:\n            x = self.dropout(x)\n\n        return x\n","metadata":{"papermill":{"duration":0.017189,"end_time":"2024-01-17T08:48:08.693872","exception":false,"start_time":"2024-01-17T08:48:08.676683","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.389456Z","iopub.execute_input":"2024-02-13T13:28:15.389739Z","iopub.status.idle":"2024-02-13T13:28:15.400217Z","shell.execute_reply.started":"2024-02-13T13:28:15.389717Z","shell.execute_reply":"2024-02-13T13:28:15.399360Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n        super(MLP, self).__init__()\n\n        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n        self.linear = nn.Linear(mid_size, out_size)\n\n    def forward(self, x):\n        return self.linear(self.fc(x))","metadata":{"papermill":{"duration":0.016097,"end_time":"2024-01-17T08:48:08.718259","exception":false,"start_time":"2024-01-17T08:48:08.702162","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.401296Z","iopub.execute_input":"2024-02-13T13:28:15.401545Z","iopub.status.idle":"2024-02-13T13:28:15.413035Z","shell.execute_reply.started":"2024-02-13T13:28:15.401524Z","shell.execute_reply":"2024-02-13T13:28:15.412376Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, size, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.eps = eps\n\n        self.a_2 = nn.Parameter(torch.ones(size))\n        self.b_2 = nn.Parameter(torch.zeros(size))\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n\n        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2","metadata":{"papermill":{"duration":0.016429,"end_time":"2024-01-17T08:48:08.742700","exception":false,"start_time":"2024-01-17T08:48:08.726271","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.418551Z","iopub.execute_input":"2024-02-13T13:28:15.418867Z","iopub.status.idle":"2024-02-13T13:28:15.426112Z","shell.execute_reply.started":"2024-02-13T13:28:15.418838Z","shell.execute_reply":"2024-02-13T13:28:15.425190Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class MHAtt(nn.Module):\n    def __init__(self, opts):\n        super(MHAtt, self).__init__()\n        self.opts = opts\n\n        self.linear_v = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_k = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_q = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_merge = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n\n        self.dropout = nn.Dropout(opts.dropout)\n\n    def forward(self, v, k, q, mask):\n        n_batches = q.size(0)\n\n        v = self.linear_v(v).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        k = self.linear_k(k).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        q = self.linear_q(q).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        atted = self.att(v, k, q, mask)\n        atted = atted.transpose(1, 2).contiguous().view(\n            n_batches,\n            -1,\n            self.opts.hiddenDim\n        )\n\n        atted = self.linear_merge(atted)\n\n        return atted\n\n    def att(self, value, key, query, mask):\n        d_k = query.size(-1)\n\n        scores = torch.matmul(\n            query, key.transpose(-2, -1)\n        ) / math.sqrt(d_k)\n\n        if mask is not None:\n            scores = scores.masked_fill(mask, -1e9)\n\n        att_map = F.softmax(scores, dim=-1)\n        att_map = self.dropout(att_map)\n\n        return torch.matmul(att_map, value)","metadata":{"papermill":{"duration":0.022395,"end_time":"2024-01-17T08:48:08.773097","exception":false,"start_time":"2024-01-17T08:48:08.750702","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.427839Z","iopub.execute_input":"2024-02-13T13:28:15.428668Z","iopub.status.idle":"2024-02-13T13:28:15.441304Z","shell.execute_reply.started":"2024-02-13T13:28:15.428637Z","shell.execute_reply":"2024-02-13T13:28:15.440421Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self, opts):\n        super(FFN, self).__init__()\n\n        self.mlp = MLP(\n            in_size=opts.hiddenDim,\n            mid_size=opts.FeedForwardSize,\n            out_size=opts.hiddenDim,\n            dropout_r=opts.dropout,\n            use_relu=True\n        )\n\n    def forward(self, x):\n        return self.mlp(x)\n","metadata":{"papermill":{"duration":0.0159,"end_time":"2024-01-17T08:48:08.797277","exception":false,"start_time":"2024-01-17T08:48:08.781377","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.442374Z","iopub.execute_input":"2024-02-13T13:28:15.442685Z","iopub.status.idle":"2024-02-13T13:28:15.455869Z","shell.execute_reply.started":"2024-02-13T13:28:15.442653Z","shell.execute_reply":"2024-02-13T13:28:15.455116Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class SA(nn.Module):\n    def __init__(self, opts):\n        super(SA, self).__init__()\n        self.mhatt = MHAtt(opts)\n        self.ffn = FFN(opts)\n\n        self.dropout1 = nn.Dropout(opts.dropout)\n        self.norm1 = LayerNorm(opts.hiddenDim)\n\n        self.dropout2 = nn.Dropout(opts.dropout)\n        self.norm2 = LayerNorm(opts.hiddenDim)\n\n    def forward(self, x, x_mask):\n        x = self.norm1(x + self.dropout1(\n            self.mhatt(x, x, x, x_mask)\n        ))\n\n        x = self.norm2(x + self.dropout2(\n            self.ffn(x)\n        ))\n\n        return x","metadata":{"papermill":{"duration":0.016871,"end_time":"2024-01-17T08:48:08.823651","exception":false,"start_time":"2024-01-17T08:48:08.806780","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.457721Z","iopub.execute_input":"2024-02-13T13:28:15.457977Z","iopub.status.idle":"2024-02-13T13:28:15.466539Z","shell.execute_reply.started":"2024-02-13T13:28:15.457955Z","shell.execute_reply":"2024-02-13T13:28:15.465781Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class AttFlat(nn.Module):\n    def __init__(self, opts):\n        super(AttFlat, self).__init__()\n        self.opts = opts\n\n        self.mlp = MLP(\n            in_size=opts.hiddenDim,\n            mid_size=opts.FlatMLPSize,\n            out_size=opts.FlatGlimpses,\n            dropout_r=opts.dropout,\n            use_relu=True\n        )\n        # FLAT_GLIMPSES = 1\n        self.linear_merge = nn.Linear(\n            opts.hiddenDim * opts.FlatGlimpses,\n            opts.FlatOutSize\n        )\n\n    def forward(self, x, x_mask):\n        att = self.mlp(x)\n        att = att.masked_fill(\n            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n            -1e9\n        )\n        att = F.softmax(att, dim=1)\n\n        att_list = []\n        for i in range(self.opts.FlatGlimpses):\n            att_list.append(\n                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n            )\n\n        x_atted = torch.cat(att_list, dim=1)\n        x_atted = self.linear_merge(x_atted)\n\n        return x_atted","metadata":{"papermill":{"duration":0.018218,"end_time":"2024-01-17T08:48:08.850658","exception":false,"start_time":"2024-01-17T08:48:08.832440","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.467650Z","iopub.execute_input":"2024-02-13T13:28:15.468180Z","iopub.status.idle":"2024-02-13T13:28:15.479936Z","shell.execute_reply.started":"2024-02-13T13:28:15.468132Z","shell.execute_reply":"2024-02-13T13:28:15.479188Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from itertools import chain # needed for preprocessing the output of the local decode function -> added by Sepi","metadata":{"papermill":{"duration":0.01509,"end_time":"2024-01-17T08:48:08.873723","exception":false,"start_time":"2024-01-17T08:48:08.858633","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.480891Z","iopub.execute_input":"2024-02-13T13:28:15.481121Z","iopub.status.idle":"2024-02-13T13:28:15.489841Z","shell.execute_reply.started":"2024-02-13T13:28:15.481100Z","shell.execute_reply":"2024-02-13T13:28:15.488902Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, opts, textVocabSize):\n        super(Encoder, self).__init__()\n        self.bidirectional = opts.bidirectional > 0\n\n        self.embedding = nn.Embedding(textVocabSize, opts.embedDim)\n        self.lstm = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=opts.hiddenDim,\n            num_layers=opts.numLayers,\n            bidirectional=self.bidirectional,\n            batch_first=True\n        )\n        if self.bidirectional:\n            opts.hiddenDim *= 2\n            opts.hiddenSizeHead *= 2\n            opts.FlatOutSize *= 2\n        self.attCurr = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n        self.attHist = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n        self.attFlat = AttFlat(opts)\n        self.fc_1 = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.fc_2 = nn.Linear(2 * opts.hiddenDim, opts.hiddenDim)\n\n\n    def forward(self, curr, hist=None):\n        if hist is None:\n            hist = torch.zeros_like(curr)\n        curr_mask = self.make_mask(curr.unsqueeze(2))\n        hist_Mask = self.make_mask(hist.unsqueeze(2))\n            \n            \n        curr = self.embedding(curr)\n        hist = self.embedding(hist)\n            # Get the batch size and sequence length\n        batch_size, sequence_length, _ = curr.size()\n\n    # Initialize LSTM hidden states\n        h0 = torch.zeros(self.lstm.num_layers * (2 if self.bidirectional else 1), batch_size, self.lstm.hidden_size)\n        c0 = torch.zeros(self.lstm.num_layers * (2 if self.bidirectional else 1), batch_size, self.lstm.hidden_size)\n\n        if torch.cuda.is_available():\n            h0 = h0.cuda()\n            c0 = c0.cuda()\n\n        combined_input = torch.cat([curr, hist], dim=1)\n            # Apply LSTM layer\n        combined_input,(_, _) = self.lstm(combined_input, (h0, c0))\n       \n        currO = combined_input.detach().clone()\n        curr, hist = torch.split(combined_input, [curr.size(1), hist.size(1)], dim=1)\n\n            \n        for attC, attH in zip(self.attCurr, self.attHist):\n            curr = attC(curr, curr_mask)\n            hist = attH(hist, hist_Mask)#***\n        curr = self.attFlat(curr, curr_mask)\n\n        if(not(hist == None)):\n            attWeights = torch.sum(torch.mul(hist, curr.unsqueeze(1)), -1)\n            attWeights = torch.softmax(attWeights, -1)\n            hist = torch.sum(torch.mul(hist, attWeights.unsqueeze(2)), 1)\n            encOut = self.fc_2(torch.cat([curr, hist], -1))\n        else:\n            encOut = self.fc_1(curr)\n\n        return encOut, currO\n\n    # Masking\n    def make_mask(self, feature):\n        return (torch.sum(\n            torch.abs(feature),\n            dim=-1\n        ) == 0).unsqueeze(1).unsqueeze(2)\n","metadata":{"papermill":{"duration":0.026628,"end_time":"2024-01-17T08:48:08.908463","exception":false,"start_time":"2024-01-17T08:48:08.881835","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.491220Z","iopub.execute_input":"2024-02-13T13:28:15.491452Z","iopub.status.idle":"2024-02-13T13:28:15.508420Z","shell.execute_reply.started":"2024-02-13T13:28:15.491432Z","shell.execute_reply":"2024-02-13T13:28:15.507497Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, opts, progVocabSize, maxLen, startID=1, endID=2):\n        super(Decoder, self).__init__()\n        self.numLayers = opts.numLayers\n        self.bidirectional = opts.bidirectional > 0\n        self.maxLen = maxLen\n        self.startID = startID\n        self.endID = endID\n\n        self.embedding = nn.Embedding(progVocabSize, opts.embedDim)\n        self.lstmProg = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=2*opts.hiddenDim if self.bidirectional else opts.hiddenDim,\n            num_layers=opts.numLayers,\n            batch_first=True,\n            # bidirectional=self.bidirectional,\n        )\n        hiddenDim = opts.hiddenDim\n        if self.bidirectional:\n            hiddenDim *= 2\n\n        self.fcAtt = nn.Linear(2*hiddenDim, hiddenDim)\n        self.fcOut = nn.Linear(hiddenDim, progVocabSize)\n\n    def initPrgHidden(self, encOut):\n        hidden = [encOut for _ in range(self.numLayers)]\n        hidden = torch.stack(hidden, 0).contiguous()\n        return hidden, hidden\n\n    def forwardStep(self, prog, progH, questO):\n        #**********************************************our error relates to this prog cause in our case it is not acting as tensor anymore.\n        batchSize = prog.size(0)\n        inputDim = questO.size(1)\n        prog = self.embedding(prog)\n        outProg, progH = self.lstmProg(prog, progH)\n\n        att = torch.bmm(outProg, questO.transpose(1, 2))\n        att = F.softmax(att.view(-1, inputDim), 1).view(batchSize, -1, inputDim)\n        context = torch.bmm(att, questO)\n        # (batchSize, progLength, hiddenDim)\n        out = F.tanh(self.fcAtt(torch.cat([outProg, context], dim=-1)))\n\n        # (batchSize, progLength, progVocabSize)\n        out = self.fcOut(out)\n        predSoftmax = F.log_softmax(out, 2)\n        return predSoftmax, progH\n\n    def forward(self, prog, encOut, questO):\n        progH = self.initPrgHidden(encOut)\n        predSoftmax, progH = self.forwardStep(prog, progH, questO)\n\n        return predSoftmax, progH\n\n    def sample(self, encOut, questO):\n        batchSize = encOut.size(0)\n        cudaFlag = encOut.is_cuda\n        progH = self.initPrgHidden(encOut)\n        # prog = progCopy[:, 0:3]\n        prog = torch.LongTensor(batchSize, 1).fill_(self.startID)\n        # prog = torch.cat((progStart, progEnd), -1)\n        if cudaFlag:\n            prog = prog.cuda()\n        outputLogProbs = []\n        outputTokens = []\n     \n\n        def decode(i, output):\n            tokens = output.topk(1, dim=-1)[1].view(batchSize, -1)\n            return tokens\n\n        for i in range(self.maxLen):\n            predSoftmax, progH = self.forwardStep(prog, progH, questO)\n            prog = decode(i, predSoftmax)\n            prog_flat = list(chain(*prog))\n            flat_list = [item.item() for item in prog_flat]\n            outputTokens.append(flat_list)#new\n        return outputTokens, outputLogProbs\n","metadata":{"papermill":{"duration":0.033208,"end_time":"2024-01-17T08:48:08.949858","exception":false,"start_time":"2024-01-17T08:48:08.916650","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.509673Z","iopub.execute_input":"2024-02-13T13:28:15.509998Z","iopub.status.idle":"2024-02-13T13:28:15.526884Z","shell.execute_reply.started":"2024-02-13T13:28:15.509970Z","shell.execute_reply":"2024-02-13T13:28:15.525985Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"class SeqToSeqC(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(SeqToSeqC, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, cap, prog):\n        encOut, capO = self.encoder(cap)\n        predSoftmax, progHC = self.decoder(prog, encOut, capO)\n        return predSoftmax, progHC\n   \n    def sample(self, cap):\n        with torch.no_grad():\n            encOut, capO = self.encoder(cap)\n        outputTokens, outputLogProbs = self.decoder.sample(encOut, capO)\n        #***************************************************************** Added by Sepi to avoid returning an empty torchlist.\n        #if not outputTokens:\n          #  print(\"***\")\n        # Handle the case where outputTokens is empty, for example, return a placeholder tensor\n           # return torch.tensor([])\n        #***************************************************************** \n        #outputTokens = torch.stack(outputTokens, 0).transpose(0, 1)\n        #outputTokens = torch.stack(outputTokens, dim=0).transpose(0, 1)\n        outputTokens_t = [[row[i] for row in outputTokens] for i in range(len(outputTokens[0]))]\n        #return outputTokens\n        return outputTokens_t\n","metadata":{"papermill":{"duration":0.018462,"end_time":"2024-01-17T08:48:08.976570","exception":false,"start_time":"2024-01-17T08:48:08.958108","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.528050Z","iopub.execute_input":"2024-02-13T13:28:15.528565Z","iopub.status.idle":"2024-02-13T13:28:15.542680Z","shell.execute_reply.started":"2024-02-13T13:28:15.528533Z","shell.execute_reply":"2024-02-13T13:28:15.541900Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as Optim","metadata":{"papermill":{"duration":0.015489,"end_time":"2024-01-17T08:48:09.000775","exception":false,"start_time":"2024-01-17T08:48:08.985286","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.545662Z","iopub.execute_input":"2024-02-13T13:28:15.545952Z","iopub.status.idle":"2024-02-13T13:28:15.556814Z","shell.execute_reply.started":"2024-02-13T13:28:15.545930Z","shell.execute_reply":"2024-02-13T13:28:15.555989Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"class WarmupOptimizer(object):\n    def __init__(self, lr_base, optimizer, data_size, batch_size):\n        self.optimizer = optimizer\n        self._step = 0\n        self.lr_base = lr_base\n        self._rate = 0\n        self.data_size = data_size\n        self.batch_size = batch_size\n\n    def step(self):\n        self._step += 1\n\n        rate = self.rate()\n        for p in self.optimizer.param_groups:\n            p['lr'] = rate\n        self._rate = rate\n\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def rate(self, step=None):\n        if step is None:\n            step = self._step\n\n        if step <= int(self.data_size / self.batch_size * 1):\n            r = self.lr_base * 1/2.\n        else:\n            r = self.lr_base\n\n        return r\n\n\ndef get_optim(opts, model, data_size, lr_base=None):\n    if lr_base is None:\n        lr_base = opts.lr\n\n    if opts.optim == 'adam':\n        optim = Optim.Adam(\n                filter(lambda p: p.requires_grad, model.parameters()),\n                lr=0,\n                betas=opts.betas,\n                eps=opts.eps,\n\n            )\n    elif opts.optim == 'rmsprop':\n        optim = Optim.RMSprop(\n                filter(lambda p: p.requires_grad, model.parameters()),\n                lr=0,\n                eps=opts.eps,\n                weight_decay=opts.weight_decay\n            )\n    else:\n        raise ValueError('{} optimizer is not supported'.fromat(opts.optim))\n    return WarmupOptimizer(\n        lr_base,\n        optim,\n        data_size,\n        opts.batch_size\n    )\n\ndef adjust_lr(optim, decay_r):\n    optim.lr_base *= decay_r\n","metadata":{"papermill":{"duration":0.023162,"end_time":"2024-01-17T08:48:09.033366","exception":false,"start_time":"2024-01-17T08:48:09.010204","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.557798Z","iopub.execute_input":"2024-02-13T13:28:15.558063Z","iopub.status.idle":"2024-02-13T13:28:15.570313Z","shell.execute_reply.started":"2024-02-13T13:28:15.558033Z","shell.execute_reply":"2024-02-13T13:28:15.569310Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport torch\n#import utils_m","metadata":{"papermill":{"duration":0.015328,"end_time":"2024-01-17T08:48:09.057491","exception":false,"start_time":"2024-01-17T08:48:09.042163","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.571508Z","iopub.execute_input":"2024-02-13T13:28:15.571783Z","iopub.status.idle":"2024-02-13T13:28:15.585530Z","shell.execute_reply.started":"2024-02-13T13:28:15.571753Z","shell.execute_reply":"2024-02-13T13:28:15.584628Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"class Options_c():#changed optiopn class as Option_c to differentiate it with the one belong to question\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.initialized = False\n\n    def initialize(self):\n        self.parser.add_argument(\n            '--mode',\n            default=\"train\",\n            # required=True,\n            type=str,\n            choices=['train', 'test'],\n            help='The mode of the experiment')\n\n        self.parser.add_argument(\n            '--run_dir',\n            default= '/kaggle/working',\n            # required=True,\n            type=str,\n            help='The experiment directory')\n\n        self.parser.add_argument(\n            '--load_checkpoint_path',\n            default=None,\n            type=str,\n            help='The path the the pretrained CaptionNet')\n\n        self.parser.add_argument(\n            '--res_path',\n            default = '/kaggle/working/res.txt',\n            # required=True,\n            type=str,\n            help='Path where to log the predicted caption programs')\n\n        self.parser.add_argument(\n            '--gpu_ids',\n            default='0',\n            type=str,\n            help='Id of the gpu to be used')\n\n        self.parser.add_argument(\n            '--seed',\n            default=42,\n            type=int,\n            help='The seed used in training')\n\n        self.parser.add_argument(\n            '--dataPathTr',\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_tr_half.h5\",\n            # required=True,\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n\n        self.parser.add_argument(\n            '--dataPathVal',\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_val_half.h5\",\n            # required=True,\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n\n        self.parser.add_argument(\n            '--dataPathTest',\n            # required=True,\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_test_75000.h5\",\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n\n        self.parser.add_argument(\n            '--vocabPath',\n            default = \"/kaggle/input/nsvd-dataset/caption/vocab_output_caption.json\",\n            # required=True,\n            type=str,\n            help='Path to the generated vocabulary')\n\n        self.parser.add_argument(\n            '--batch_size',\n            default=64,\n            type=int,\n            help='Batch size')\n\n        self.parser.add_argument(\n            '--num_workers',\n            default=0,\n            type=int,\n            help='Number of workers for loading')\n\n        self.parser.add_argument(\n            '--num_iters',\n            default=TOTAL_ITER,\n            type=int,\n            help='Total number of iterations')\n\n        self.parser.add_argument(\n            '--display_every',\n            default=5,\n            type=int,\n            help='Display training information every N iterations')\n\n        self.parser.add_argument(\n            '--debug_every',\n            default=100,\n            type=int,\n            help='Display debug message every N iterations')\n\n        self.parser.add_argument(\n            '--validate_every',\n            default=VALID_EVE,\n            type=int,\n            help='Validate every N iterations')\n\n        self.parser.add_argument(\n            '--shuffle_data',\n            default=1,\n            type=int,\n            help='Activate to shuffle the training data')\n\n        self.parser.add_argument(\n            '--optim',\n            default='adam',\n            type=str,\n            help='The name of the optimizer to be used')\n\n        self.parser.add_argument(\n            '--lr',\n            default=1e-3,\n            type=float,\n            help='Base learning rate')\n\n        self.parser.add_argument(\n            '--betas',\n            default='0.9, 0.98',\n            type=str,\n            help='Adam optimizer\\'s betas')\n\n        self.parser.add_argument(\n            '--eps',\n            default='1e-9',\n            type=float,\n            help='Adam optimizer\\'s epsilon')\n\n        self.parser.add_argument(\n            '--lr_decay_marks',\n            default='50000, 55000',\n            type=str,\n            help='Learing rate decay marks')\n\n        self.parser.add_argument(\n            '--lr_decay_factor',\n            default=0.5,\n            type=float,\n            help='Learning rate decay factor')\n\n        self.parser.add_argument(\n            '--weight_decay',\n            default=1e-6,\n            type=float,\n            help='Weight decay')\n\n        self.parser.add_argument(\n            '--embedDim',\n            default=300,\n            type=int,\n            help='Embedding dimension')\n\n        self.parser.add_argument(\n            '--hiddenDim',\n            default=512,\n            type=int,\n            help='LSTM hidden dimension')\n\n        self.parser.add_argument(\n            '--numLayers',\n            default=2,\n            # default=1,\n            type=int,\n            help='Number of hidden LSTM layers')\n\n        self.parser.add_argument(\n            '--dropout',\n            default=0.1,\n            type=float,\n            help='Dropout value')\n\n        self.parser.add_argument(\n            '--multiHead',\n            default=8,\n            type=int,\n            help='Number of attention heads')\n\n        self.parser.add_argument(\n            '--hiddenSizeHead',\n            default=64,\n            type=int,\n            help='Dimension of each attention head')\n\n        self.parser.add_argument(\n            '--FeedForwardSize',\n            default=2048,\n            type=int,\n            help='Dimension of the feed forward layer')\n\n        self.parser.add_argument(\n            '--FlatMLPSize',\n            default=512,\n            type=int,\n            help='MLP flatten size')\n\n        self.parser.add_argument(\n            '--FlatGlimpses',\n            default=1,\n            type=int,\n            help='Number of flatten glimpses')\n\n        self.parser.add_argument(\n            '--FlatOutSize',\n            default=512,\n            type=int,\n            help='Final attention reduction dimension')\n\n        self.parser.add_argument(\n            '--layers',\n            default=6,\n            type=int,\n            help='Number of self attention layers')\n\n        self.parser.add_argument(\n            '--bidirectional',\n            default=1,\n            type=int,\n            help='Activate to use bidirectional LSTMs')\n\n        self.initialized = True\n\n    def parse(self):\n        # initialize parser\n        if not self.initialized:\n            self.initialize()\n       # self.opts = self.parser.parse_args()\n        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n\n        # parse gpu id list\n        str_gpu_ids = self.opts.gpu_ids.split(',')\n        self.opts.gpu_ids = []\n        for str_id in str_gpu_ids:\n            if str_id.isdigit() and int(str_id) >= 0:\n                self.opts.gpu_ids.append(int(str_id))\n        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n        else:\n            print('\\n[INFO] Using cpu ...')\n            self.opts.gpu_ids = []\n\n        # parse the optimizer's betas and lr decay marks\n        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n        for i in range(1, len(lr_decay_marks)):\n            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n        self.opts.lr_decay_marks = lr_decay_marks\n\n        # print and save options\n        args = vars(self.opts)\n        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n        for k, v in args.items():\n            print('%s: %s' % (str(k), str(v)))\n\n        if not os.path.isdir(self.opts.run_dir):\n            os.makedirs(self.opts.run_dir)\n        filename = 'opts_c.txt'\n        file_path = os.path.join(self.opts.run_dir, filename)\n        with open(file_path, 'wt') as fout:\n            fout.write('| options\\n')\n            # for k, v in sorted(args.items()):\n                # fout.write('%s: %s\\n' % (str(k), str(v)))\n        return self.opts\n","metadata":{"papermill":{"duration":0.043496,"end_time":"2024-01-17T08:48:09.133209","exception":false,"start_time":"2024-01-17T08:48:09.089713","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.586722Z","iopub.execute_input":"2024-02-13T13:28:15.587023Z","iopub.status.idle":"2024-02-13T13:28:15.619041Z","shell.execute_reply.started":"2024-02-13T13:28:15.586999Z","shell.execute_reply":"2024-02-13T13:28:15.618078Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#from clevrDialog_dataset import ClevrDialogCaptionDataset\n#from models import SeqToSeqC, CaptionEncoder, Decoder\n#from optim import get_optim, adjust_lr\n#from options_caption_parser import Options\nimport os, json, torch, pickle, copy, time\nimport numpy as np\nimport torch.nn as nn\nimport torch.utils.data as Data\nfrom tensorboardX import SummaryWriter\nfrom pprint import pprint","metadata":{"papermill":{"duration":8.115876,"end_time":"2024-01-17T08:48:17.257632","exception":false,"start_time":"2024-01-17T08:48:09.141756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.620049Z","iopub.execute_input":"2024-02-13T13:28:15.620300Z","iopub.status.idle":"2024-02-13T13:28:15.634389Z","shell.execute_reply.started":"2024-02-13T13:28:15.620279Z","shell.execute_reply":"2024-02-13T13:28:15.633657Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import sys\nclass Execution:\n    def __init__(self, opts):\n        self.opts = opts\n\n        self.loss_fn = torch.nn.NLLLoss().cuda()\n        print(\"[INFO] Loading dataset ...\")\n\n        self.dataset_tr = ClevrDialogCaptionDataset(\n            opts.dataPathTr, opts.vocabPath, \"train\", \"Captions Tr\")\n\n        self.dataset_val = ClevrDialogCaptionDataset(\n            opts.dataPathVal, opts.vocabPath, \"val\", \"Captions Val\")\n\n        self.dataset_test = ClevrDialogCaptionDataset(\n           opts.dataPathTest, opts.vocabPath, \"test\", \"Captions Test\")\n\n        tb_path = os.path.join(opts.run_dir, \"tb_logdir\")\n        if not os.path.isdir(tb_path):\n            os.makedirs(tb_path)\n\n        self.ckpt_path = os.path.join(opts.run_dir, \"ckpt_dir\")\n        if not os.path.isdir(self.ckpt_path):\n            os.makedirs(self.ckpt_path)\n\n        self.writer = SummaryWriter(tb_path)\n        self.iter_val = 0\n        self.bestValAcc = float(\"-inf\")\n        self.bestValIter = -1\n\n    def constructNet(self, lenVocabText, lenVocabProg, maxLenProg, ):\n        decoder = Decoder(self.opts, lenVocabProg, maxLenProg)\n        encoder = Encoder(self.opts, lenVocabText)\n        net = SeqToSeqC(encoder, decoder)\n        return net\n\n    def train(self, dataset, dataset_val=None):\n        # Obtain needed information\n        lenVocabText = dataset.lenVocabText\n        lenVocabProg = dataset.lenVocabProg\n        maxLenProg = dataset.maxLenProg\n        net = self.constructNet(lenVocabText, lenVocabProg, maxLenProg)\n\n        net.cuda()\n        net.train()\n\n        # Define the multi-gpu training if needed\n        if len(self.opts.gpu_ids) > 1:\n            net = nn.DataParallel(net, device_ids=self.opts.gpu_ids)\n\n        # Load checkpoint if resume training\n        if self.opts.load_checkpoint_path is not None:\n            print(\"[INFO] Resume trainig from ckpt {} ...\".format(\n                self.opts.load_checkpoint_path\n            ))\n\n            # Load the network parameters\n            ckpt = torch.load(self.opts.load_checkpoint_path)\n            print(\"[INFO] Checkpoint successfully loaded ...\")\n            net.load_state_dict(ckpt['state_dict'])\n\n            # Load the optimizer paramters\n            optim = get_optim(self.opts, net, len(dataset), lr_base=ckpt['lr_base'])\n            optim.optimizer.load_state_dict(ckpt['optimizer'])\n\n        else:\n            optim = get_optim(self.opts, net, len(dataset))\n        _iter = 0\n        epoch = 0\n\n        # Define dataloader\n        dataloader = Data.DataLoader(\n            dataset,\n            batch_size=self.opts.batch_size,\n            shuffle=self.opts.shuffle_data,\n            num_workers=self.opts.num_workers,\n        )\n        _iterCur = 0\n        _totalCur = len(dataloader)\n        # Training loop\n        while _iter < self.opts.num_iters:\n            # Learning Rate Decay\n            if _iter in self.opts.lr_decay_marks:\n                adjust_lr(optim, self.opts.lr_decay_factor)\n\n            time_start = time.time()\n            # Iteration\n            for caption, captionPrg in dataloader:\n                if _iter >= self.opts.num_iters:\n                    break\n                caption = caption.cuda()\n                captionPrg = captionPrg.cuda()\n                captionPrgTarget = captionPrg.clone()\n                optim.zero_grad()\n\n                predSoftmax, _ = net(caption, captionPrg)\n\n                loss = self.loss_fn(\n                    predSoftmax[:, :-1, :].contiguous().view(-1, predSoftmax.size(2)),\n                    captionPrgTarget[:, 1:].contiguous().view(-1))\n                loss.backward()\n\n                # logging\n                self.writer.add_scalar(\n                    'train/loss',\n                    loss.cpu().data.numpy(),\n                    global_step=_iter)\n\n                self.writer.add_scalar(\n                    'train/lr',\n                    optim._rate,\n                    global_step=_iter)\n                if _iter % self.opts.display_every == 0:\n                    print(\"\\r[CLEVR-Dialog - %s (%d/%4d)][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" % (\n                            dataset.name,\n                            _iterCur,\n                            _totalCur,\n                            epoch,\n                            _iter,\n                            self.opts.num_iters,\n                            loss.cpu().data.numpy(),\n                            optim._rate,\n                        ), end='          ')\n                optim.step()\n                _iter += 1\n                _iterCur += 1\n\n                if _iter % self.opts.validate_every == 0:\n                    if dataset_val is not None:\n                        valAcc = self.eval(\n                            net,\n                            dataset_val,\n                            valid=True,\n                        )\n                        if valAcc > self.bestValAcc:\n                            self.bestValAcc = valAcc\n                            self.bestValIter = _iter\n\n                            print(\"[INFO] Checkpointing model @ iter {}\".format(_iter))\n                            state = {\n                                'state_dict': net.state_dict(),\n                                'optimizer': optim.optimizer.state_dict(),\n                                'lr_base': optim.lr_base,\n                                'optim': optim.lr_base,\n                                'last_iter': _iter,\n                                'last_epoch': epoch,\n                            }\n                            # checkpointing\n                            torch.save(\n                                state,\n                                #os.path.join(self.ckpt_path, 'ckpt_iter' + str(_iter) + '.pkl')\n                                os.path.join(self.ckpt_path, 'UC_ckpt_iter' + str(valAcc) + str(_iter) + '.pkl')\n                            )\n                    else:\n                        print(\"[INFO] No validation dataset available\")\n\n            time_end = time.time()\n            print('Finished epoch in {}s'.format(int(time_end-time_start)))\n            epoch += 1\n\n        print(\"[INFO] Training done. Best model had val acc. {} @ iter {}...\".format(self.bestValAcc, self.bestValIter))\n\n    # Evaluation\n    def eval(self, net, dataset, valid=False):\n        net = net.eval()\n        data_size = len(dataset)\n        dataloader = Data.DataLoader(\n            dataset,\n            batch_size=self.opts.batch_size,\n            shuffle=False,\n            num_workers=self.opts.num_workers,\n            pin_memory=False\n        )\n        allPredictedProgs = []\n        numAllProg = 0\n        falsePred = 0\n        for step, (caption, captionPrg) in enumerate(dataloader):\n            print(\"\\rEvaluation: [step %4d/%4d]\" % (\n                step,\n                int(data_size / self.opts.batch_size),\n            ), end='          ')\n            sys.stdout.flush()\n            g_truth = torch.tensor(captionPrg)\n            caption = caption.cuda()\n            captionPrg = captionPrg.cuda()\n            tokens = net.sample(caption)\n            prediction_s = torch.tensor(tokens)\n            targetProgs = decodeProg(captionPrg, dataset.vocab[\"idx_prog_to_token\"], target=True)\n            predProgs = decodeProg(tokens, dataset.vocab[\"idx_prog_to_token\"])\n            predProgs = [sublist for sublist in predProgs if sublist]\n            allPredictedProgs.extend(list(map(lambda s: \"( {} ( {} ) ) \\n\".format(s[0], \", \".join(s[1:])), predProgs)))\n                              \n                                \n            numAllProg += len(targetProgs)\n            for targetProg, predProg in zip(targetProgs, predProgs):\n                mainMod = targetProg[0] == predProg[0]\n                sameLength = len(targetProg) == len(predProg)\n                sameArgs = False\n                if sameLength:\n                    sameArgs = True\n                    for argTarget in targetProg[1:]:\n                        if argTarget not in predProg[1:]:\n                            sameArgs = False\n                            break\n\n                if not (mainMod and sameArgs):\n                    falsePred += 1\n        val_acc = (1 - (falsePred / numAllProg)) * 100.0\n        print(\"Acc: {}\".format(val_acc))\n        net = net.train()\n        if not valid:\n            with open(self.opts.res_path, \"w\") as f:\n                f.writelines(allPredictedProgs)\n            print(\"[INFO] Predicted caption programs logged into {}\".format(self.opts.res_path))\n        return val_acc\n\n    def run(self, run_mode):\n        self.set_seed(self.opts.seed)\n        if run_mode == 'train':\n            self.train(self.dataset_tr, self.dataset_val)\n\n        elif run_mode == 'test':\n            lenVocabText = self.dataset_test.lenVocabText\n            lenVocabProg = self.dataset_test.lenVocabProg\n            maxLenProg = self.dataset_test.maxLenProg\n            net = self.constructNet(lenVocabText, lenVocabProg, maxLenProg)\n\n            print('Loading ckpt {}'.format(self.opts.load_checkpoint_path))\n            state_dict = torch.load(self.opts.load_checkpoint_path)['state_dict']\n            net.load_state_dict(state_dict)\n            net.cuda()\n            self.eval(net, self.dataset_test)\n\n        else:\n            exit(-1)\n\n    def set_seed(self, seed):\n        \"\"\"Sets the seed for reproducibility.\n        Args:\n            seed (int): The seed used\n        \"\"\"\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        np.random.seed(seed)\n        print('[INFO] Seed set to {}...'.format(seed))\n\n\ndef decodeProg(tokens, prgIdxToToken, target=False):\n    \n    if (target == True):\n        tokensBatch = tokens.tolist()\n    else:\n        tokensBatch = tokens\n    #print(\"want to see what happens to tokens in decodeProg\", tokensBatch)\n    progsBatch = []\n    for tokens in tokensBatch:\n        #print(\"tokens inside the first for loop in decodeProg\", tokens)\n        prog = []\n        for tok in tokens:\n            if tok == 2:  # <END> has index 2\n                break\n            \n            prog.append(prgIdxToToken.get(tok))\n          \n           \n        if target:\n            #print(\"tuye if\")\n            prog = prog[1:]\n        progsBatch.append(prog)\n    return progsBatch\n\n\n\n","metadata":{"papermill":{"duration":0.052372,"end_time":"2024-01-17T08:48:17.318876","exception":false,"start_time":"2024-01-17T08:48:17.266504","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.635487Z","iopub.execute_input":"2024-02-13T13:28:15.635798Z","iopub.status.idle":"2024-02-13T13:28:15.677951Z","shell.execute_reply.started":"2024-02-13T13:28:15.635768Z","shell.execute_reply":"2024-02-13T13:28:15.677198Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"##### #__name__ == \"__main__\":\nopts = Options_c().parse()\n\n\n","metadata":{"papermill":{"duration":0.098392,"end_time":"2024-01-17T08:48:17.425387","exception":false,"start_time":"2024-01-17T08:48:17.326995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.678917Z","iopub.execute_input":"2024-02-13T13:28:15.679180Z","iopub.status.idle":"2024-02-13T13:28:15.695763Z","shell.execute_reply.started":"2024-02-13T13:28:15.679158Z","shell.execute_reply":"2024-02-13T13:28:15.694877Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"\n[INFO] Using 1 CUDA device(s) ...\n\n ------------------------------Opts------------------------------\nmode: train\nrun_dir: /kaggle/working\nload_checkpoint_path: None\nres_path: /kaggle/working/res.txt\ngpu_ids: [0]\nseed: 42\ndataPathTr: /kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_tr_half.h5\ndataPathVal: /kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_val_half.h5\ndataPathTest: /kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/cap_test_75000.h5\nvocabPath: /kaggle/input/nsvd-dataset/caption/vocab_output_caption.json\nbatch_size: 64\nnum_workers: 0\nnum_iters: 5000\ndisplay_every: 5\ndebug_every: 100\nvalidate_every: 1000\nshuffle_data: 1\noptim: adam\nlr: 0.001\nbetas: [0.9, 0.98]\neps: 1e-09\nlr_decay_marks: [50000, 55000]\nlr_decay_factor: 0.5\nweight_decay: 1e-06\nembedDim: 300\nhiddenDim: 512\nnumLayers: 2\ndropout: 0.1\nmultiHead: 8\nhiddenSizeHead: 64\nFeedForwardSize: 2048\nFlatMLPSize: 512\nFlatGlimpses: 1\nFlatOutSize: 512\nlayers: 6\nbidirectional: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"exe = Execution(opts)","metadata":{"papermill":{"duration":1.232001,"end_time":"2024-01-17T08:48:18.665738","exception":false,"start_time":"2024-01-17T08:48:17.433737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:15.696833Z","iopub.execute_input":"2024-02-13T13:28:15.697167Z","iopub.status.idle":"2024-02-13T13:28:16.344457Z","shell.execute_reply.started":"2024-02-13T13:28:15.697108Z","shell.execute_reply":"2024-02-13T13:28:16.343380Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"[INFO] Loading dataset ...\n","output_type":"stream"}]},{"cell_type":"code","source":"exe.run(opts.mode)","metadata":{"papermill":{"duration":89.472307,"end_time":"2024-01-17T08:49:48.146898","exception":false,"start_time":"2024-01-17T08:48:18.674591","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T13:28:16.345853Z","iopub.execute_input":"2024-02-13T13:28:16.346789Z","iopub.status.idle":"2024-02-13T14:05:14.291639Z","shell.execute_reply.started":"2024-02-13T13:28:16.346754Z","shell.execute_reply":"2024-02-13T14:05:14.290771Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"[INFO] Seed set to 42...\nEvaluation: [step    1/   1]          ][epoch  0][iter  995/5000] loss: 0.6006, lr: 5.00e-04          ","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/782879147.py:183: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  g_truth = torch.tensor(captionPrg)\n","output_type":"stream"},{"name":"stdout","text":"Acc: 71.7741935483871\n[INFO] Checkpointing model @ iter 1000\nEvaluation: [step    1/   1]          )][epoch  0][iter 1995/5000] loss: 0.5720, lr: 5.00e-04          Acc: 75.80645161290323\n[INFO] Checkpointing model @ iter 2000\n[CLEVR-Dialog - Captions Tr (2730/2733)][epoch  0][iter 2730/5000] loss: 0.5676, lr: 5.00e-04          Finished epoch in 1206s\nEvaluation: [step    1/   1]          )][epoch  1][iter 2995/5000] loss: 0.5755, lr: 1.00e-03          Acc: 75.80645161290323\nEvaluation: [step    1/   1]          )][epoch  1][iter 3995/5000] loss: 0.5671, lr: 1.00e-03          Acc: 75.80645161290323\nEvaluation: [step    1/   1]          )][epoch  1][iter 4995/5000] loss: 0.5495, lr: 1.00e-03          Acc: 75.80645161290323\nFinished epoch in 1006s\n[INFO] Training done. Best model had val acc. 75.80645161290323 @ iter 2000...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"[INFO] Done ...\")","metadata":{"papermill":{"duration":0.022547,"end_time":"2024-01-17T08:49:48.183663","exception":false,"start_time":"2024-01-17T08:49:48.161116","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-13T14:05:14.293040Z","iopub.execute_input":"2024-02-13T14:05:14.293904Z","iopub.status.idle":"2024-02-13T14:05:14.298725Z","shell.execute_reply.started":"2024-02-13T14:05:14.293873Z","shell.execute_reply":"2024-02-13T14:05:14.297848Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"[INFO] Done ...\n","output_type":"stream"}]}]}