{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7619146,"sourceType":"datasetVersion","datasetId":4436528}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### for cleaning the CPU ram\nimport gc\ngc.collect()\n\n%reset -f","metadata":{"execution":{"iopub.execute_input":"2024-01-15T08:21:13.081056Z","iopub.status.busy":"2024-01-15T08:21:13.080540Z","iopub.status.idle":"2024-01-15T08:21:13.169248Z","shell.execute_reply":"2024-01-15T08:21:13.168532Z","shell.execute_reply.started":"2024-01-15T08:21:13.081031Z"}}},{"cell_type":"code","source":"#for cleaning the GPU ram\nimport torch \ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.141504Z","iopub.execute_input":"2024-02-13T16:22:22.141866Z","iopub.status.idle":"2024-02-13T16:22:22.148884Z","shell.execute_reply.started":"2024-02-13T16:22:22.141840Z","shell.execute_reply":"2024-02-13T16:22:22.147696Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"TOTAL_ITER = 1000\nVALID_EVE =100","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.150769Z","iopub.execute_input":"2024-02-13T16:22:22.151175Z","iopub.status.idle":"2024-02-13T16:22:22.156584Z","shell.execute_reply.started":"2024-02-13T16:22:22.151142Z","shell.execute_reply":"2024-02-13T16:22:22.155646Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport json\nimport os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\nimport argparse#***","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.157927Z","iopub.execute_input":"2024-02-13T16:22:22.158521Z","iopub.status.idle":"2024-02-13T16:22:22.165104Z","shell.execute_reply.started":"2024-02-13T16:22:22.158487Z","shell.execute_reply":"2024-02-13T16:22:22.164218Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def invertDict(_dict):\n    return {v: k for k, v in _dict.items()}","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.166329Z","iopub.execute_input":"2024-02-13T16:22:22.166648Z","iopub.status.idle":"2024-02-13T16:22:22.172426Z","shell.execute_reply.started":"2024-02-13T16:22:22.166608Z","shell.execute_reply":"2024-02-13T16:22:22.171329Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class ClevrDialogDataset(Dataset):\n    def __init__(self, dataPath, vocabPath, split, indStart=0, indEnd=-1):\n        super(ClevrDialogDataset, self).__init__()\n        self.data = h5py.File(dataPath, \"r\")\n        with open(vocabPath, \"r\") as f:\n            self.vocab = json.load(f)\n        self.vocab[\"idx_text_to_token\"] = invertDict(self.vocab[\"text_token_to_idx\"])\n        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n        self.lenVocabText = len(self.vocab[\"text_token_to_idx\"])\n        self.lenVocabProg = len(self.vocab[\"prog_token_to_idx\"])\n\n        self.split = split\n        self.indStart = indStart\n        self.indEnd = indEnd\n        self.maxSamples = indEnd - indStart\n        self.maxLenProg = 6\n\n    def __len__(self):\n        raise NotImplementedError\n\n    def __getitem__(self, index):\n        raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.174923Z","iopub.execute_input":"2024-02-13T16:22:22.175375Z","iopub.status.idle":"2024-02-13T16:22:22.185057Z","shell.execute_reply.started":"2024-02-13T16:22:22.175315Z","shell.execute_reply":"2024-02-13T16:22:22.184157Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class ClevrDialogUnifiedDataset(ClevrDialogDataset):\n    def __init__(self, dataPath, vocabPath, split, name, train=True, indStart=0, indEnd=-1):\n        super(ClevrDialogUnifiedDataset, self).__init__(dataPath, vocabPath, split, indStart=indStart, indEnd=indEnd)\n        #self.captions = torch.LongTensor(np.asarray(self.data[\"captions\"], dtype=np.int64)[indStart: indEnd])\n        #self.captionsPrgs = torch.LongTensor(np.asarray(self.data[\"captionProgs\"], dtype=np.int64)[indStart: indEnd])\n\n        self.questions = torch.LongTensor(np.asarray(self.data[\"questions\"], dtype=np.int64)[indStart: indEnd])\n        self.quesProgs = torch.LongTensor(np.asarray(self.data[\"questionProgs\"], dtype=np.int64)[indStart: indEnd])\n        self.questionRounds = torch.LongTensor(np.asarray(self.data[\"questionRounds\"], dtype=np.int64)[indStart: indEnd])\n        self.questionImgIdx = torch.LongTensor(np.asarray(self.data[\"questionImgIdx\"], dtype=np.int64)[indStart: indEnd])\n        self.histories = torch.LongTensor(np.asarray(self.data[\"histories\"], dtype=np.int64)[indStart: indEnd])\n        self.historiesProgs = torch.LongTensor(np.asarray(self.data[\"historiesProg\"], dtype=np.int64)[indStart: indEnd])\n\n        self.answers = torch.LongTensor(np.asarray(self.data[\"answers\"], dtype=np.int64)[indStart: indEnd])\n        self.name = name\n        self.train = train\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        assert idx < len(self)\n        question = self.questions[idx]\n        questionPrg = self.quesProgs[idx]\n        questionImgIdx = self.questionImgIdx[idx]\n        questionRound = self.questionRounds[idx]\n\n        history = self.histories[idx]\n        historiesProg = self.historiesProgs[idx]\n\n        answer = self.answers[idx]\n        if self.train:\n            #return caption, captionPrg, question, questionPrg, questionRound, history, answer\n            return question, questionPrg, questionRound, history,historiesProg, answer\n        else:\n            return question, questionPrg, questionRound, history,historiesProg, answer, questionImgIdx","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.186369Z","iopub.execute_input":"2024-02-13T16:22:22.186635Z","iopub.status.idle":"2024-02-13T16:22:22.200187Z","shell.execute_reply.started":"2024-02-13T16:22:22.186613Z","shell.execute_reply":"2024-02-13T16:22:22.199200Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"COLORS = [\"blue\", \"brown\", \"cyan\", \"gray\", \"green\", \"purple\", \"red\", \"yellow\"]\nMATERIALS = [\"rubber\", \"metal\"]\nSHAPES = [\"cube\", \"cylinder\", \"sphere\"]\nSIZES = [\"large\", \"small\"]\n\nATTRIBUTES_ALL = COLORS + MATERIALS + SHAPES + SIZES\n\nANSWER_CANDIDATES = {\n    # Count questions\n    \"count-all\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n    \"count-other\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"count-all-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n    \"count-attribute\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n    \"count-attribure-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n    \"count-obj-rel-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"count-obj-rel-imm2\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"count-obj-rel-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"count-obj-exclude-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"count-obj-exclude-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n\n    # Existence questions\n    \"exist-other\": [\"yes\", \"no\"],\n    \"exist-attribute\": [\"yes\", \"no\"],\n    \"exist-attribute-group\": [\"yes\", \"no\"],\n    \"exist-obj-rel-imm\": [\"yes\", \"no\"],\n    \"exist-obj-rel-imm2\": [\"yes\", \"no\"],\n    \"exist-obj-rel-early\": [\"yes\", \"no\"],\n    \"exist-obj-exclude-imm\": [\"yes\", \"no\"],\n    \"exist-obj-exclude-early\": [\"yes\", \"no\"],\n\n    # Seek questions\n    \"seek-attr-imm\": ATTRIBUTES_ALL,\n    \"seek-attr-imm2\": ATTRIBUTES_ALL,\n    \"seek-attr-early\": ATTRIBUTES_ALL,\n    \"seek-attr-sim-early\": ATTRIBUTES_ALL,\n    \"seek-attr-rel-imm\": ATTRIBUTES_ALL,\n    \"seek-attr-rel-early\": ATTRIBUTES_ALL,\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.238998Z","iopub.execute_input":"2024-02-13T16:22:22.239233Z","iopub.status.idle":"2024-02-13T16:22:22.250388Z","shell.execute_reply.started":"2024-02-13T16:22:22.239214Z","shell.execute_reply":"2024-02-13T16:22:22.249435Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\n\n\ndef merge_captions_question_programs(path_cap, path_ques, caption_first=True):\n    with open(path_cap, \"r\"):\n        c_progs = path_cap.readlines()\n    with open(path_ques, \"r\"):\n        q_progs = path_ques.readlines()\n\n    all_merged_progs = []\n    i = 0\n    while i < len(q_progs):\n        cap_idx = i % 11 if caption_first else i % 10\n        start_idx_p = i + 1 if caption_first else i\n        end_idx_p = start_idx_p + 12 if caption_first else  start_idx_p + 11\n        temp = c_progs[cap_idx] + q_progs[start_idx_p, end_idx_p]\n        all_merged_progs.append(temp)\n        i = end_idx_p\n\n\ndef load_clevr_scenes(scenes_json):\n    with open(scenes_json) as f:\n        scenes_raw = json.load(f)\n    if type(scenes_raw) == dict:\n        scenes_raw = scenes_raw[\"scenes\"]\n\n    scenes = []\n    for s in scenes_raw:\n        table = []\n        for i, o in enumerate(s['objects']):\n            item = {}\n            item['id'] = '%d-%d' % (s['image_index'], i)\n            if '3d_coords' in o:\n                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n                                    np.dot(o['3d_coords'], s['directions']['front']),\n                                    o['3d_coords'][2]]\n            else:\n                item['position'] = o['position']\n            item['color'] = o['color']\n            item['material'] = o['material']\n            item['shape'] = o['shape']\n            item['size'] = o['size']\n            table.append(item)\n        scenes.append(table)\n    return scenes\n\n\ndef load_minecraft_scenes(scenes_json):\n    with open(scenes_json) as f:\n        scenes_raw = json.load(f)\n    if type(scenes_raw) == dict:\n        scenes_raw = scenes_raw[\"scenes\"]\n\n    scenes = []\n    for s in scenes_raw:\n        table = []\n        for i, o in enumerate(s['objects']):\n            item = {}\n            item['id'] = '%d-%d' % (s['image_index'], i)\n            if '3d_coords' in o:\n                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n                                    np.dot(o['3d_coords'], s['directions']['front']),\n                                    o['3d_coords'][2]]\n            else:\n                item['position'] = o['position']\n            item['nature'] = o['nature']\n            item['class'] = o['class']\n            item['direction'] = \"facing_\"\n            if o['direction'] == \"front\":\n                item['direction'] += \"forward\"\n            elif o['direction'] == \"back\":\n                item['direction'] += \"backward\"\n            elif o['direction'] == \"right\":\n                item['direction'] += \"right\"\n            elif o['direction'] == \"left\":\n                item['direction'] += \"left\"\n            table.append(item)\n        scenes.append(table)\n    return scenes","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.252069Z","iopub.execute_input":"2024-02-13T16:22:22.252421Z","iopub.status.idle":"2024-02-13T16:22:22.272111Z","shell.execute_reply.started":"2024-02-13T16:22:22.252386Z","shell.execute_reply":"2024-02-13T16:22:22.271116Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom copy import deepcopy\n\n\n#from executor.clevr_statics import COLORS, MATERIALS, SHAPES, SIZES\n#from executor.clevr_statics import ANSWER_CANDIDATES as ANSWER_CANDIDATES_CLEVR\n#from executor.clevr_statics import ATTRIBUTES_ALL as ATTRIBUTES_ALL_CLEVR\n\n#from utils_m import load_clevr_scenes\n\n\nclass SymbolicExecutorClevr(object):\n    \"\"\"Symbolic executor for clevr-dialog\n    \"\"\"\n    def __init__(self, scenesPath):\n        super(SymbolicExecutorClevr, self).__init__()\n        self.functions = {}\n        self.registerFunctions()\n        self.uniqueObjFlag = False\n        self.colors = COLORS\n        self.materials = MATERIALS\n        self.shapes = SHAPES\n        self.sizes = SIZES\n        self.answer_candidates = ANSWER_CANDIDATES#***\n        self.attribute_all = ATTRIBUTES_ALL#***\n        self.scenes = load_clevr_scenes(scenesPath)\n\n    def reset(self, sceneIdx):\n        \"\"\"Resets the scene\n\n        Args:\n            sceneIdx: The index of the new scene\n        \"\"\"\n        self.scene = self.scenes[sceneIdx]\n        for _obj in self.scene:\n            _obj[\"identifier\"] = None\n        # store previous objects in a list to better answer\n        # xxx-imm, xxx-imm2, xxx-group and xxx-early questions.\n        self.objs = []\n        self.groups = []\n        self.visited = []\n        self.currentObj = None\n        self.currentGrp = []\n        self.uniqueObjFlag = False\n\n    def registerFunctions(self):\n        \"\"\"Registers the available functions of the executor.\n        \"\"\"\n        # Captions - extreme location\n        self.functions[\"extreme-right\"] = self.extremeRight\n        self.functions[\"extreme-left\"] = self.extremeLeft\n        self.functions[\"extreme-behind\"] = self.extremeBehind\n        self.functions[\"extreme-front\"] = self.extremeFront\n        self.functions[\"extreme-center\"] = self.extremeCenter\n\n        # Captions - multiple objects\n        self.functions[\"count-att\"] = self.countAttributeCaption\n\n        # Captions - object relations\n        self.functions[\"obj-relation\"] = self.objRelation\n\n        # Captions - unique object\n        self.functions[\"unique-obj\"] = self.uniqueObject\n\n        # Questions - Count\n        self.functions[\"count-all\"] = self.countAll\n        self.functions[\"count-other\"] = self.countOther\n        self.functions[\"count-all-group\"] = self.countAllGroup\n        self.functions[\"count-attribute\"] = self.countAttribute\n        self.functions[\"count-attribute-group\"] = self.countAttributeGroup\n        self.functions[\"count-obj-rel-imm\"] = self.countObjRelImm\n        self.functions[\"count-obj-rel-imm2\"] = self.countObjRelImm2\n        self.functions[\"count-obj-rel-early\"] = self.countObjRelEarly\n        self.functions[\"count-obj-exclude-imm\"] = self.countObjExcludeImm\n        self.functions[\"count-obj-exclude-early\"] = self.countObjExcludeEarly\n\n        # Questions - Exist\n        self.functions[\"exist-other\"] = self.existOther\n        self.functions[\"exist-attribute\"] = self.existAttribute\n        self.functions[\"exist-attribute-group\"] = self.existAttributeGroup\n        self.functions[\"exist-obj-rel-imm\"] = self.existObjRelImm\n        self.functions[\"exist-obj-rel-imm2\"] = self.existObjRelImm\n        self.functions[\"exist-obj-rel-early\"] = self.existObjRelEarly\n        self.functions[\"exist-obj-exclude-imm\"] = self.existObjExcludeImm\n        self.functions[\"exist-obj-exclude-early\"] = self.existObjExcludeEarly\n\n        # Questions - Seek\n        self.functions[\"seek-attr-imm\"] = self.seekAttrImm\n        self.functions[\"seek-attr-imm2\"] = self.seekAttrImm\n        self.functions[\"seek-attr-early\"] = self.seekAttributeEarly\n        self.functions[\"seek-attr-rel-imm\"] = self.seekAttributeRelImm\n        self.functions[\"seek-attr-rel-early\"] = self.seekAttributeRelEarly\n\n\n    ########################################################\n    #                   Helper functions                   #\n    ########################################################\n    def getAttributeType(self, attribute):\n        assert attribute in self.attribute_all, \"The attribute {} is unkown\".format(\n            attribute)\n        if attribute in self.colors:\n            return \"color\"\n        elif attribute in self.materials:\n            return \"material\"\n        elif attribute in self.shapes:\n            return \"shape\"\n        elif attribute in self.sizes:\n            return \"size\"\n\n    def execute(self, functionLabel, functionArgs):\n        assert functionLabel in self.functions, \"{} is not a valid function\".format(\n            functionLabel)\n        function = self.functions[functionLabel]\n        answer = function(*functionArgs)\n        return answer\n\n    def updateCurrentObj(self, obj):\n        self.currentObj = obj\n        objsCopy = deepcopy(self.objs)\n        for i, _obj in enumerate(objsCopy):\n            if _obj[\"id\"] == obj[\"id\"]:\n                del self.objs[i]\n        # Current obj is always kept at the end of the visited objs\n        self.objs.append(obj)\n\n    def updateVisited(self, obj):\n        if len(self.visited) == 0:\n            self.visited.append(obj)\n        else:\n            newObjFlag = True\n            for _obj in self.visited:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    newObjFlag = False\n                    break\n            if newObjFlag:\n                self.visited.append(obj)\n\n    def getOther(self):\n        others = []\n        if len(self.visited) < len(self.scene):\n            for _obj in self.scene:\n                notExisting = True\n                for __obj in self.visited:\n                    if __obj[\"id\"] == _obj[\"id\"]:\n                        notExisting = False\n                        break\n                if notExisting:\n                    others.append(_obj)\n        return others\n\n    def updateIdentifier(self, obj, attribute):\n        if obj[\"identifier\"] is None:\n            obj[\"identifier\"] = attribute\n        else:\n            identifiers = obj[\"identifier\"].split(\"-\")\n            if attribute not in identifiers:\n                identifiers.append(attribute)\n                obj[\"identifier\"] = \"-\".join(identifiers)\n\n\n    ########################################################\n    #                   Caption programs                   #\n    ########################################################\n\n    def extremeRight(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n\n        leftToRight = deepcopy(self.scene)\n        leftToRight.sort(key=lambda o: o[\"position\"][0])\n        extremeRightObj = leftToRight[-1]\n        for attributeType, attribute in zip(attributeTypes, attributes):\n            assert extremeRightObj[attributeType] == attribute\n            self.updateIdentifier(extremeRightObj, attribute)\n\n        self.updateCurrentObj(extremeRightObj)\n        self.updateVisited(extremeRightObj)\n        del leftToRight\n\n    def extremeLeft(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n\n        leftToRight = deepcopy(self.scene)\n        leftToRight.sort(key=lambda o: o[\"position\"][0])\n        extremeLeftObj = leftToRight[0]\n        for attributeType, attribute in zip(attributeTypes, attributes):\n            assert extremeLeftObj[attributeType] == attribute\n            self.updateIdentifier(extremeLeftObj, attribute)\n\n        self.updateCurrentObj(extremeLeftObj)\n        self.updateVisited(extremeLeftObj)\n        del leftToRight\n\n    def extremeFront(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n\n        backToFront = deepcopy(self.scene)\n        backToFront.sort(key=lambda o: o[\"position\"][1])\n        extremeFrontObj = backToFront[-1]\n        for attributeType, attribute in zip(attributeTypes, attributes):\n            assert extremeFrontObj[attributeType] == attribute\n            self.updateIdentifier(extremeFrontObj, attribute)\n\n        self.updateCurrentObj(extremeFrontObj)\n        self.updateVisited(extremeFrontObj)\n        del backToFront\n\n    def extremeBehind(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n\n        backToFront = deepcopy(self.scene)\n        backToFront.sort(key=lambda o: o[\"position\"][1])\n        extremeBehindObj = backToFront[0]\n        for attributeType, attribute in zip(attributeTypes, attributes):\n            assert extremeBehindObj[attributeType] == attribute\n            self.updateIdentifier(extremeBehindObj, attribute)\n\n        self.updateCurrentObj(extremeBehindObj)\n        self.updateVisited(extremeBehindObj)\n        del backToFront\n\n    def extremeCenter(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n        numObjs = len(self.scene)\n\n        frontToBack = deepcopy(self.scene)\n        frontToBack.sort(key=lambda o: o[\"position\"][1], reverse=True)\n\n        rightToLeft = deepcopy(self.scene)\n        rightToLeft.sort(key=lambda o: o[\"position\"][0], reverse=True)\n\n        prelimenaryCandidates = []\n\n        for i, objFrontToBack in enumerate(frontToBack):\n            numObjsInFront = i\n            numObjsBehind = len(rightToLeft) - i - 1\n            if numObjsInFront <= numObjs / 2 and numObjsBehind <= numObjs / 2:\n                prelimenaryCandidates.append(objFrontToBack)\n        foundCenter = False\n        for _obj in prelimenaryCandidates:\n            for i, objRightToLeft in enumerate(rightToLeft):\n                if _obj[\"id\"] == objRightToLeft[\"id\"]:\n                    numObjsToTheRight = i\n                    numObjsToTheLeft = len(frontToBack) - i - 1\n                    if numObjsToTheRight <= numObjs / 2 and numObjsToTheLeft <= numObjs / 2:\n                        foundCenter = True\n                        for attributeType, attribute in zip(attributeTypes, attributes):\n                            if _obj[attributeType] != attribute:\n                                foundCenter = False\n                                break\n                        break\n            if foundCenter:\n                break\n        for attributeType, attribute in zip(attributeTypes, attributes):\n            self.updateIdentifier(_obj, attribute)\n        self.updateCurrentObj(_obj)\n        self.updateVisited(_obj)\n        del rightToLeft, frontToBack\n\n    def countAttributeCaption(self, attribute):\n        attributeType = self.getAttributeType(attribute)\n        objs = []\n        for _obj in self.scene:\n            if _obj[attributeType] == attribute:\n                objs.append(deepcopy(_obj))\n        for _obj in objs:\n            self.updateIdentifier(_obj, attribute)\n        # update the current group\n        self.currentGrp = objs\n\n        # update the visited objects list\n        for _obj in objs:\n            self.updateVisited(_obj)\n\n    def getAnchorAttribute(self, attribute_1, attribute_2, scene):\n        # The anchor object is unique. If we filter the object list\n        # based on the attribute anchor, we must find only one object.\n        filterAttribute_1 = self.filterAttribute(scene, attribute_1)\n        if len(filterAttribute_1) == 1:\n            return attribute_1\n        else:\n            return attribute_2\n\n    def objRelation(self, attribute, attributeAnchor, relation):\n        assert relation in [\"left\", \"right\", \"front\", \"behind\"]\n        # find the anchor object\n        if attributeAnchor != self.getAnchorAttribute(attribute, attributeAnchor, self.scene):\n            temp = deepcopy(attribute)\n            attribute = deepcopy(attributeAnchor)\n            attributeAnchor = temp\n            if relation == \"left\":\n                relation = \"right\"\n            elif relation == \"right\":\n                relation = \"left\"\n            elif relation == \"behind\":\n                relation = \"front\"\n            elif relation == \"front\":\n                relation = \"behind\"\n\n        # Order the objects in the scene w.r.t. the relation\n        sceneCopy = deepcopy(self.scene)\n\n        if relation in [\"left\", \"right\"]:\n            sceneCopy.sort(key=lambda o: o[\"position\"][0])\n        else:\n            sceneCopy.sort(key=lambda o: o[\"position\"][1])\n\n        # get the anchor object\n        attributeTypeAnchor = self.getAttributeType(attributeAnchor)\n        for i, _obj in enumerate(sceneCopy):\n            if _obj[attributeTypeAnchor] == attributeAnchor:\n                break\n        # save the anchor object before the main object\n        anchorObj = _obj\n        self.updateIdentifier(anchorObj, attributeAnchor)\n        self.updateCurrentObj(anchorObj)\n        self.updateVisited(anchorObj)\n\n        if relation in [\"left\", \"behind\"]:\n            sceneCopy = list(reversed(sceneCopy[:i]))\n        else:\n            sceneCopy = sceneCopy[i+1:]\n\n        attributeType = self.getAttributeType(attribute)\n        # get the main object\n        for _obj in sceneCopy:\n            # and not equalDicts(_obj, anchorObj):\n            if _obj[attributeType] == attribute:\n                break\n        self.updateIdentifier(_obj, attribute)\n        self.updateCurrentObj(_obj)\n        self.updateVisited(_obj)\n        del sceneCopy\n\n    def uniqueObject(self, *attributes):\n        attributes = list(attributes)\n        attributeTypes = list(\n            map(lambda att: self.getAttributeType(att), attributes))\n\n        for _obj in self.scene:\n            found = True\n            for attributeType, attribute in zip(attributeTypes, attributes):\n                if _obj[attributeType] != attribute:\n                    found = False\n                    break\n\n            if found:\n                break\n        for att in attributes:\n            self.updateIdentifier(_obj, att)\n\n        self.updateCurrentObj(_obj)\n        self.updateVisited(_obj)\n\n    ######################################## Question Programs ########################################\n    def filterOutObj(self, scene, obj):\n        sceneCopy = deepcopy(scene)\n        for i, _obj in enumerate(scene):\n            if obj[\"id\"] == _obj[\"id\"]:\n                break\n        del sceneCopy[i]\n        return sceneCopy\n\n    def filterAttribute(self, scene, attribute):\n        attributeType = self.getAttributeType(attribute)\n        filtered = []\n        if len(scene) == 0:\n            return filtered\n\n        for _obj in scene:\n            if _obj[attributeType] == attribute:\n                filtered.append(_obj)\n        return filtered\n\n    def excludeAttribute(self, scene, obj, attributeType):\n        filtered = []\n        if len(scene) == 0:\n            return filtered\n        for _obj in scene:\n            if _obj[\"id\"] != obj[\"id\"] and obj[attributeType] == _obj[attributeType]:\n                filtered.append(_obj)\n\n        # Update the visited objects list\n        if len(filtered) > 0:\n            for _obj in filtered:\n                self.updateVisited(_obj)\n        return filtered\n\n    def filterLeft(self, scene, obj):\n        filtered = []\n        if len(scene) == 0:\n            return filtered\n\n        for _obj in self.scene:\n            # if the x-coordinate of _obj is smaller than the x-coordinate of slef.currentObj,\n            # then _obj is located to the left of self.currentObj\n            if _obj[\"position\"][0] < obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n                filtered.append(_obj)\n        return filtered\n\n    def filterRight(self, scene, obj):\n        filtered = []\n        for _obj in self.scene:\n            # if the x-coordinate of _obj is bigger than the x-coordinate of slef.currentObj,\n            # then _obj is located to the right of self.currentObj\n            if _obj[\"position\"][0] > obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n                filtered.append(_obj)\n        return filtered\n\n    def filterFront(self, scene, obj):\n        filtered = []\n        if len(scene) == 0:\n            return filtered\n\n        for _obj in self.scene:\n            # if the y-coordinate of _obj is smaller than the y-coordinate of slef.currentObj,\n            # then _obj is located in front of self.currentObj\n            if _obj[\"position\"][1] > obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n                filtered.append(_obj)\n        return filtered\n\n    def filterBehind(self, scene, obj):\n        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n        filtered = []\n        if len(scene) == 0:\n            return filtered\n\n        for _obj in scene:\n            # if the y-coordinate of _obj is bigger than the y-coordinate of slef.currentObj,\n            # then _obj is located behind self.currentObj\n            if _obj[\"position\"][1] < obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n                filtered.append(_obj)\n        return filtered\n\n    def filterPosition(self, scene, obj, pos):\n        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n        assert pos in [\"left\", \"right\", \"front\", \"behind\"]\n        if pos == \"left\":\n            filtered = self.filterLeft(scene, obj)\n        elif pos == \"right\":\n            filtered = self.filterRight(scene, obj)\n        elif pos == \"front\":\n            filtered = self.filterFront(scene, obj)\n        elif pos == \"behind\":\n            filtered = self.filterBehind(scene, obj)\n\n        return filtered\n\n    ###########################################################################\n    #                           Counting questions                            #\n    ###########################################################################\n    def countAll(self):\n        self.currentGrp = deepcopy(self.scene)\n        self.groups.append(deepcopy(self.scene))\n        return len(self.scene)\n\n    def countOther(self):\n        others = self.getOther()\n        if len(others) > 0:\n            self.currentGrp = others\n            self.groups.append(others)\n        if len(others) == 1:\n            obj = others[0]\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    break\n            self.updateCurrentObj(obj)\n\n            self.updateVisited(obj)\n        return len(others)\n\n    def countAllGroup(self):\n        return len(self.currentGrp)\n\n    def countAttribute(self, attribute, updateCurrentObj=True):\n        filtered = self.filterAttribute(self.scene, attribute)\n        if len(filtered) == 0:\n            return 0\n        # Update the visited objects list\n        for _obj in filtered:\n            self.updateVisited(_obj)\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            self.updateIdentifier(obj, attribute)\n            self.updateVisited(obj)\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n            else:\n                if new:\n                    self.objs.append(obj)\n\n        self.groups.append(filtered)\n        self.currentGrp = filtered\n        return len(filtered)\n\n    def countAttributeGroup(self, attribute, updateCurrentObj=True):\n        filtered = self.filterAttribute(self.currentGrp, attribute)\n        if len(filtered) == 0:\n            return 0\n        # Update the visited objects list\n        for _obj in filtered:\n            self.updateVisited(_obj)\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            self.updateIdentifier(obj, attribute)\n            self.updateVisited(obj)\n\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n            else:\n                if new:\n                    self.objs.append(obj)\n\n        self.groups.append(filtered)\n        self.currentGrp = filtered\n        return len(filtered)\n\n    def countObjRelImm(self, pos, updateCurrentObj=True):\n        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n        if len(filtered) == 0:\n            return 0\n        # Update the visited objects list\n        for _obj in filtered:\n            self.updateVisited(_obj)\n\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n                self.uniqueObjFlag = True\n            else:\n                if new:\n                    self.objs.append(obj)\n        return len(filtered)\n\n    def countObjRelImm2(self, pos):\n        if self.uniqueObjFlag:\n            # del self.objs[-1]\n            self.updateCurrentObj(self.objs[-2])\n            self.uniqueObjFlag = False\n        return self.countObjRelImm(pos)\n\n    def countObjRelEarly(self, pos, earlyObjAttribute, updateCurrentObj=True):\n        for objEarly in reversed(self.objs):\n            if objEarly[\"identifier\"] is not None:\n                identifiers = objEarly[\"identifier\"].split(\"-\")\n                if earlyObjAttribute in identifiers:\n                    break\n            else:\n                continue\n        filtered = self.filterPosition(self.scene, objEarly, pos)\n        if len(filtered) == 0:\n            return 0\n        # Update the visited objects list\n        for _obj in filtered:\n            self.updateVisited(_obj)\n\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n            else:\n                if new:\n                    self.objs.append(obj)\n        else:\n            self.updateCurrentObj(objEarly)\n\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n        return len(filtered)\n\n    def countObjExcludeImm(self, attributeType, updateCurrentObj=True):\n        filtered = self.excludeAttribute(\n            self.scene, self.currentObj, attributeType)\n        if len(filtered) == 0:\n            return 0\n\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n            else:\n                if new:\n                    self.objs.append(obj)\n\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n        return len(filtered)\n\n    def countObjExcludeEarly(self, attributeType, earlyObjAttribute, updateCurrentObj=True):\n        for objEarly in reversed(self.objs):\n            if objEarly[\"identifier\"] is not None:\n                identifiers = objEarly[\"identifier\"].split(\"-\")\n                if earlyObjAttribute in identifiers:\n                    break\n            else:\n                continue\n\n        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n        if len(filtered) == 0:\n            return 0\n\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj = _obj\n                    new = False\n                    break\n            if updateCurrentObj:\n                self.updateCurrentObj(obj)\n            else:\n                if new:\n                    self.objs.append(obj)\n        else:\n            self.updateCurrentObj(objEarly)\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n        return len(filtered)\n\n    ###########################################################################\n    #                           Existence questions                           #\n    ###########################################################################\n\n    def existOther(self):\n        others = self.getOther()\n        numOther = len(others)\n        if numOther > 0:\n            self.currentGrp = others\n            self.groups.append(others)\n            for _obj in others:\n                self.updateVisited(_obj)\n        return \"yes\" if numOther > 0 else \"no\"\n\n    def existAttribute(self, attribute):\n        filtered = self.filterAttribute(self.scene, attribute)\n        numAttribute = len(filtered)\n        if numAttribute == 0:\n            return \"no\"\n\n        # Update the visited objects list\n        for _obj in filtered:\n            self.updateVisited(_obj)\n        if len(filtered) == 1:\n            obj = filtered[0]\n            new = True\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    self.updateIdentifier(_obj, attribute)\n                    new = False\n                    break\n            if new:\n                self.updateIdentifier(obj, attribute)\n                self.objs.append(obj)\n                # self.updateCurrentObj(obj)\n\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n        return \"yes\"\n\n    def existAttributeGroup(self, attribute):\n        numAttributeGrp = self.countAttributeGroup(\n            attribute, updateCurrentObj=False)\n        return \"yes\" if numAttributeGrp > 0 else \"no\"\n\n    def existObjRelImm(self, pos):\n        numObjs = self.countObjRelImm(pos, updateCurrentObj=False)\n        return \"yes\" if numObjs > 0 else \"no\"\n\n    def existObjRelEarly(self, pos, earlyObjAttribute):\n        numObjs = self.countObjRelEarly(\n            pos, earlyObjAttribute, updateCurrentObj=False)\n        return \"yes\" if numObjs > 0 else \"no\"\n\n    def existObjExcludeImm(self, attributeType):\n        numObjs = self.countObjExcludeImm(\n            attributeType, updateCurrentObj=False)\n        return \"yes\" if numObjs > 0 else \"no\"\n\n    def existObjExcludeEarly(self, attributeType, earlyObjAttribute):\n        for objEarly in reversed(self.objs):\n            if objEarly[\"identifier\"] is not None:\n                identifiers = objEarly[\"identifier\"].split(\"-\")\n                if earlyObjAttribute in identifiers:\n                    break\n            else:\n                continue\n\n        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n        numObjs = len(filtered)\n        if numObjs == 0:\n            return \"no\"\n        self.currentGrp = filtered\n        self.groups.append(filtered)\n        return \"yes\"\n\n    ###########################################################################\n    #                             Seek questions                              #\n    ###########################################################################\n\n    def seekAttrImm(self, attributeType):\n        assert attributeType in self.currentObj, \"Attributre <{}> is not valid\"\n        self.updateIdentifier(self.currentObj, self.currentObj[attributeType])\n        return self.currentObj[attributeType]\n\n    def seekAttributeEarly(self, attributeType, earlyObjAttribute):\n        for objEarly in reversed(self.objs):\n            if objEarly[\"identifier\"] is not None:\n                identifiers = objEarly[\"identifier\"].split(\"-\")\n                if earlyObjAttribute in identifiers:\n                    break\n            else:\n                continue\n        self.updateIdentifier(objEarly, objEarly[attributeType])\n        self.updateCurrentObj(objEarly)\n        self.updateVisited(objEarly)\n        return objEarly[attributeType]\n\n    def seekAttributeRelImm(self, attributeType, pos):\n        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n        if len(filtered) == 0:\n            return \"none\"\n        else:\n            # Get the closest object to slef.obj\n            if pos == \"left\":\n                filtered.sort(key=lambda x: x[\"position\"][0])\n                obj = filtered[-1]\n            elif pos == \"right\":\n                filtered.sort(key=lambda x: x[\"position\"][0])\n                obj = filtered[0]\n            elif pos == \"front\":\n                filtered.sort(key=lambda x: x[\"position\"][1])\n                obj = filtered[0]\n            elif pos == \"behind\":\n                filtered.sort(key=lambda x: x[\"position\"][1])\n                obj = filtered[-1]\n\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj[\"identifier\"] = _obj[\"identifier\"]\n                    break\n            self.updateIdentifier(obj, obj[attributeType])\n            self.updateCurrentObj(obj)\n            self.updateVisited(obj)\n            return obj[attributeType]\n\n    def seekAttributeRelEarly(self, attributeType, pos, earlyObjAttribute):\n        for objEarly in reversed(self.objs):\n            if objEarly[\"identifier\"] is not None:\n                identifiers = objEarly[\"identifier\"].split(\"-\")\n                if earlyObjAttribute in identifiers:\n                    break\n            else:\n                continue\n\n        filtered = self.filterPosition(self.scene, objEarly, pos)\n        if len(filtered) == 0:\n            return \"none\"\n        else:\n            # Get the closest object to slef.obj\n            if pos == \"left\":\n                filtered.sort(key=lambda x: x[\"position\"][0])\n                obj = filtered[-1]\n            elif pos == \"right\":\n                filtered.sort(key=lambda x: x[\"position\"][0])\n                obj = filtered[0]\n            elif pos == \"front\":\n                filtered.sort(key=lambda x: x[\"position\"][1])\n                obj = filtered[0]\n            elif pos == \"behind\":\n                filtered.sort(key=lambda x: x[\"position\"][1])\n                obj = filtered[-1]\n            for _obj in self.objs:\n                if _obj[\"id\"] == obj[\"id\"]:\n                    obj[\"identifier\"] = _obj[\"identifier\"]\n                    break\n            self.updateIdentifier(obj, obj[attributeType])\n            self.updateCurrentObj(obj)\n            self.updateVisited(obj)\n            return obj[attributeType]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.337746Z","iopub.execute_input":"2024-02-13T16:22:22.338013Z","iopub.status.idle":"2024-02-13T16:22:22.606224Z","shell.execute_reply.started":"2024-02-13T16:22:22.337991Z","shell.execute_reply":"2024-02-13T16:22:22.605216Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport torch\n#import utils_m","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.608086Z","iopub.execute_input":"2024-02-13T16:22:22.608456Z","iopub.status.idle":"2024-02-13T16:22:22.618187Z","shell.execute_reply.started":"2024-02-13T16:22:22.608427Z","shell.execute_reply":"2024-02-13T16:22:22.617410Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#!touch \"pkl-small/quastion-train\" res.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.619441Z","iopub.execute_input":"2024-02-13T16:22:22.619730Z","iopub.status.idle":"2024-02-13T16:22:22.625868Z","shell.execute_reply.started":"2024-02-13T16:22:22.619706Z","shell.execute_reply":"2024-02-13T16:22:22.625092Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class OptionsC():#changed optiopn class as Option_c to differentiate it with the one belong to question\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.initialized = False\n\n    def initialize(self):\n        self.parser.add_argument(\n            '--mode',\n            default=\"train\",#*** in the training mode.\n            # required=True,\n            type=str,\n            choices=['train', 'test'],\n            help='The mode of the experiment')\n\n        self.parser.add_argument(\n            '--run_dir',\n            \n            default=\"pkl-small/quastion-train\",#for saving the results of the small dataset\n            # required=True,\n            type=str,\n            help='The experiment directory')\n\n        self.parser.add_argument(\n            '--load_checkpoint_path',\n            \n            default='None',#*** training mode\n            type=str,\n            help='The path the the pretrained CaptionNet')\n\n        self.parser.add_argument(\n            '--res_path',\n            \n            default=\"pkl-small/quastion-train\",#for saving the results of the small dataset\n            # required=True,\n            type=str,\n            help='Path where to log the predicted caption programs')\n\n        self.parser.add_argument(\n            '--gpu_ids',\n            default='0',\n            type=str,\n            help='Id of the gpu to be used')\n\n        self.parser.add_argument(\n            '--seed',\n            default=42,\n            type=int,\n            help='The seed used in training')\n\n        self.parser.add_argument(\n            '--dataPathTr',\n            \n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/train_concat_half.h5\",\n            # required=True,\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n\n        self.parser.add_argument(\n            '--dataPathVal',\n            \n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/val_concat_half.h5\",\n            # required=True,\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n\n        self.parser.add_argument(\n            '--dataPathTest',\n            # required=True,\n            \n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/test_concat_75000.h5\",\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n\n        self.parser.add_argument(\n            '--vocabPath',\n            \n            default = \"/kaggle/input/nsvd-dataset/train_concat/vocab_output.json\", \n            # required=True,\n            type=str,\n            help='Path to the generated vocabulary')\n\n        self.parser.add_argument(\n            '--batch_size',\n            default=64,\n            type=int,\n            help='Batch size')\n\n        self.parser.add_argument(\n            '--num_workers',\n            default=0,\n            type=int,\n            help='Number of workers for loading')\n\n        self.parser.add_argument(\n            '--num_iters',\n            #default=5000,\n            default=TOTAL_ITER,\n            type=int,\n            help='Total number of iterations')\n\n        self.parser.add_argument(\n            '--display_every',\n            default=5,\n            type=int,\n            help='Display training information every N iterations')\n\n        self.parser.add_argument(\n            '--debug_every',\n            default=100,\n            type=int,\n            help='Display debug message every N iterations')\n\n        self.parser.add_argument(\n            '--validate_every',\n            default=VALID_EVE,\n            #default=200,\n            type=int,\n            help='Validate every N iterations')\n\n        self.parser.add_argument(\n            '--shuffle_data',\n            default=1,\n            type=int,\n            help='Activate to shuffle the training data')\n\n        self.parser.add_argument(\n            '--optim',\n            default='adam',\n            type=str,\n            help='The name of the optimizer to be used')\n\n        self.parser.add_argument(\n            '--lr',\n            default=1e-3, #A version\n            #default=1e-1,#just change to be synced with the OptionQ\n            type=float,\n            help='Base learning rate')\n\n        self.parser.add_argument(\n            '--betas',\n            default='0.9, 0.98',\n            type=str,\n            help='Adam optimizer\\'s betas')\n\n        self.parser.add_argument(\n            '--eps',\n            default='1e-9',\n            type=float,\n            help='Adam optimizer\\'s epsilon')\n\n        self.parser.add_argument(\n            '--lr_decay_marks',\n            default='50000, 55000',\n            type=str,\n            help='Learing rate decay marks')\n\n        self.parser.add_argument(\n            '--lr_decay_factor',\n            #default=0.5,\n            default=0.3,\n            type=float,\n            help='Learning rate decay factor')\n\n        self.parser.add_argument(\n            '--weight_decay',\n            default=1e-6, # the original value\n            #default=1e-2, # To reach to a better accuracy\n            type=float,\n            help='Weight decay')\n\n        self.parser.add_argument(\n            '--embedDim',\n            default=300,\n            type=int,\n            help='Embedding dimension')\n\n        self.parser.add_argument(\n            '--hiddenDim',\n            default=512,\n            type=int,\n            help='LSTM hidden dimension')\n\n        self.parser.add_argument(\n            '--numLayers',\n            #default=2,\n            default=1,#to sync with the ques train\n            type=int,\n            help='Number of hidden LSTM layers')\n\n        self.parser.add_argument(\n            '--dropout',\n            #default=0.1, #original value\n            default=0.2, # to make it sync with ques_train\n            type=float,\n            help='Dropout value')\n\n        self.parser.add_argument(\n            '--multiHead',\n            default=8,\n            type=int,\n            help='Number of attention heads')\n\n        self.parser.add_argument(\n            '--hiddenSizeHead',\n            default=64,\n            type=int,\n            help='Dimension of each attention head')\n\n        self.parser.add_argument(\n            '--FeedForwardSize',\n            default=2048,\n            type=int,\n            help='Dimension of the feed forward layer')\n\n        self.parser.add_argument(\n            '--FlatMLPSize',\n            default=512,\n            type=int,\n            help='MLP flatten size')\n\n        self.parser.add_argument(\n            '--FlatGlimpses',\n            default=1,\n            type=int,\n            help='Number of flatten glimpses')\n\n        self.parser.add_argument(\n            '--FlatOutSize',\n            default=512,\n            type=int,\n            help='Final attention reduction dimension')\n\n        self.parser.add_argument(\n            '--layers',\n            default=6,#A'original\n            #default=8,#to sync with questrain\n            type=int,\n            help='Number of self attention layers')\n\n        self.parser.add_argument(\n            '--bidirectional',\n            default=1,\n            type=int,\n            help='Activate to use bidirectional LSTMs')\n\n        self.initialized = True\n\n    def parse(self):\n        # initialize parser\n        if not self.initialized:\n            self.initialize()\n       # self.opts = self.parser.parse_args()\n        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n\n        # parse gpu id list\n        str_gpu_ids = self.opts.gpu_ids.split(',')\n        self.opts.gpu_ids = []\n        for str_id in str_gpu_ids:\n            if str_id.isdigit() and int(str_id) >= 0:\n                self.opts.gpu_ids.append(int(str_id))\n        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n        else:\n            print('\\n[INFO] Using cpu ...')\n            self.opts.gpu_ids = []\n\n        # parse the optimizer's betas and lr decay marks\n        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n        for i in range(1, len(lr_decay_marks)):\n            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n        self.opts.lr_decay_marks = lr_decay_marks\n\n        # print and save options\n        args = vars(self.opts)\n        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n        # for k, v in args.items():\n            # print('%s: %s' % (str(k), str(v)))\n\n        if not os.path.isdir(self.opts.run_dir):\n            os.makedirs(self.opts.run_dir)\n        filename = 'opts_c.txt'\n        file_path = os.path.join(self.opts.run_dir, filename)\n        with open(file_path, 'wt') as fout:\n            fout.write('| options\\n')\n            for k, v in sorted(args.items()):\n                fout.write('%s: %s\\n' % (str(k), str(v)))\n        return self.opts\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.627006Z","iopub.execute_input":"2024-02-13T16:22:22.627294Z","iopub.status.idle":"2024-02-13T16:22:22.661015Z","shell.execute_reply.started":"2024-02-13T16:22:22.627253Z","shell.execute_reply":"2024-02-13T16:22:22.660062Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import torch\nimport math\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.663804Z","iopub.execute_input":"2024-02-13T16:22:22.664131Z","iopub.status.idle":"2024-02-13T16:22:22.672691Z","shell.execute_reply.started":"2024-02-13T16:22:22.664106Z","shell.execute_reply":"2024-02-13T16:22:22.671584Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class FC(nn.Module):\n    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n        super(FC, self).__init__()\n        self.dropout_r = dropout_r\n        self.use_relu = use_relu\n\n        self.linear = nn.Linear(in_size, out_size)\n\n        if use_relu:\n            self.relu = nn.ReLU(inplace=True)\n\n        if dropout_r > 0:\n            self.dropout = nn.Dropout(dropout_r)\n\n    def forward(self, x):\n        x = self.linear(x)\n\n        if self.use_relu:\n            x = self.relu(x)\n\n        if self.dropout_r > 0:\n            x = self.dropout(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.673781Z","iopub.execute_input":"2024-02-13T16:22:22.674084Z","iopub.status.idle":"2024-02-13T16:22:22.682402Z","shell.execute_reply.started":"2024-02-13T16:22:22.674060Z","shell.execute_reply":"2024-02-13T16:22:22.681514Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n        super(MLP, self).__init__()\n\n        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n        self.linear = nn.Linear(mid_size, out_size)\n\n    def forward(self, x):\n        return self.linear(self.fc(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.683611Z","iopub.execute_input":"2024-02-13T16:22:22.683872Z","iopub.status.idle":"2024-02-13T16:22:22.694308Z","shell.execute_reply.started":"2024-02-13T16:22:22.683850Z","shell.execute_reply":"2024-02-13T16:22:22.693225Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, size, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.eps = eps\n\n        self.a_2 = nn.Parameter(torch.ones(size))\n        self.b_2 = nn.Parameter(torch.zeros(size))\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n\n        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.695639Z","iopub.execute_input":"2024-02-13T16:22:22.695995Z","iopub.status.idle":"2024-02-13T16:22:22.705022Z","shell.execute_reply.started":"2024-02-13T16:22:22.695966Z","shell.execute_reply":"2024-02-13T16:22:22.703984Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class MHAtt(nn.Module):\n    def __init__(self, opts):\n        super(MHAtt, self).__init__()\n        self.opts = opts\n\n        self.linear_v = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_k = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_q = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n        self.linear_merge = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n\n        self.dropout = nn.Dropout(opts.dropout)\n\n    def forward(self, v, k, q, mask):\n        n_batches = q.size(0)\n\n        v = self.linear_v(v).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        k = self.linear_k(k).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        q = self.linear_q(q).view(\n            n_batches,\n            -1,\n            self.opts.multiHead,\n            self.opts.hiddenSizeHead\n        ).transpose(1, 2)\n\n        atted = self.att(v, k, q, mask)\n        atted = atted.transpose(1, 2).contiguous().view(\n            n_batches,\n            -1,\n            self.opts.hiddenDim\n        )\n\n        atted = self.linear_merge(atted)\n\n        return atted\n\n    def att(self, value, key, query, mask):\n        d_k = query.size(-1)\n\n        scores = torch.matmul(\n            query, key.transpose(-2, -1)\n        ) / math.sqrt(d_k)\n\n        if mask is not None:\n            scores = scores.masked_fill(mask, -1e9)\n\n        att_map = F.softmax(scores, dim=-1)\n        att_map = self.dropout(att_map)\n\n        return torch.matmul(att_map, value)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.706554Z","iopub.execute_input":"2024-02-13T16:22:22.706907Z","iopub.status.idle":"2024-02-13T16:22:22.722332Z","shell.execute_reply.started":"2024-02-13T16:22:22.706876Z","shell.execute_reply":"2024-02-13T16:22:22.721261Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self, opts):\n        super(FFN, self).__init__()\n\n        self.mlp = MLP(\n            in_size=opts.hiddenDim,\n            mid_size=opts.FeedForwardSize,\n            out_size=opts.hiddenDim,\n            dropout_r=opts.dropout,\n            use_relu=True\n        )\n\n    def forward(self, x):\n        return self.mlp(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.723562Z","iopub.execute_input":"2024-02-13T16:22:22.723879Z","iopub.status.idle":"2024-02-13T16:22:22.733309Z","shell.execute_reply.started":"2024-02-13T16:22:22.723854Z","shell.execute_reply":"2024-02-13T16:22:22.732235Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"class SA(nn.Module):\n    def __init__(self, opts):\n        super(SA, self).__init__()\n        self.mhatt = MHAtt(opts)\n        self.ffn = FFN(opts)\n\n        self.dropout1 = nn.Dropout(opts.dropout)\n        self.norm1 = LayerNorm(opts.hiddenDim)\n\n        self.dropout2 = nn.Dropout(opts.dropout)\n        self.norm2 = LayerNorm(opts.hiddenDim)\n\n    def forward(self, x, x_mask):\n        x = self.norm1(x + self.dropout1(\n            self.mhatt(x, x, x, x_mask)\n        ))\n\n        x = self.norm2(x + self.dropout2(\n            self.ffn(x)\n        ))\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.734585Z","iopub.execute_input":"2024-02-13T16:22:22.734911Z","iopub.status.idle":"2024-02-13T16:22:22.742957Z","shell.execute_reply.started":"2024-02-13T16:22:22.734887Z","shell.execute_reply":"2024-02-13T16:22:22.741960Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class AttFlat(nn.Module):\n    def __init__(self, opts):\n        super(AttFlat, self).__init__()\n        self.opts = opts\n\n        self.mlp = MLP(\n            in_size=opts.hiddenDim,\n            mid_size=opts.FlatMLPSize,\n            out_size=opts.FlatGlimpses,\n            dropout_r=opts.dropout,\n            use_relu=True\n        )\n        # FLAT_GLIMPSES = 1\n        self.linear_merge = nn.Linear(\n            opts.hiddenDim * opts.FlatGlimpses,\n            opts.FlatOutSize\n        )\n\n    def forward(self, x, x_mask):\n        att = self.mlp(x)\n        att = att.masked_fill(\n            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n            -1e9\n        )\n        att = F.softmax(att, dim=1)\n\n        att_list = []\n        for i in range(self.opts.FlatGlimpses):\n            att_list.append(\n                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n            )\n\n        x_atted = torch.cat(att_list, dim=1)\n        x_atted = self.linear_merge(x_atted)\n\n        return x_atted","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.744136Z","iopub.execute_input":"2024-02-13T16:22:22.744877Z","iopub.status.idle":"2024-02-13T16:22:22.754106Z","shell.execute_reply.started":"2024-02-13T16:22:22.744845Z","shell.execute_reply":"2024-02-13T16:22:22.752923Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, opts, textVocabSize):\n        super(Encoder, self).__init__()\n\n        self.embedding_Cap = nn.Embedding(textVocabSize, opts.embedDim)\n        bidirectional = opts.bidirectional > 0\n        self.lstmC = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=opts.hiddenDim,\n            num_layers=opts.numLayers,\n            batch_first=True,\n            bidirectional=bidirectional\n        )\n\n\n        self.embedding_Quest = nn.Embedding(textVocabSize, opts.embedDim)\n        self.lstmQ = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=opts.hiddenDim,\n            num_layers=opts.numLayers,\n            bidirectional=bidirectional,\n            batch_first=True\n        )\n\n        self.lstmH = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=opts.hiddenDim,\n            num_layers=opts.numLayers,\n            bidirectional=bidirectional,\n            batch_first=True)\n#++++++++++++++++++++++++++++++++++++++++++++++++++++++\n        if bidirectional:\n            opts.hiddenDim *= 2\n            opts.hiddenSizeHead *= 2\n            opts.FlatOutSize *= 2\n\n        self.attCap = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n        self.attFlatCap = AttFlat(opts)\n        self.fc_Cap = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n#++++++++++++++++++++++++++++++++++++++++++++++++++++++\n        self.attQues = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n        self.attHist = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n\n        self.attFlatQuest = AttFlat(opts)\n        self.fc_Quest = nn.Linear(2 * opts.hiddenDim, opts.hiddenDim)\n\n\n    def capForward(self, cap, hist=None):\n        capMask = self.make_mask(cap.unsqueeze(2))\n        cap = self.embedding_Cap(cap)\n        cap, (_, _) = self.lstmC(cap)\n        capO = cap.detach().clone()\n\n        for attC in self.attCap:\n            cap = attC(cap, capMask)\n        # (batchSize, 512)\n        cap = self.attFlatCap(cap, capMask)\n        encOut = self.fc_Cap(cap)\n        return encOut, capO\n    \n    def questForward(self, quest, hist):\n        questMask = self.make_mask(quest.unsqueeze(2))\n        histMask = self.make_mask(hist.unsqueeze(2))\n\n        # quest = F.tanh(self.embedding(quest))\n        quest = self.embedding_Quest(quest)\n\n        quest, (_, _) = self.lstmQ(quest)\n        questO = quest.detach().clone()\n\n        hist = self.embedding_Quest(hist)\n        hist, (_, _) = self.lstmH(hist)\n\n        for attQ, attH in zip(self.attQues, self.attHist):\n            quest = attQ(quest, questMask)\n            hist = attH(hist, histMask)\n        # (batchSize, 512)\n        quest = self.attFlatQuest(quest, questMask)\n\n        # hist: (batchSize, length, 512)\n        attWeights = torch.sum(torch.mul(hist, quest.unsqueeze(1)), -1)\n        attWeights = torch.softmax(attWeights, -1)\n        hist = torch.sum(torch.mul(hist, attWeights.unsqueeze(2)), 1)\n        encOut = self.fc_Quest(torch.cat([quest, hist], -1))\n\n        return encOut, questO\n\n    def forward(self, cap, quest, hist):\n        capEncOut, capO = self.capForward(cap)\n        questEncOut, questO = self.questForward(quest, hist)\n\n        return capEncOut, questEncOut, capO, questO\n\n    # Masking\n    def make_mask(self, feature):\n        return (torch.sum(\n            torch.abs(feature),\n            dim=-1\n        ) == 0).unsqueeze(1).unsqueeze(2)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.755552Z","iopub.execute_input":"2024-02-13T16:22:22.755881Z","iopub.status.idle":"2024-02-13T16:22:22.777745Z","shell.execute_reply.started":"2024-02-13T16:22:22.755857Z","shell.execute_reply":"2024-02-13T16:22:22.776867Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#*** ->for qiansu: copy and paste the whole class\nclass Decoder(nn.Module):\n    def __init__(self, opts, progVocabSize, maxLen, startID=1, endID=2):\n        super(Decoder, self).__init__()\n        self.numLayers = opts.numLayers\n        self.bidirectional = opts.bidirectional > 0\n        self.maxLen = maxLen\n        self.startID = startID\n        self.endID = endID\n\n        self.embedding = nn.Embedding(progVocabSize, opts.embedDim)\n        self.lstmProg = nn.LSTM(\n            input_size=opts.embedDim,\n            hidden_size=2*opts.hiddenDim if self.bidirectional else opts.hiddenDim,\n            num_layers=opts.numLayers,\n            batch_first=True,\n            #bidirectional=self.bidirectional,#???????\n        )\n        hiddenDim = opts.hiddenDim\n        if self.bidirectional:\n            hiddenDim *= 2\n\n        self.fcAtt = nn.Linear(2*hiddenDim, hiddenDim)\n        self.fcOut = nn.Linear(hiddenDim, progVocabSize)\n\n    def initPrgHidden(self, encOut):\n        hidden = [encOut for _ in range(self.numLayers)]\n        hidden = torch.stack(hidden, 0).contiguous()\n        return hidden, hidden\n\n    def forwardStep(self, prog, progH, questO):\n        #**********************************************our error relates to this prog cause in our case it is not acting as tensor anymore.\n        batchSize = prog.size(0)\n        inputDim = questO.size(1)\n        prog = self.embedding(prog)\n        outProg, progH = self.lstmProg(prog, progH)\n\n        att = torch.bmm(outProg, questO.transpose(1, 2))\n        att = F.softmax(att.view(-1, inputDim), 1).view(batchSize, -1, inputDim)\n        context = torch.bmm(att, questO)\n        # (batchSize, progLength, hiddenDim)\n        out = F.tanh(self.fcAtt(torch.cat([outProg, context], dim=-1)))\n\n        # (batchSize, progLength, progVocabSize)\n        out = self.fcOut(out)\n        predSoftmax = F.log_softmax(out, 2)\n        return predSoftmax, progH\n\n    def forward(self, prog, encOut, questO):\n        progH = self.initPrgHidden(encOut)\n        predSoftmax, progH = self.forwardStep(prog, progH, questO)\n\n        return predSoftmax, progH\n\n    def sample(self, encOut, questO):\n        batchSize = encOut.size(0)\n        cudaFlag = encOut.is_cuda\n        progH = self.initPrgHidden(encOut)\n        # prog = progCopy[:, 0:3]\n        prog = torch.LongTensor(batchSize, 1).fill_(self.startID)\n        # prog = torch.cat((progStart, progEnd), -1)\n        if cudaFlag:\n            prog = prog.cuda()\n        outputLogProbs = []\n        outputTokens = []\n     \n\n        def decode(i, output):\n            tokens = output.topk(1, dim=-1)[1].view(batchSize, -1)\n            #print(\"This is inside of the decode local function and this is the tockens=\", tokens)\n            return tokens\n\n        for i in range(self.maxLen):\n            predSoftmax, progH = self.forwardStep(prog, progH, questO)\n            prog = decode(i, predSoftmax)\n            prog_flat = list(chain(*prog))\n            flat_list = [item.item() for item in prog_flat]\n\n        #****************************************my modification\n            outputTokens.append(flat_list)#new\n       #print(\"lets check what is inside outputTocken\", outputTokens)    \n       # print(\"-----------------------------------------\")\n        return outputTokens, outputLogProbs\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.782705Z","iopub.execute_input":"2024-02-13T16:22:22.783008Z","iopub.status.idle":"2024-02-13T16:22:22.801902Z","shell.execute_reply.started":"2024-02-13T16:22:22.782986Z","shell.execute_reply":"2024-02-13T16:22:22.800840Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class SeqToSeqUnified(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(SeqToSeqUnified, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, cap, quest, questProg, capProg, hist):\n        capEncOut, questEncOut, capO, questO = self.encoder(cap, quest, hist)\n\n        # unitEncOut = torch.cat((capEncOut, questEncOut), dim = 0)\n        #++++++++++++++++++++++++\n        #print(\"The shape of the capProg\", capProg.shape)\n        #print(\"The shape of the questProg\", questProg.shape)\n        #--------------------------\n        #capProg = capProg[:, :-1]\n        # unitO = torch.cat((capO, questO), dim = 0)\n        # unitProg = torch.cat((capProg, questProg), dim = 0)\n\n        # predSoftmax, progHC = self.decoder(unitProg, unitEncOut, unitO)\n        predSoftmaxCap, progHCCap = self.decoder(capProg, capEncOut, capO)\n        predSoftmaxQuest, progHCQuest = self.decoder(questProg, questEncOut, questO)\n        # [changed]\n        predSoftmax = torch.cat((predSoftmaxCap, predSoftmaxQuest), dim = 1)\n        \n        # predSoftmax = torch.cat((predSoftmaxCap, predSoftmaxQuest), dim = 0)\n        return predSoftmax, progHCCap\n\n    def sample(self, cap, quest, hist):\n        with torch.no_grad():\n            capEncOut, questEncOut, capO, questO  = self.encoder(cap, quest, hist)\n\n            outputTokensC, outputLogProbsC = self.decoder.sample(capEncOut, capO)\n            outputTokensQ, outputLogProbsQ = self.decoder.sample(questEncOut, questO)\n            \n        outputTokens_t_c = [[row[i] for row in outputTokensC] for i in range(len(outputTokensC[0]))]\n        outputTokens_t_q = [[row[i] for row in outputTokensQ] for i in range(len(outputTokensQ[0]))]\n\n        outputTokens_t = torch.cat((torch.tensor(outputTokens_t_c), torch.tensor(outputTokens_t_q)), dim = 1)\n\n        return outputTokens_t","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.803194Z","iopub.execute_input":"2024-02-13T16:22:22.803569Z","iopub.status.idle":"2024-02-13T16:22:22.816660Z","shell.execute_reply.started":"2024-02-13T16:22:22.803545Z","shell.execute_reply":"2024-02-13T16:22:22.815703Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as Optim\nfrom itertools import chain #***","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.817758Z","iopub.execute_input":"2024-02-13T16:22:22.818059Z","iopub.status.idle":"2024-02-13T16:22:22.826387Z","shell.execute_reply.started":"2024-02-13T16:22:22.818036Z","shell.execute_reply":"2024-02-13T16:22:22.825547Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class WarmupOptimizer(object):\n    def __init__(self, lr_base, optimizer, data_size, batch_size):\n        self.optimizer = optimizer\n        self._step = 0\n        self.lr_base = lr_base\n        self._rate = 0\n        self.data_size = data_size\n        self.batch_size = batch_size\n\n    def step(self):\n        self._step += 1\n\n        rate = self.rate()\n        for p in self.optimizer.param_groups:\n            p['lr'] = rate\n        self._rate = rate\n\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def rate(self, step=None):\n        if step is None:\n            step = self._step\n\n        if step <= int(self.data_size / self.batch_size * 1):\n            r = self.lr_base * 1/2.\n        else:\n            r = self.lr_base\n\n        return r\n\n\ndef get_optim(opts, model, data_size, lr_base=None):\n    if lr_base is None:\n        lr_base = opts.lr\n\n    if opts.optim == 'adam':\n        optim = Optim.Adam(\n                filter(lambda p: p.requires_grad, model.parameters()),\n                lr=0,\n                betas=opts.betas,\n                eps=opts.eps,\n\n            )\n    elif opts.optim == 'rmsprop':\n        optim = Optim.RMSprop(\n                filter(lambda p: p.requires_grad, model.parameters()),\n                lr=0,\n                eps=opts.eps,\n                weight_decay=opts.weight_decay\n            )\n    else:\n        raise ValueError('{} optimizer is not supported'.fromat(opts.optim))\n    return WarmupOptimizer(\n        lr_base,\n        optim,\n        data_size,\n        opts.batch_size\n    )\n\ndef adjust_lr(optim, decay_r):\n    optim.lr_base *= decay_r\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.827644Z","iopub.execute_input":"2024-02-13T16:22:22.828007Z","iopub.status.idle":"2024-02-13T16:22:22.844288Z","shell.execute_reply.started":"2024-02-13T16:22:22.827973Z","shell.execute_reply":"2024-02-13T16:22:22.843055Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\n#import utils_m\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.848430Z","iopub.execute_input":"2024-02-13T16:22:22.848799Z","iopub.status.idle":"2024-02-13T16:22:22.853947Z","shell.execute_reply.started":"2024-02-13T16:22:22.848765Z","shell.execute_reply":"2024-02-13T16:22:22.852723Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class OptionsQ():#changed optiopn class as Option_q to differentiate it with the one belong to caption\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.initialized = False\n        \n\n    def initialize(self):\n        self.parser.add_argument(\n            '--mode',\n            #required=True,\n            default='test_with_gt',#***-> this is for train-concat and train-stack\n            type=str,\n            help='The mode of the experiment')\n        self.parser.add_argument(\n            '--type',\n            default= 'q',\n            help='The encoder type is caption encoder.'\n        )\n\n        self.parser.add_argument(\n            '--run_dir',\n            default = \"/kaggle/working/\", \n            type=str,\n            help='The experiment directory')\n        #***\n        self.parser.add_argument(\n            '--useCuda',\n            default=1,\n            type=int,\n            help='hahahaha')\n         #***\n        self.parser.add_argument(\n            '--text_log_dir',\n            default=\"pkl-small/quastion-train\",#for saving the results of the small dataset\n            type=str,\n            help='File to save the logged text')\n\n        self.parser.add_argument(\n            '--questionNetPath',\n            default=\"None\",#fixed this it should have not been None.\n            type=str,\n            help='Path to the pretrained QuestionNet that will be used for testing.')\n        #*********\n        self.parser.add_argument(\n            '--trainedUnifiedNetPath',\n            default = \"/kaggle/input/nsvd-dataset/ckpt_iter_50.0_100.pkl\",\n            type=str,\n            help='Path to the pretrained trainedUnifiedNetPath that will be used for testing.')\n        #*********\n\n        self.parser.add_argument(\n            '--captionNetPath',\n            default= 'None',\n            type=str,\n            help='Path to the pretrained CaptionNet that will be used for testing.')\n\n        self.parser.add_argument(\n            '--dialogLen',\n            default=10,\n            type=int,\n            help='Length of the dialogs to be used for testing. We used 10, 15, and 20 in our experiments.')\n\n        self.parser.add_argument(\n            '--last_n_rounds',\n            default=10,\n            type=int,\n            help='Number of the last rounds to consider in the history. We used 1, 2, 3, 4, and 10 in our experiments. ')\n\n        self.parser.add_argument(\n            '--encoderType',\n            #required=True,\n            default=1,#***-> this is for question-concat\n            #default= 2, #*** -> this one is for question-stack\n            type=int,\n            choices=[1, 2],\n            help='Type of the encoder: 1 --> Concat, 2 --> Stack')\n\n        self.parser.add_argument(\n            '--load_checkpoint_path',\n            default='None',\n            type=str,\n            help='Path to a QestionNet checkpoint path to resume training')\n\n        self.parser.add_argument(\n            '--gpu_ids',\n            default='0',\n            type=str,\n            help='Id of the gpu to be used')\n\n        self.parser.add_argument(\n            '--seed',\n            default=42,\n            type=int,\n            help='The seed used in training')\n\n        self.parser.add_argument(\n            '--dataPathTr',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/train_concat_half.h5\", \n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n\n        self.parser.add_argument(\n            '--dataPathVal',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/val_concat_half.h5\", \n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n\n        self.parser.add_argument(\n            '--dataPathTest',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/test_concat_75000.h5\",\n            type=str,\n            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n\n        self.parser.add_argument(\n            '--scenesPath',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/data/CLEVR_scenes_test.json\", \n            type=str,\n            help='Path to the derendered clevr-dialog scenes')\n\n        self.parser.add_argument(\n            '--vocabPath',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/train_concat/vocab_output.json\", \n            type=str,\n            help='Path to the generated vocabulary')\n        \n        self.parser.add_argument(\n            '--vocabTestPath',\n            #required=True,\n            default = \"/kaggle/input/nsvd-dataset/test_concat/vocab_output.json\",\n            type=str,\n            help='Path to the generated vocabulary')\n\n        self.parser.add_argument(\n            '--batch_size',\n            default=64,\n            type=int,\n            help='Batch size')\n\n        self.parser.add_argument(\n            '--countFirstFailueRound',\n            default=0,\n            type=int,\n            help='If activated, we count the first failure round')\n\n        self.parser.add_argument(\n            '--maxSamples',\n            default=-1,\n            type=int,\n            help='Maximum number of training samples')\n\n        self.parser.add_argument(\n            '--num_workers',\n            default=0,\n            type=int,\n            help='Number of workers for loading')\n\n        self.parser.add_argument(\n            '--num_iters',\n            default=TOTAL_ITER,\n            type=int,\n            help='Total number of iterations')\n\n        self.parser.add_argument(\n            '--display_every',\n            default=5,\n            type=int,\n            help='Display training information every N iterations')\n\n        self.parser.add_argument(\n            '--validate_every',\n            default=VALID_EVE,\n            #default=200,\n            type=int,\n            help='Validate every N iterations')\n\n        self.parser.add_argument(\n            '--shuffle_data',\n            default=1,\n            type=int,\n            help='Activate to shuffle the training data')\n\n        self.parser.add_argument(\n            '--optim',\n            default='adam',\n            type=str,\n            help='The name of the optimizer to be used')\n\n        self.parser.add_argument(\n            '--lr',\n            default=1e-3,\n            #default=1e-1, # to reach 51\n            type=float,\n            help='Base learning rate')\n\n        self.parser.add_argument(\n            '--betas',\n            default='0.9, 0.98',\n            type=str,\n            help='Adam optimizer\\'s betas')\n\n        self.parser.add_argument(\n            '--eps',\n            default='1e-9',\n            type=float,\n            help='Adam optimizer\\'s epsilon')\n\n        self.parser.add_argument(\n            '--lr_decay_marks',\n            default='50000, 55000',\n            type=str,\n            help='Learing rate decay marks')\n\n        self.parser.add_argument(\n            '--lr_decay_factor',\n            #default=0.5,\n            default=0.3, #just trying\n            type=float,\n            help='Learning rate decay factor')\n\n        self.parser.add_argument(\n            '--weight_decay',\n            default=1e-6,#original\n            #default=1e-2,#for reaching more than 51.72 pr:1e-5\n            type=float,\n            help='Weight decay')\n\n        self.parser.add_argument(\n            '--embedDim',\n            default=300,\n            type=int,\n            help='Embedding dimension')\n\n        self.parser.add_argument(\n            '--hiddenDim',\n            default=512,\n            type=int,\n            help='LSTM hidden dimension')\n\n        self.parser.add_argument(\n            '--numLayers',\n            default=2,\n            # default=1,\n            type=int,\n            help='Number of hidden LSTM layers')\n\n        self.parser.add_argument(\n            '--dropout',\n            default=0.1,\n            # default=0.2,\n            type=float,\n            help='Dropout value')\n\n        self.parser.add_argument(\n            '--multiHead',\n            default=8,\n            type=int,\n            help='Number of attention heads')\n\n        self.parser.add_argument(\n            '--hiddenSizeHead',\n            default=64,\n            type=int,\n            help='Dimension of each attention head')\n\n        self.parser.add_argument(\n            '--FeedForwardSize',\n            default=2048,\n            type=int,\n            help='Dimension of the feed forward layer')\n\n        self.parser.add_argument(\n            '--FlatMLPSize',\n            default=512,\n            type=int,\n            help='MLP flatten size')\n\n        self.parser.add_argument(\n            '--FlatGlimpses',\n            default=1,\n            type=int,\n            help='Number of flatten glimpses')\n\n        self.parser.add_argument(\n            '--FlatOutSize',\n            default=512,\n            type=int,\n            help='Final attention reduction dimension')\n\n        self.parser.add_argument(\n            '--layers',\n            default=6,\n            #default=8, #to reach more than 51\n            type=int,\n            help='Number of self attention layers')\n\n        self.parser.add_argument(\n            '--bidirectional',\n            default=1,\n            type=int,\n            help='Activate to use bidirectional LSTMs')\n\n        self.initialized = True\n\n    def parse(self):\n        # initialize parser\n        if not self.initialized:\n            self.initialize()\n        #self.opts = self.parser.parse_args()#***\n        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n        # parse gpu id list\n        str_gpu_ids = self.opts.gpu_ids.split(',')\n        self.opts.gpu_ids = []\n        for str_id in str_gpu_ids:\n            if str_id.isdigit() and int(str_id) >= 0:\n                self.opts.gpu_ids.append(int(str_id))\n        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n            print('\\n[INFO] Using {} CUDA device(s) ...'.format(\n                len(self.opts.gpu_ids)))\n        else:\n            print('\\n[INFO] Using cpu ...')\n            self.opts.gpu_ids = []\n\n        # parse the optimizer's betas and lr decay marks\n        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n        for i in range(1, len(lr_decay_marks)):\n            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n        self.opts.lr_decay_marks = lr_decay_marks\n\n        # print and save options\n        args = vars(self.opts)\n        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n        # for k, v in args.items():\n            # print('%s: %s' % (str(k), str(v)))\n\n        if not os.path.isdir(self.opts.run_dir):\n            os.makedirs(self.opts.run_dir)\n        filename = 'opts.txt'\n        file_path = os.path.join(self.opts.run_dir, filename)\n        with open(file_path, 'wt') as fout:\n            fout.write('| options\\n')\n            for k, v in sorted(args.items()):\n                fout.write('%s: %s\\n' % (str(k), str(v)))\n        return self.opts\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.855676Z","iopub.execute_input":"2024-02-13T16:22:22.855972Z","iopub.status.idle":"2024-02-13T16:22:22.909068Z","shell.execute_reply.started":"2024-02-13T16:22:22.855948Z","shell.execute_reply":"2024-02-13T16:22:22.907646Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport json, torch, pickle, copy, time\nimport numpy as np\nimport argparse\nimport torch.nn as nn\nimport torch.utils.data as Data\nfrom tensorboardX import SummaryWriter\nfrom copy import deepcopy\n#from clevrDialog_dataset import ClevrDialogQuestionDataset\nimport pickle\nfrom tqdm import tqdm\n\n#sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n#from executor.symbolic_executor import SymbolicExecutorClevr, SymbolicExecutorMinecraft\n#from models import SeqToSeqQ, QuestEncoder_1, QuestEncoder_2, Decoder, CaptionEncoder, SeqToSeqC\n#from optim import get_optim, adjust_lr\n#from options_caption_parser import Options as OptionsC\n#from options_question_parser import Options as OptionsQ","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.910752Z","iopub.execute_input":"2024-02-13T16:22:22.911360Z","iopub.status.idle":"2024-02-13T16:22:22.918611Z","shell.execute_reply.started":"2024-02-13T16:22:22.911325Z","shell.execute_reply":"2024-02-13T16:22:22.917736Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"class Execution:\n    def __init__(self, optsQ):\n        self.opts_Q = deepcopy(optsQ)\n        if self.opts_Q.useCuda > 0 and torch.cuda.is_available():\n            self.device = torch.device(\"cuda:0\")\n            print(\"[INFO] Using GPU {} ...\".format(torch.cuda.get_device_name(0)))\n        else:\n            print(\"[INFO] Using CPU ...\")\n            self.device = torch.device(\"cpu\")\n\n        self.loss_fn = torch.nn.NLLLoss().to(self.device)\n\n        print(\"[INFO] Loading dataset ...\")\n\n        self.datasetTr = ClevrDialogUnifiedDataset(\n            self.opts_Q.dataPathTr, self.opts_Q.vocabPath, \"train\", \"All tr data\")\n        self.datasetVal = ClevrDialogUnifiedDataset(\n            self.opts_Q.dataPathVal, self.opts_Q.vocabPath, \"val\", \"All val data\", train=False)\n        self.datasetTest = ClevrDialogUnifiedDataset(\n            self.opts_Q.dataPathTest, self.opts_Q.vocabTestPath, \"test\", \"All val data\", train=False)\n           \n\n        self.unitNet = constructNet(\n            self.opts_Q,\n            self.datasetTr.lenVocabText,\n            self.datasetTr.lenVocabProg,\n            self.datasetTr.maxLenProg,\n        )\n\n        # TODO: add argument \"trainedUnifiedNetPath\"\n        '''\n        if os.path.isfile(self.opts_Q.trainedUnifiedNetPath):\n            print('Loading CaptionNet from {}'.format(self.opts_Q.trainedUnifiedNetPath))\n            state_dict = torch.load(self.opts_Q.trainedUnifiedNetPath)['state_dict']\n            self.unitNet.load_state_dict(state_dict)'''\n\n        self.unitNet.to(self.device)\n\n        # if os.path.isfile(self.opts_Q.load_checkpoint_path):\n        #     print('Loading questNet from {}'.format(optsQ.load_checkpoint_path))\n        #     state_dict = torch.load(self.opts_Q.load_checkpoint_path)['state_dict']\n        #     self.questNet.load_state_dict(state_dict)\n        total_params_curr = sum(p.numel() for p in self.unitNet.parameters() if p.requires_grad)\n        print(\"The quest encoder has {} trainable parameters\".format(total_params_curr))\n\n        if \"minecraft\" in self.opts_Q.scenesPath:\n            self.symbolicExecutor = SymbolicExecutorMinecraft(self.opts_Q.scenesPath)\n        else:\n            self.symbolicExecutor = SymbolicExecutorClevr(self.opts_Q.scenesPath)\n\n        tb_path = os.path.join(self.opts_Q.run_dir, \"tb_logdir\")\n        if not os.path.isdir(tb_path):\n            os.makedirs(tb_path)\n\n        self.ckpt_path = os.path.join(self.opts_Q.run_dir, \"ckpt_dir\")\n        if not os.path.isdir(self.ckpt_path):\n            os.makedirs(self.ckpt_path)\n        if not os.path.isdir(self.opts_Q.text_log_dir):\n            os.makedirs(self.opts_Q.text_log_dir)\n\n        self.writer = SummaryWriter(tb_path)\n        self.iter_val = 0\n\n        #if os.path.isfile(self.opts_Q.dependenciesPath):\n           # with open(self.opts_Q.dependenciesPath, \"rb\") as f:\n                #self.dependencies = pickle.load(f)\n\n \n\n    # Evaluation\n    def eval_with_gt(self):\n        # Define the multi-gpu training if needed\n        all_pred_answers = []\n        all_gt_answers = []\n        all_quest_types = []\n        all_penalties = []\n        all_pred_programs = []\n        all_gt_programs = []\n\n        first_failure_round = 0\n        total_correct = 0\n        total_acc_pen = 0\n        total = 0\n        total_curr_prog_correct = 0\n\n        if len(self.opts_Q.gpu_ids) > 1:\n            self.unitNet = nn.DataParallel(self.unitNet, device_ids=self.opts_Q.gpu_ids)\n        self.unitNet = self.unitNet.eval()\n        if self.opts_Q.batch_size != self.opts_Q.dialogLen:\n            print(\"[INFO] Changed batch size from {} to {}\".format(self.opts_Q.batch_size, self.opts_Q.dialogLen))\n            self.opts_Q.batch_size = self.opts_Q.dialogLen\n        dataloader = Data.DataLoader(\n            self.datasetTest,\n            batch_size=self.opts_Q.batch_size,\n            shuffle=False,\n            num_workers=self.opts_Q.num_workers,\n            pin_memory=False\n        )\n        _iterCur = 0\n        _totalCur = len(dataloader)\n        print(\"This the len of dataloader:\", _totalCur)\n\n        for step, (quest, questPrg,questRounds, history, historiesProg, answer, questImgIdx) in enumerate(dataloader):\n            # print(\"\\rEvaluation: [step %4d/%4d]\" % (\n            #     step + 1,\n            #     int(data_size / self.opts_Q.batch_size),\n            # ), end='          ')\n            # if step >= 5000:\n            #     break\n            batchSize = quest.size(0)\n            quest = quest.to(self.device)\n            # dependecy = self.dependencies[step*batchSize:(step+1)*batchSize]\n\n            if history.dim() == 3:\n                caption = history.detach()\n                caption = caption[:, 0, :]\n                caption = caption[:, :16].to(self.device)\n            elif history.dim() == 2:\n                caption = history.detach()\n                caption = caption[:, :16].to(self.device)\n            if self.opts_Q.last_n_rounds < 10:\n                last_n_rounds_batch = []\n                for i, r in enumerate(questRounds.tolist()):\n                    startIdx = max(r - self.opts_Q.last_n_rounds, 0)\n                    endIdx = max(r, self.opts_Q.last_n_rounds)\n                    if history.dim() == 3:\n                        assert endIdx - startIdx == self.opts_Q.last_n_rounds\n                        histBatch = history[i, :, :]\n                        last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n                    elif history.dim() == 2:\n                        startIdx *= 20\n                        endIdx *= 20\n                        histBatch = history[i, :]\n                        temp = histBatch[startIdx:endIdx]\n                        if r > self.opts_Q.last_n_rounds:\n                            last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n                        else:\n                            last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n                history = torch.stack(last_n_rounds_batch, dim=0)\n\n            history = history.to(self.device)\n            questPrg = questPrg.to(self.device)\n            historiesProg = historiesProg.tolist()\n            questRounds = questRounds.tolist()\n            answer = answer.tolist()\n            answers = list(map(lambda a: self.datasetTest.vocab[\"idx_text_to_token\"][a], answer))\n            questImgIdx = questImgIdx.tolist()\n            # if \"minecraft\" in self.opts_Q.scenesPath:\n            #     questImgIdx = [idx - 1 for idx in questImgIdx]\n\n            \n            unifiedProgsToksPred = torch.tensor(self.unitNet.sample(caption, quest, history))\n            # chunks = torch.split(torch.tensor(unifiedProgsToksPred), 2, dim=0)\n            # print(\"[debug] unifiedProg:\".format(unifiedProgsToksPred))\n            capProgsToksPred = unifiedProgsToksPred[:, 6:]\n            currProgsToksPred = unifiedProgsToksPred[:, :6]\n\n\n            currProgsPred = decodeProg(currProgsToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])\n            capProgsPred = decodeProg(capProgsToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])\n            targetProgs = decodeProg(questPrg, self.datasetTest.vocab[\"idx_prog_to_token\"], target=True)\n\n\n            questTypes = [targetProg[0] for targetProg in targetProgs]\n            # progHistories = getProgHistories(historiesProg[0], dataset.vocab[\"idx_prog_to_token\"])\n            progHistories = [getProgHistories(progHistToks, self.datasetTest.vocab[\"idx_prog_to_token\"]) for progHistToks in historiesProg]\n            pred_answers = []\n            all_pred_programs.append([capProgsPred[0]] + currProgsPred)\n            all_gt_programs.append([progHistories[0]] + (targetProgs))\n\n            for i in range(batchSize):\n                # if capProgsPred[i][0] == \"extreme-center\":\n                #     print(\"bla\")\n                # print(\"idx = {}\".format(questImgIdx[i]))\n                ans = self.getPrediction(\n                    currProgsPred[i],\n                    capProgsPred[i],\n                    progHistories[i],\n                    questImgIdx[i]\n                )\n                # if ans == \"Error\":\n                #     print(capProgsPred[i])\n                pred_answers.append(ans)\n            # print(pred_answers)\n            correct = [1 if pred == ans else 0 for (pred, ans) in zip(pred_answers, answers)]\n            correct_prog = [1 if pred == ans else 0 for (pred, ans) in zip(currProgsPred, targetProgs)]\n            idx_false = np.argwhere(np.array(correct) == 0).squeeze(-1)\n            if idx_false.shape[-1] > 0:\n                first_failure_round += idx_false[0] + 1\n            else:\n                first_failure_round += self.opts_Q.dialogLen + 1\n\n            correct = sum(correct)\n            correct_prog = sum(correct_prog)\n            total_correct += correct\n            total_curr_prog_correct += correct_prog\n            total += len(answers)\n            all_pred_answers.append(pred_answers)\n            all_gt_answers.append(answers)\n            all_quest_types.append(questTypes)\n            penalty = np.ones_like(answers)\n\n            # penalty = np.zeros_like(answers)\n            all_penalties.append(penalty)\n            _iterCur += 1\n            if _iterCur % self.opts_Q.display_every == 0:\n                print(\"[Evaluation] step {0} / {1} | acc. = {2:.2f}\".format(\n                    _iterCur, _totalCur, 100.0 * (total_correct / total)))\n\n        ffr = 1.0 * (first_failure_round/_totalCur)/(self.opts_Q.dialogLen + 1)\n\n        textOut = \"\\n --------------- Average First Failure Round --------------- \\n\"\n        textOut += \"{} / {}\".format(ffr, self.opts_Q.dialogLen)\n\n        # print(total_correct, total)\n        accuracy = total_correct / total\n        vd_acc = total_acc_pen / total\n        curr_prog_acc = total_curr_prog_correct / total\n        textOut += \"\\n --------------- Overall acc. --------------- \\n\"\n        textOut += \"{}\".format(100.0 * accuracy)\n        textOut += \"\\n --------------- Overall VD acc. --------------- \\n\"\n        textOut += \"{}\".format(100.0 * vd_acc)\n        textOut += \"\\n --------------- quest Prog. Acc --------------- \\n\"\n        textOut += \"{}\".format(100.0 * curr_prog_acc)\n        textOut += get_per_round_acc(\n            all_pred_answers, all_gt_answers, all_penalties)\n\n        textOut += get_per_quest_type_acc(\n            all_pred_answers, all_gt_answers, all_quest_types, all_penalties)\n\n        # textOut += get_per_dependency_type_acc(\n        #     all_pred_answers, all_gt_answers, all_penalties)\n\n        textOut += \"\\n --------------- Done --------------- \\n\"\n        print(textOut)\n\n\n# Evaluation\n \n\n    def getPrediction(self, currProgPred, capProgPred, historyProg, imgIndex):\n        self.symbolicExecutor.reset(imgIndex)\n        # if round one, execute the predicted caption program first then answer the quest\n        if len(historyProg) == 1:\n            captionFuncLabel = capProgPred[0]\n            captionFuncArgs = capProgPred[1:]\n\n            questFuncLabel = currProgPred[0]\n            questFuncArgs = currProgPred[1:]\n\n            try:\n                _ = self.symbolicExecutor.execute(captionFuncLabel, captionFuncArgs)\n            except:\n                return \"Error\"\n\n            try:\n                predAnswer = self.symbolicExecutor.execute(questFuncLabel, questFuncArgs)\n            except:\n                return \"Error\"\n\n        # If it is not the first round, we have to execute the program history and\n        # then answer the quest.\n        else:\n            questFuncLabel = currProgPred[0]\n            questFuncArgs = currProgPred[1:]\n            for prg in historyProg:\n                # prg = prg.split(\" \")\n                FuncLabel = prg[0]\n                FuncArgs = prg[1:]\n                try:\n                    _ = self.symbolicExecutor.execute(FuncLabel, FuncArgs)\n                except:\n                    return \"Error\"\n\n            try:\n                predAnswer = self.symbolicExecutor.execute(questFuncLabel, questFuncArgs)\n            except:\n                return \"Error\"\n        return str(predAnswer)\n\n    def run(self, run_mode, epoch=None):\n        self.set_seed(self.opts_Q.seed)\n        if run_mode == 'test_with_gt':\n            print('Testing with gt answers in history')\n            print('Loading ckpt {}'.format(self.opts_Q.trainedUnifiedNetPath))\n            state_dict = torch.load(self.opts_Q.trainedUnifiedNetPath)['state_dict']\n            self.unitNet.load_state_dict(state_dict)\n            self.eval_with_gt()\n        else:\n            exit(-1)\n\n    def set_seed(self, seed):\n        \"\"\"Sets the seed for reproducibility.\n        Args:\n            seed (int): The seed used\n        \"\"\"\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        np.random.seed(seed)\n        print('[INFO] Seed set to {}...'.format(seed))\n\n\ndef constructquestNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n    if opts_Q.encoderType == 1:\n        encoder = currEncoder_1(opts_Q, lenVocabText)\n    elif opts_Q.encoderType == 2:\n        encoder = currEncoder_2(opts_Q, lenVocabText)\n\n    net = SeqToSeqQ(encoder, decoder)\n    return net\n\n\ndef constructCaptionNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n    encoder = CaptionEncoder(opts_Q, lenVocabText)\n    net = SeqToSeqC(encoder, decoder)\n    return net\n\ndef constructNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n    encoder = Encoder(opts_Q, lenVocabText)\n    net = SeqToSeqUnified(encoder, decoder)\n    return net\n\ndef getProgHistories(progHistToks, prgIdxToToken):\n    progHist = []\n    temp = []\n    for tok in progHistToks:\n        if tok not in [0, 1, 2]:\n            temp.append(prgIdxToToken[tok])\n            # del progHistToks[i]\n        if tok == 2:\n            # del progHistToks[i]\n            # progHist.append(\" \".join(temp))\n            progHist.append(temp)\n            temp = []\n    return progHist\n\n\ndef getHistoriesFromStack(histToks, textIdxToToken):\n    histories = \"\\n\"\n    temp = []\n    for i, roundToks in enumerate(histToks):\n        for tok in roundToks:\n            if tok not in [0, 1, 2]:\n                temp.append(textIdxToToken[tok])\n                # del progHistToks[i]\n            if tok == 2:\n                # del progHistToks[i]\n                if i == 0:\n                    histories += \" \".join(temp) + \".\\n\"\n                else:\n                    histories += \" \".join(temp[:-1]) + \"? | {}.\\n\".format(temp[-1])\n                # histories.append(temp)\n                temp = []\n                break\n    return histories\n\n\ndef getHistoriesFromConcat(histToks, textIdxToToken):\n    histories = []\n    temp = []\n    for tok in histToks:\n        if tok not in [0, 1, 2]:\n            temp.append(textIdxToToken[tok])\n            # del progHistToks[i]\n        if tok == 2:\n            # del progHistToks[i]\n            histories.append(\" \".join(temp[:-1]) + \"? | {}\".format(temp[-1]))\n            # histories.append(temp)\n            temp = []\n    return histories\n\n\ndef decodeProg(tokens, prgIdxToToken, target=False):\n    \n    if (target == True):#***\n        tokensBatch = tokens.tolist()\n    else:#***\n        tokensBatch = tokens\n    progsBatch = []\n    for tokens in tokensBatch:\n        prog = []\n        for tok in tokens:\n            if tok == 2:  # <END> has index 2\n                break\n            prog.append(prgIdxToToken.get(int(tok)))\n            \n        if target:\n            prog = prog[1:]\n        \n        progsBatch.append(prog)\n\n    return progsBatch\n\n\ndef printPred(predSoftmax, gts, prgIdxToToken):\n    assert predSoftmax.size(0) == gts.size(0)\n    tokens = predSoftmax.topk(1)[1].squeeze(-1)\n    tokens = tokens.tolist()\n    gts = gts.tolist()\n    message = \"\\n ------------------------ \\n\"\n    for token, gt in zip(tokens, gts):\n        message += \"Prediction: \"\n        for tok in token:\n            message += prgIdxToToken.get(tok) + \" \"\n        message += \"\\n Target   : \"\n        for tok in gt:\n            message += prgIdxToToken.get(tok) + \" \"\n        message += \"\\n ------------------------ \\n\"\n    return message\n\n\ndef get_per_round_acc(preds, gts, penalties):\n    res = {}\n    for img_preds, img_gt, img_pen in zip(preds, gts, penalties):\n        img_preds = list(img_preds)\n        img_gt = list(img_gt)\n        img_pen = list(img_pen)\n        for i, (pred, gt, pen) in enumerate(zip(img_preds, img_gt, img_pen)):\n            _round = str(i + 1)\n            if _round not in res:\n                res[_round] = {\n                    \"correct\": 0,\n                    \"all\": 0\n                }\n            res[_round][\"all\"] += 1\n            if pred == gt:\n                res[_round][\"correct\"] += 0.5** float(pen)\n\n    textOut = \"\\n --------------- Per round Acc --------------- \\n\"\n    for k in res:\n        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res[k][\"correct\"]/res[k][\"all\"]))\n    return textOut\n\n\ndef get_per_quest_type_acc(preds, gts, qtypes, penalties):\n    res1 = {}\n    res2 = {}\n\n    for img_preds, img_gt, img_qtypes, img_pen in zip(preds, gts, qtypes, penalties):\n        # img_preds = list(img_preds)\n        # img_gt = list(img_gt)\n        img_pen = list(img_pen)\n        for pred, gt, temp, pen in zip(img_preds, img_gt, img_qtypes, img_pen):\n            if temp not in res1:\n                res1[temp] = {\n                    \"correct\": 0,\n                    \"all\": 0\n                }\n            temp_cat = temp.split(\"-\")[0]\n            if temp_cat not in res2:\n                res2[temp_cat] = {\n                    \"correct\": 0,\n                    \"all\": 0\n                }\n            res1[temp][\"all\"] += 1\n            res2[temp_cat][\"all\"] += 1\n\n            if pred == gt:\n                res1[temp][\"correct\"] += 0.5** float(pen)\n                res2[temp_cat][\"correct\"] += 0.5** float(pen)\n\n    textOut = \"\\n --------------- Per quest Type Acc --------------- \\n\"\n    for k in res1:\n        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res1[k][\"correct\"]/res1[k][\"all\"]))\n\n    textOut += \"\\n --------------- Per quest Category Acc --------------- \\n\"\n    for k in res2:\n        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res2[k][\"correct\"]/res2[k][\"all\"]))\n    return textOut\n\n\ndef decode(tokens, prgIdxToToken, target=False):\n    if type(tokens) != list:\n        tokens = tokens.tolist()\n\n    progsBatch = []\n    for token in tokens:\n        questProg = []\n        for tok in token:\n            if tok == 2:  # <END> has index 2\n                break\n            questProg.append(prgIdxToToken.get(tok))\n        if target:\n            questProg = questProg[1:]\n        # progsBatch.append(\" \".join(questProg))\n        progsBatch.append(questProg)\n    return progsBatch","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:22.920000Z","iopub.execute_input":"2024-02-13T16:22:22.920336Z","iopub.status.idle":"2024-02-13T16:22:22.999285Z","shell.execute_reply.started":"2024-02-13T16:22:22.920307Z","shell.execute_reply":"2024-02-13T16:22:22.998387Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optsQ = OptionsQ().parse()#***","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:23.000586Z","iopub.execute_input":"2024-02-13T16:22:23.000908Z","iopub.status.idle":"2024-02-13T16:22:23.013786Z","shell.execute_reply.started":"2024-02-13T16:22:23.000884Z","shell.execute_reply":"2024-02-13T16:22:23.012841Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"\n[INFO] Using 1 CUDA device(s) ...\n\n ------------------------------Opts------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"\nexe = Execution(optsQ)#***\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T16:22:23.014809Z","iopub.execute_input":"2024-02-13T16:22:23.015690Z","iopub.status.idle":"2024-02-13T16:22:31.725409Z","shell.execute_reply.started":"2024-02-13T16:22:23.015658Z","shell.execute_reply":"2024-02-13T16:22:31.724402Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"[INFO] Using GPU Tesla T4 ...\n[INFO] Loading dataset ...\nThe quest encoder has 202484871 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"exe.run('test_with_gt')\nprint(\"[INFO] Done ...\")#***","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-02-13T16:22:31.726694Z","iopub.execute_input":"2024-02-13T16:22:31.726983Z","iopub.status.idle":"2024-02-13T16:40:29.072894Z","shell.execute_reply.started":"2024-02-13T16:22:31.726958Z","shell.execute_reply":"2024-02-13T16:40:29.071869Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"[INFO] Seed set to 42...\nTesting with gt answers in history\nLoading ckpt /kaggle/input/nsvd-dataset/ckpt_iter_50.0_100.pkl\n[INFO] Changed batch size from 64 to 10\nThis the len of dataloader: 7500\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/2936983435.py:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  unifiedProgsToksPred = torch.tensor(self.unitNet.sample(caption, quest, history))\n","output_type":"stream"},{"name":"stdout","text":"[Evaluation] step 5 / 7500 | acc. = 10.00\n[Evaluation] step 10 / 7500 | acc. = 13.00\n[Evaluation] step 15 / 7500 | acc. = 12.67\n[Evaluation] step 20 / 7500 | acc. = 12.50\n[Evaluation] step 25 / 7500 | acc. = 11.20\n[Evaluation] step 30 / 7500 | acc. = 12.00\n[Evaluation] step 35 / 7500 | acc. = 11.43\n[Evaluation] step 40 / 7500 | acc. = 11.00\n[Evaluation] step 45 / 7500 | acc. = 10.89\n[Evaluation] step 50 / 7500 | acc. = 10.40\n[Evaluation] step 55 / 7500 | acc. = 10.36\n[Evaluation] step 60 / 7500 | acc. = 10.33\n[Evaluation] step 65 / 7500 | acc. = 10.31\n[Evaluation] step 70 / 7500 | acc. = 9.71\n[Evaluation] step 75 / 7500 | acc. = 9.60\n[Evaluation] step 80 / 7500 | acc. = 9.62\n[Evaluation] step 85 / 7500 | acc. = 9.88\n[Evaluation] step 90 / 7500 | acc. = 10.00\n[Evaluation] step 95 / 7500 | acc. = 10.00\n[Evaluation] step 100 / 7500 | acc. = 9.90\n[Evaluation] step 105 / 7500 | acc. = 9.90\n[Evaluation] step 110 / 7500 | acc. = 9.82\n[Evaluation] step 115 / 7500 | acc. = 9.83\n[Evaluation] step 120 / 7500 | acc. = 10.00\n[Evaluation] step 125 / 7500 | acc. = 10.08\n[Evaluation] step 130 / 7500 | acc. = 10.08\n[Evaluation] step 135 / 7500 | acc. = 10.37\n[Evaluation] step 140 / 7500 | acc. = 10.43\n[Evaluation] step 145 / 7500 | acc. = 10.48\n[Evaluation] step 150 / 7500 | acc. = 10.60\n[Evaluation] step 155 / 7500 | acc. = 10.58\n[Evaluation] step 160 / 7500 | acc. = 10.81\n[Evaluation] step 165 / 7500 | acc. = 10.61\n[Evaluation] step 170 / 7500 | acc. = 10.76\n[Evaluation] step 175 / 7500 | acc. = 10.86\n[Evaluation] step 180 / 7500 | acc. = 10.78\n[Evaluation] step 185 / 7500 | acc. = 10.65\n[Evaluation] step 190 / 7500 | acc. = 10.68\n[Evaluation] step 195 / 7500 | acc. = 10.82\n[Evaluation] step 200 / 7500 | acc. = 10.75\n[Evaluation] step 205 / 7500 | acc. = 10.78\n[Evaluation] step 210 / 7500 | acc. = 10.81\n[Evaluation] step 215 / 7500 | acc. = 10.79\n[Evaluation] step 220 / 7500 | acc. = 11.00\n[Evaluation] step 225 / 7500 | acc. = 11.02\n[Evaluation] step 230 / 7500 | acc. = 11.09\n[Evaluation] step 235 / 7500 | acc. = 11.15\n[Evaluation] step 240 / 7500 | acc. = 11.12\n[Evaluation] step 245 / 7500 | acc. = 11.14\n[Evaluation] step 250 / 7500 | acc. = 11.04\n[Evaluation] step 255 / 7500 | acc. = 11.14\n[Evaluation] step 260 / 7500 | acc. = 11.08\n[Evaluation] step 265 / 7500 | acc. = 11.17\n[Evaluation] step 270 / 7500 | acc. = 11.11\n[Evaluation] step 275 / 7500 | acc. = 11.02\n[Evaluation] step 280 / 7500 | acc. = 10.96\n[Evaluation] step 285 / 7500 | acc. = 11.02\n[Evaluation] step 290 / 7500 | acc. = 10.97\n[Evaluation] step 295 / 7500 | acc. = 10.95\n[Evaluation] step 300 / 7500 | acc. = 10.80\n[Evaluation] step 305 / 7500 | acc. = 10.75\n[Evaluation] step 310 / 7500 | acc. = 10.74\n[Evaluation] step 315 / 7500 | acc. = 10.70\n[Evaluation] step 320 / 7500 | acc. = 10.69\n[Evaluation] step 325 / 7500 | acc. = 10.68\n[Evaluation] step 330 / 7500 | acc. = 10.64\n[Evaluation] step 335 / 7500 | acc. = 10.60\n[Evaluation] step 340 / 7500 | acc. = 10.68\n[Evaluation] step 345 / 7500 | acc. = 10.67\n[Evaluation] step 350 / 7500 | acc. = 10.66\n[Evaluation] step 355 / 7500 | acc. = 10.68\n[Evaluation] step 360 / 7500 | acc. = 10.61\n[Evaluation] step 365 / 7500 | acc. = 10.68\n[Evaluation] step 370 / 7500 | acc. = 10.70\n[Evaluation] step 375 / 7500 | acc. = 10.69\n[Evaluation] step 380 / 7500 | acc. = 10.74\n[Evaluation] step 385 / 7500 | acc. = 10.70\n[Evaluation] step 390 / 7500 | acc. = 10.72\n[Evaluation] step 395 / 7500 | acc. = 10.71\n[Evaluation] step 400 / 7500 | acc. = 10.70\n[Evaluation] step 405 / 7500 | acc. = 10.69\n[Evaluation] step 410 / 7500 | acc. = 10.66\n[Evaluation] step 415 / 7500 | acc. = 10.72\n[Evaluation] step 420 / 7500 | acc. = 10.62\n[Evaluation] step 425 / 7500 | acc. = 10.56\n[Evaluation] step 430 / 7500 | acc. = 10.53\n[Evaluation] step 435 / 7500 | acc. = 10.51\n[Evaluation] step 440 / 7500 | acc. = 10.59\n[Evaluation] step 445 / 7500 | acc. = 10.65\n[Evaluation] step 450 / 7500 | acc. = 10.62\n[Evaluation] step 455 / 7500 | acc. = 10.66\n[Evaluation] step 460 / 7500 | acc. = 10.67\n[Evaluation] step 465 / 7500 | acc. = 10.58\n[Evaluation] step 470 / 7500 | acc. = 10.57\n[Evaluation] step 475 / 7500 | acc. = 10.59\n[Evaluation] step 480 / 7500 | acc. = 10.56\n[Evaluation] step 485 / 7500 | acc. = 10.52\n[Evaluation] step 490 / 7500 | acc. = 10.53\n[Evaluation] step 495 / 7500 | acc. = 10.55\n[Evaluation] step 500 / 7500 | acc. = 10.50\n[Evaluation] step 505 / 7500 | acc. = 10.48\n[Evaluation] step 510 / 7500 | acc. = 10.43\n[Evaluation] step 515 / 7500 | acc. = 10.45\n[Evaluation] step 520 / 7500 | acc. = 10.44\n[Evaluation] step 525 / 7500 | acc. = 10.40\n[Evaluation] step 530 / 7500 | acc. = 10.45\n[Evaluation] step 535 / 7500 | acc. = 10.43\n[Evaluation] step 540 / 7500 | acc. = 10.46\n[Evaluation] step 545 / 7500 | acc. = 10.46\n[Evaluation] step 550 / 7500 | acc. = 10.42\n[Evaluation] step 555 / 7500 | acc. = 10.40\n[Evaluation] step 560 / 7500 | acc. = 10.38\n[Evaluation] step 565 / 7500 | acc. = 10.37\n[Evaluation] step 570 / 7500 | acc. = 10.33\n[Evaluation] step 575 / 7500 | acc. = 10.33\n[Evaluation] step 580 / 7500 | acc. = 10.29\n[Evaluation] step 585 / 7500 | acc. = 10.27\n[Evaluation] step 590 / 7500 | acc. = 10.25\n[Evaluation] step 595 / 7500 | acc. = 10.27\n[Evaluation] step 600 / 7500 | acc. = 10.22\n[Evaluation] step 605 / 7500 | acc. = 10.21\n[Evaluation] step 610 / 7500 | acc. = 10.21\n[Evaluation] step 615 / 7500 | acc. = 10.21\n[Evaluation] step 620 / 7500 | acc. = 10.18\n[Evaluation] step 625 / 7500 | acc. = 10.24\n[Evaluation] step 630 / 7500 | acc. = 10.24\n[Evaluation] step 635 / 7500 | acc. = 10.25\n[Evaluation] step 640 / 7500 | acc. = 10.25\n[Evaluation] step 645 / 7500 | acc. = 10.28\n[Evaluation] step 650 / 7500 | acc. = 10.26\n[Evaluation] step 655 / 7500 | acc. = 10.23\n[Evaluation] step 660 / 7500 | acc. = 10.24\n[Evaluation] step 665 / 7500 | acc. = 10.27\n[Evaluation] step 670 / 7500 | acc. = 10.33\n[Evaluation] step 675 / 7500 | acc. = 10.37\n[Evaluation] step 680 / 7500 | acc. = 10.37\n[Evaluation] step 685 / 7500 | acc. = 10.32\n[Evaluation] step 690 / 7500 | acc. = 10.38\n[Evaluation] step 695 / 7500 | acc. = 10.36\n[Evaluation] step 700 / 7500 | acc. = 10.40\n[Evaluation] step 705 / 7500 | acc. = 10.40\n[Evaluation] step 710 / 7500 | acc. = 10.35\n[Evaluation] step 715 / 7500 | acc. = 10.36\n[Evaluation] step 720 / 7500 | acc. = 10.43\n[Evaluation] step 725 / 7500 | acc. = 10.43\n[Evaluation] step 730 / 7500 | acc. = 10.41\n[Evaluation] step 735 / 7500 | acc. = 10.41\n[Evaluation] step 740 / 7500 | acc. = 10.41\n[Evaluation] step 745 / 7500 | acc. = 10.39\n[Evaluation] step 750 / 7500 | acc. = 10.39\n[Evaluation] step 755 / 7500 | acc. = 10.44\n[Evaluation] step 760 / 7500 | acc. = 10.47\n[Evaluation] step 765 / 7500 | acc. = 10.50\n[Evaluation] step 770 / 7500 | acc. = 10.57\n[Evaluation] step 775 / 7500 | acc. = 10.57\n[Evaluation] step 780 / 7500 | acc. = 10.56\n[Evaluation] step 785 / 7500 | acc. = 10.57\n[Evaluation] step 790 / 7500 | acc. = 10.53\n[Evaluation] step 795 / 7500 | acc. = 10.52\n[Evaluation] step 800 / 7500 | acc. = 10.51\n[Evaluation] step 805 / 7500 | acc. = 10.51\n[Evaluation] step 810 / 7500 | acc. = 10.52\n[Evaluation] step 815 / 7500 | acc. = 10.52\n[Evaluation] step 820 / 7500 | acc. = 10.52\n[Evaluation] step 825 / 7500 | acc. = 10.53\n[Evaluation] step 830 / 7500 | acc. = 10.53\n[Evaluation] step 835 / 7500 | acc. = 10.55\n[Evaluation] step 840 / 7500 | acc. = 10.54\n[Evaluation] step 845 / 7500 | acc. = 10.57\n[Evaluation] step 850 / 7500 | acc. = 10.56\n[Evaluation] step 855 / 7500 | acc. = 10.56\n[Evaluation] step 860 / 7500 | acc. = 10.56\n[Evaluation] step 865 / 7500 | acc. = 10.55\n[Evaluation] step 870 / 7500 | acc. = 10.55\n[Evaluation] step 875 / 7500 | acc. = 10.53\n[Evaluation] step 880 / 7500 | acc. = 10.53\n[Evaluation] step 885 / 7500 | acc. = 10.49\n[Evaluation] step 890 / 7500 | acc. = 10.53\n[Evaluation] step 895 / 7500 | acc. = 10.54\n[Evaluation] step 900 / 7500 | acc. = 10.54\n[Evaluation] step 905 / 7500 | acc. = 10.54\n[Evaluation] step 910 / 7500 | acc. = 10.57\n[Evaluation] step 915 / 7500 | acc. = 10.58\n[Evaluation] step 920 / 7500 | acc. = 10.59\n[Evaluation] step 925 / 7500 | acc. = 10.56\n[Evaluation] step 930 / 7500 | acc. = 10.56\n[Evaluation] step 935 / 7500 | acc. = 10.58\n[Evaluation] step 940 / 7500 | acc. = 10.57\n[Evaluation] step 945 / 7500 | acc. = 10.57\n[Evaluation] step 950 / 7500 | acc. = 10.56\n[Evaluation] step 955 / 7500 | acc. = 10.57\n[Evaluation] step 960 / 7500 | acc. = 10.54\n[Evaluation] step 965 / 7500 | acc. = 10.51\n[Evaluation] step 970 / 7500 | acc. = 10.51\n[Evaluation] step 975 / 7500 | acc. = 10.49\n[Evaluation] step 980 / 7500 | acc. = 10.49\n[Evaluation] step 985 / 7500 | acc. = 10.49\n[Evaluation] step 990 / 7500 | acc. = 10.45\n[Evaluation] step 995 / 7500 | acc. = 10.45\n[Evaluation] step 1000 / 7500 | acc. = 10.46\n[Evaluation] step 1005 / 7500 | acc. = 10.48\n[Evaluation] step 1010 / 7500 | acc. = 10.46\n[Evaluation] step 1015 / 7500 | acc. = 10.46\n[Evaluation] step 1020 / 7500 | acc. = 10.47\n[Evaluation] step 1025 / 7500 | acc. = 10.47\n[Evaluation] step 1030 / 7500 | acc. = 10.45\n[Evaluation] step 1035 / 7500 | acc. = 10.43\n[Evaluation] step 1040 / 7500 | acc. = 10.46\n[Evaluation] step 1045 / 7500 | acc. = 10.45\n[Evaluation] step 1050 / 7500 | acc. = 10.43\n[Evaluation] step 1055 / 7500 | acc. = 10.39\n[Evaluation] step 1060 / 7500 | acc. = 10.43\n[Evaluation] step 1065 / 7500 | acc. = 10.44\n[Evaluation] step 1070 / 7500 | acc. = 10.42\n[Evaluation] step 1075 / 7500 | acc. = 10.42\n[Evaluation] step 1080 / 7500 | acc. = 10.41\n[Evaluation] step 1085 / 7500 | acc. = 10.41\n[Evaluation] step 1090 / 7500 | acc. = 10.41\n[Evaluation] step 1095 / 7500 | acc. = 10.42\n[Evaluation] step 1100 / 7500 | acc. = 10.43\n[Evaluation] step 1105 / 7500 | acc. = 10.44\n[Evaluation] step 1110 / 7500 | acc. = 10.44\n[Evaluation] step 1115 / 7500 | acc. = 10.43\n[Evaluation] step 1120 / 7500 | acc. = 10.46\n[Evaluation] step 1125 / 7500 | acc. = 10.45\n[Evaluation] step 1130 / 7500 | acc. = 10.50\n[Evaluation] step 1135 / 7500 | acc. = 10.53\n[Evaluation] step 1140 / 7500 | acc. = 10.52\n[Evaluation] step 1145 / 7500 | acc. = 10.53\n[Evaluation] step 1150 / 7500 | acc. = 10.53\n[Evaluation] step 1155 / 7500 | acc. = 10.55\n[Evaluation] step 1160 / 7500 | acc. = 10.58\n[Evaluation] step 1165 / 7500 | acc. = 10.57\n[Evaluation] step 1170 / 7500 | acc. = 10.57\n[Evaluation] step 1175 / 7500 | acc. = 10.55\n[Evaluation] step 1180 / 7500 | acc. = 10.55\n[Evaluation] step 1185 / 7500 | acc. = 10.53\n[Evaluation] step 1190 / 7500 | acc. = 10.53\n[Evaluation] step 1195 / 7500 | acc. = 10.52\n[Evaluation] step 1200 / 7500 | acc. = 10.49\n[Evaluation] step 1205 / 7500 | acc. = 10.49\n[Evaluation] step 1210 / 7500 | acc. = 10.49\n[Evaluation] step 1215 / 7500 | acc. = 10.49\n[Evaluation] step 1220 / 7500 | acc. = 10.48\n[Evaluation] step 1225 / 7500 | acc. = 10.46\n[Evaluation] step 1230 / 7500 | acc. = 10.45\n[Evaluation] step 1235 / 7500 | acc. = 10.46\n[Evaluation] step 1240 / 7500 | acc. = 10.45\n[Evaluation] step 1245 / 7500 | acc. = 10.43\n[Evaluation] step 1250 / 7500 | acc. = 10.42\n[Evaluation] step 1255 / 7500 | acc. = 10.41\n[Evaluation] step 1260 / 7500 | acc. = 10.40\n[Evaluation] step 1265 / 7500 | acc. = 10.41\n[Evaluation] step 1270 / 7500 | acc. = 10.41\n[Evaluation] step 1275 / 7500 | acc. = 10.41\n[Evaluation] step 1280 / 7500 | acc. = 10.41\n[Evaluation] step 1285 / 7500 | acc. = 10.40\n[Evaluation] step 1290 / 7500 | acc. = 10.44\n[Evaluation] step 1295 / 7500 | acc. = 10.43\n[Evaluation] step 1300 / 7500 | acc. = 10.43\n[Evaluation] step 1305 / 7500 | acc. = 10.44\n[Evaluation] step 1310 / 7500 | acc. = 10.44\n[Evaluation] step 1315 / 7500 | acc. = 10.45\n[Evaluation] step 1320 / 7500 | acc. = 10.45\n[Evaluation] step 1325 / 7500 | acc. = 10.48\n[Evaluation] step 1330 / 7500 | acc. = 10.47\n[Evaluation] step 1335 / 7500 | acc. = 10.47\n[Evaluation] step 1340 / 7500 | acc. = 10.46\n[Evaluation] step 1345 / 7500 | acc. = 10.45\n[Evaluation] step 1350 / 7500 | acc. = 10.43\n[Evaluation] step 1355 / 7500 | acc. = 10.44\n[Evaluation] step 1360 / 7500 | acc. = 10.45\n[Evaluation] step 1365 / 7500 | acc. = 10.46\n[Evaluation] step 1370 / 7500 | acc. = 10.47\n[Evaluation] step 1375 / 7500 | acc. = 10.48\n[Evaluation] step 1380 / 7500 | acc. = 10.54\n[Evaluation] step 1385 / 7500 | acc. = 10.55\n[Evaluation] step 1390 / 7500 | acc. = 10.57\n[Evaluation] step 1395 / 7500 | acc. = 10.57\n[Evaluation] step 1400 / 7500 | acc. = 10.57\n[Evaluation] step 1405 / 7500 | acc. = 10.60\n[Evaluation] step 1410 / 7500 | acc. = 10.60\n[Evaluation] step 1415 / 7500 | acc. = 10.59\n[Evaluation] step 1420 / 7500 | acc. = 10.58\n[Evaluation] step 1425 / 7500 | acc. = 10.58\n[Evaluation] step 1430 / 7500 | acc. = 10.59\n[Evaluation] step 1435 / 7500 | acc. = 10.59\n[Evaluation] step 1440 / 7500 | acc. = 10.59\n[Evaluation] step 1445 / 7500 | acc. = 10.58\n[Evaluation] step 1450 / 7500 | acc. = 10.58\n[Evaluation] step 1455 / 7500 | acc. = 10.58\n[Evaluation] step 1460 / 7500 | acc. = 10.61\n[Evaluation] step 1465 / 7500 | acc. = 10.59\n[Evaluation] step 1470 / 7500 | acc. = 10.59\n[Evaluation] step 1475 / 7500 | acc. = 10.58\n[Evaluation] step 1480 / 7500 | acc. = 10.57\n[Evaluation] step 1485 / 7500 | acc. = 10.59\n[Evaluation] step 1490 / 7500 | acc. = 10.58\n[Evaluation] step 1495 / 7500 | acc. = 10.60\n[Evaluation] step 1500 / 7500 | acc. = 10.61\n[Evaluation] step 1505 / 7500 | acc. = 10.59\n[Evaluation] step 1510 / 7500 | acc. = 10.58\n[Evaluation] step 1515 / 7500 | acc. = 10.59\n[Evaluation] step 1520 / 7500 | acc. = 10.60\n[Evaluation] step 1525 / 7500 | acc. = 10.59\n[Evaluation] step 1530 / 7500 | acc. = 10.59\n[Evaluation] step 1535 / 7500 | acc. = 10.58\n[Evaluation] step 1540 / 7500 | acc. = 10.59\n[Evaluation] step 1545 / 7500 | acc. = 10.60\n[Evaluation] step 1550 / 7500 | acc. = 10.58\n[Evaluation] step 1555 / 7500 | acc. = 10.57\n[Evaluation] step 1560 / 7500 | acc. = 10.56\n[Evaluation] step 1565 / 7500 | acc. = 10.54\n[Evaluation] step 1570 / 7500 | acc. = 10.54\n[Evaluation] step 1575 / 7500 | acc. = 10.54\n[Evaluation] step 1580 / 7500 | acc. = 10.56\n[Evaluation] step 1585 / 7500 | acc. = 10.54\n[Evaluation] step 1590 / 7500 | acc. = 10.55\n[Evaluation] step 1595 / 7500 | acc. = 10.53\n[Evaluation] step 1600 / 7500 | acc. = 10.53\n[Evaluation] step 1605 / 7500 | acc. = 10.54\n[Evaluation] step 1610 / 7500 | acc. = 10.54\n[Evaluation] step 1615 / 7500 | acc. = 10.53\n[Evaluation] step 1620 / 7500 | acc. = 10.51\n[Evaluation] step 1625 / 7500 | acc. = 10.53\n[Evaluation] step 1630 / 7500 | acc. = 10.51\n[Evaluation] step 1635 / 7500 | acc. = 10.50\n[Evaluation] step 1640 / 7500 | acc. = 10.49\n[Evaluation] step 1645 / 7500 | acc. = 10.49\n[Evaluation] step 1650 / 7500 | acc. = 10.49\n[Evaluation] step 1655 / 7500 | acc. = 10.50\n[Evaluation] step 1660 / 7500 | acc. = 10.49\n[Evaluation] step 1665 / 7500 | acc. = 10.49\n[Evaluation] step 1670 / 7500 | acc. = 10.50\n[Evaluation] step 1675 / 7500 | acc. = 10.50\n[Evaluation] step 1680 / 7500 | acc. = 10.49\n[Evaluation] step 1685 / 7500 | acc. = 10.47\n[Evaluation] step 1690 / 7500 | acc. = 10.49\n[Evaluation] step 1695 / 7500 | acc. = 10.47\n[Evaluation] step 1700 / 7500 | acc. = 10.47\n[Evaluation] step 1705 / 7500 | acc. = 10.48\n[Evaluation] step 1710 / 7500 | acc. = 10.47\n[Evaluation] step 1715 / 7500 | acc. = 10.48\n[Evaluation] step 1720 / 7500 | acc. = 10.47\n[Evaluation] step 1725 / 7500 | acc. = 10.50\n[Evaluation] step 1730 / 7500 | acc. = 10.49\n[Evaluation] step 1735 / 7500 | acc. = 10.50\n[Evaluation] step 1740 / 7500 | acc. = 10.51\n[Evaluation] step 1745 / 7500 | acc. = 10.51\n[Evaluation] step 1750 / 7500 | acc. = 10.51\n[Evaluation] step 1755 / 7500 | acc. = 10.50\n[Evaluation] step 1760 / 7500 | acc. = 10.50\n[Evaluation] step 1765 / 7500 | acc. = 10.49\n[Evaluation] step 1770 / 7500 | acc. = 10.47\n[Evaluation] step 1775 / 7500 | acc. = 10.47\n[Evaluation] step 1780 / 7500 | acc. = 10.46\n[Evaluation] step 1785 / 7500 | acc. = 10.48\n[Evaluation] step 1790 / 7500 | acc. = 10.47\n[Evaluation] step 1795 / 7500 | acc. = 10.48\n[Evaluation] step 1800 / 7500 | acc. = 10.46\n[Evaluation] step 1805 / 7500 | acc. = 10.46\n[Evaluation] step 1810 / 7500 | acc. = 10.45\n[Evaluation] step 1815 / 7500 | acc. = 10.45\n[Evaluation] step 1820 / 7500 | acc. = 10.44\n[Evaluation] step 1825 / 7500 | acc. = 10.43\n[Evaluation] step 1830 / 7500 | acc. = 10.42\n[Evaluation] step 1835 / 7500 | acc. = 10.43\n[Evaluation] step 1840 / 7500 | acc. = 10.41\n[Evaluation] step 1845 / 7500 | acc. = 10.42\n[Evaluation] step 1850 / 7500 | acc. = 10.43\n[Evaluation] step 1855 / 7500 | acc. = 10.43\n[Evaluation] step 1860 / 7500 | acc. = 10.43\n[Evaluation] step 1865 / 7500 | acc. = 10.42\n[Evaluation] step 1870 / 7500 | acc. = 10.41\n[Evaluation] step 1875 / 7500 | acc. = 10.41\n[Evaluation] step 1880 / 7500 | acc. = 10.39\n[Evaluation] step 1885 / 7500 | acc. = 10.41\n[Evaluation] step 1890 / 7500 | acc. = 10.42\n[Evaluation] step 1895 / 7500 | acc. = 10.42\n[Evaluation] step 1900 / 7500 | acc. = 10.43\n[Evaluation] step 1905 / 7500 | acc. = 10.43\n[Evaluation] step 1910 / 7500 | acc. = 10.42\n[Evaluation] step 1915 / 7500 | acc. = 10.40\n[Evaluation] step 1920 / 7500 | acc. = 10.40\n[Evaluation] step 1925 / 7500 | acc. = 10.41\n[Evaluation] step 1930 / 7500 | acc. = 10.40\n[Evaluation] step 1935 / 7500 | acc. = 10.40\n[Evaluation] step 1940 / 7500 | acc. = 10.39\n[Evaluation] step 1945 / 7500 | acc. = 10.39\n[Evaluation] step 1950 / 7500 | acc. = 10.37\n[Evaluation] step 1955 / 7500 | acc. = 10.38\n[Evaluation] step 1960 / 7500 | acc. = 10.39\n[Evaluation] step 1965 / 7500 | acc. = 10.38\n[Evaluation] step 1970 / 7500 | acc. = 10.39\n[Evaluation] step 1975 / 7500 | acc. = 10.39\n[Evaluation] step 1980 / 7500 | acc. = 10.39\n[Evaluation] step 1985 / 7500 | acc. = 10.41\n[Evaluation] step 1990 / 7500 | acc. = 10.40\n[Evaluation] step 1995 / 7500 | acc. = 10.40\n[Evaluation] step 2000 / 7500 | acc. = 10.41\n[Evaluation] step 2005 / 7500 | acc. = 10.41\n[Evaluation] step 2010 / 7500 | acc. = 10.40\n[Evaluation] step 2015 / 7500 | acc. = 10.41\n[Evaluation] step 2020 / 7500 | acc. = 10.40\n[Evaluation] step 2025 / 7500 | acc. = 10.40\n[Evaluation] step 2030 / 7500 | acc. = 10.39\n[Evaluation] step 2035 / 7500 | acc. = 10.40\n[Evaluation] step 2040 / 7500 | acc. = 10.39\n[Evaluation] step 2045 / 7500 | acc. = 10.39\n[Evaluation] step 2050 / 7500 | acc. = 10.39\n[Evaluation] step 2055 / 7500 | acc. = 10.39\n[Evaluation] step 2060 / 7500 | acc. = 10.38\n[Evaluation] step 2065 / 7500 | acc. = 10.38\n[Evaluation] step 2070 / 7500 | acc. = 10.38\n[Evaluation] step 2075 / 7500 | acc. = 10.38\n[Evaluation] step 2080 / 7500 | acc. = 10.38\n[Evaluation] step 2085 / 7500 | acc. = 10.38\n[Evaluation] step 2090 / 7500 | acc. = 10.40\n[Evaluation] step 2095 / 7500 | acc. = 10.40\n[Evaluation] step 2100 / 7500 | acc. = 10.40\n[Evaluation] step 2105 / 7500 | acc. = 10.39\n[Evaluation] step 2110 / 7500 | acc. = 10.39\n[Evaluation] step 2115 / 7500 | acc. = 10.39\n[Evaluation] step 2120 / 7500 | acc. = 10.39\n[Evaluation] step 2125 / 7500 | acc. = 10.39\n[Evaluation] step 2130 / 7500 | acc. = 10.38\n[Evaluation] step 2135 / 7500 | acc. = 10.38\n[Evaluation] step 2140 / 7500 | acc. = 10.38\n[Evaluation] step 2145 / 7500 | acc. = 10.36\n[Evaluation] step 2150 / 7500 | acc. = 10.37\n[Evaluation] step 2155 / 7500 | acc. = 10.37\n[Evaluation] step 2160 / 7500 | acc. = 10.36\n[Evaluation] step 2165 / 7500 | acc. = 10.35\n[Evaluation] step 2170 / 7500 | acc. = 10.35\n[Evaluation] step 2175 / 7500 | acc. = 10.36\n[Evaluation] step 2180 / 7500 | acc. = 10.37\n[Evaluation] step 2185 / 7500 | acc. = 10.38\n[Evaluation] step 2190 / 7500 | acc. = 10.38\n[Evaluation] step 2195 / 7500 | acc. = 10.39\n[Evaluation] step 2200 / 7500 | acc. = 10.40\n[Evaluation] step 2205 / 7500 | acc. = 10.40\n[Evaluation] step 2210 / 7500 | acc. = 10.40\n[Evaluation] step 2215 / 7500 | acc. = 10.39\n[Evaluation] step 2220 / 7500 | acc. = 10.39\n[Evaluation] step 2225 / 7500 | acc. = 10.39\n[Evaluation] step 2230 / 7500 | acc. = 10.38\n[Evaluation] step 2235 / 7500 | acc. = 10.37\n[Evaluation] step 2240 / 7500 | acc. = 10.37\n[Evaluation] step 2245 / 7500 | acc. = 10.37\n[Evaluation] step 2250 / 7500 | acc. = 10.37\n[Evaluation] step 2255 / 7500 | acc. = 10.37\n[Evaluation] step 2260 / 7500 | acc. = 10.36\n[Evaluation] step 2265 / 7500 | acc. = 10.36\n[Evaluation] step 2270 / 7500 | acc. = 10.37\n[Evaluation] step 2275 / 7500 | acc. = 10.37\n[Evaluation] step 2280 / 7500 | acc. = 10.38\n[Evaluation] step 2285 / 7500 | acc. = 10.38\n[Evaluation] step 2290 / 7500 | acc. = 10.37\n[Evaluation] step 2295 / 7500 | acc. = 10.38\n[Evaluation] step 2300 / 7500 | acc. = 10.38\n[Evaluation] step 2305 / 7500 | acc. = 10.38\n[Evaluation] step 2310 / 7500 | acc. = 10.37\n[Evaluation] step 2315 / 7500 | acc. = 10.37\n[Evaluation] step 2320 / 7500 | acc. = 10.36\n[Evaluation] step 2325 / 7500 | acc. = 10.34\n[Evaluation] step 2330 / 7500 | acc. = 10.33\n[Evaluation] step 2335 / 7500 | acc. = 10.32\n[Evaluation] step 2340 / 7500 | acc. = 10.33\n[Evaluation] step 2345 / 7500 | acc. = 10.34\n[Evaluation] step 2350 / 7500 | acc. = 10.34\n[Evaluation] step 2355 / 7500 | acc. = 10.35\n[Evaluation] step 2360 / 7500 | acc. = 10.35\n[Evaluation] step 2365 / 7500 | acc. = 10.36\n[Evaluation] step 2370 / 7500 | acc. = 10.35\n[Evaluation] step 2375 / 7500 | acc. = 10.35\n[Evaluation] step 2380 / 7500 | acc. = 10.35\n[Evaluation] step 2385 / 7500 | acc. = 10.35\n[Evaluation] step 2390 / 7500 | acc. = 10.35\n[Evaluation] step 2395 / 7500 | acc. = 10.34\n[Evaluation] step 2400 / 7500 | acc. = 10.34\n[Evaluation] step 2405 / 7500 | acc. = 10.34\n[Evaluation] step 2410 / 7500 | acc. = 10.34\n[Evaluation] step 2415 / 7500 | acc. = 10.35\n[Evaluation] step 2420 / 7500 | acc. = 10.33\n[Evaluation] step 2425 / 7500 | acc. = 10.33\n[Evaluation] step 2430 / 7500 | acc. = 10.32\n[Evaluation] step 2435 / 7500 | acc. = 10.33\n[Evaluation] step 2440 / 7500 | acc. = 10.34\n[Evaluation] step 2445 / 7500 | acc. = 10.34\n[Evaluation] step 2450 / 7500 | acc. = 10.33\n[Evaluation] step 2455 / 7500 | acc. = 10.33\n[Evaluation] step 2460 / 7500 | acc. = 10.33\n[Evaluation] step 2465 / 7500 | acc. = 10.34\n[Evaluation] step 2470 / 7500 | acc. = 10.34\n[Evaluation] step 2475 / 7500 | acc. = 10.35\n[Evaluation] step 2480 / 7500 | acc. = 10.34\n[Evaluation] step 2485 / 7500 | acc. = 10.35\n[Evaluation] step 2490 / 7500 | acc. = 10.35\n[Evaluation] step 2495 / 7500 | acc. = 10.35\n[Evaluation] step 2500 / 7500 | acc. = 10.35\n[Evaluation] step 2505 / 7500 | acc. = 10.34\n[Evaluation] step 2510 / 7500 | acc. = 10.33\n[Evaluation] step 2515 / 7500 | acc. = 10.33\n[Evaluation] step 2520 / 7500 | acc. = 10.34\n[Evaluation] step 2525 / 7500 | acc. = 10.33\n[Evaluation] step 2530 / 7500 | acc. = 10.33\n[Evaluation] step 2535 / 7500 | acc. = 10.33\n[Evaluation] step 2540 / 7500 | acc. = 10.33\n[Evaluation] step 2545 / 7500 | acc. = 10.33\n[Evaluation] step 2550 / 7500 | acc. = 10.33\n[Evaluation] step 2555 / 7500 | acc. = 10.33\n[Evaluation] step 2560 / 7500 | acc. = 10.33\n[Evaluation] step 2565 / 7500 | acc. = 10.33\n[Evaluation] step 2570 / 7500 | acc. = 10.33\n[Evaluation] step 2575 / 7500 | acc. = 10.33\n[Evaluation] step 2580 / 7500 | acc. = 10.34\n[Evaluation] step 2585 / 7500 | acc. = 10.34\n[Evaluation] step 2590 / 7500 | acc. = 10.34\n[Evaluation] step 2595 / 7500 | acc. = 10.33\n[Evaluation] step 2600 / 7500 | acc. = 10.32\n[Evaluation] step 2605 / 7500 | acc. = 10.32\n[Evaluation] step 2610 / 7500 | acc. = 10.32\n[Evaluation] step 2615 / 7500 | acc. = 10.31\n[Evaluation] step 2620 / 7500 | acc. = 10.32\n[Evaluation] step 2625 / 7500 | acc. = 10.31\n[Evaluation] step 2630 / 7500 | acc. = 10.31\n[Evaluation] step 2635 / 7500 | acc. = 10.32\n[Evaluation] step 2640 / 7500 | acc. = 10.33\n[Evaluation] step 2645 / 7500 | acc. = 10.33\n[Evaluation] step 2650 / 7500 | acc. = 10.32\n[Evaluation] step 2655 / 7500 | acc. = 10.32\n[Evaluation] step 2660 / 7500 | acc. = 10.32\n[Evaluation] step 2665 / 7500 | acc. = 10.33\n[Evaluation] step 2670 / 7500 | acc. = 10.33\n[Evaluation] step 2675 / 7500 | acc. = 10.34\n[Evaluation] step 2680 / 7500 | acc. = 10.34\n[Evaluation] step 2685 / 7500 | acc. = 10.34\n[Evaluation] step 2690 / 7500 | acc. = 10.35\n[Evaluation] step 2695 / 7500 | acc. = 10.35\n[Evaluation] step 2700 / 7500 | acc. = 10.36\n[Evaluation] step 2705 / 7500 | acc. = 10.36\n[Evaluation] step 2710 / 7500 | acc. = 10.36\n[Evaluation] step 2715 / 7500 | acc. = 10.35\n[Evaluation] step 2720 / 7500 | acc. = 10.34\n[Evaluation] step 2725 / 7500 | acc. = 10.33\n[Evaluation] step 2730 / 7500 | acc. = 10.33\n[Evaluation] step 2735 / 7500 | acc. = 10.33\n[Evaluation] step 2740 / 7500 | acc. = 10.32\n[Evaluation] step 2745 / 7500 | acc. = 10.33\n[Evaluation] step 2750 / 7500 | acc. = 10.33\n[Evaluation] step 2755 / 7500 | acc. = 10.33\n[Evaluation] step 2760 / 7500 | acc. = 10.35\n[Evaluation] step 2765 / 7500 | acc. = 10.35\n[Evaluation] step 2770 / 7500 | acc. = 10.34\n[Evaluation] step 2775 / 7500 | acc. = 10.34\n[Evaluation] step 2780 / 7500 | acc. = 10.34\n[Evaluation] step 2785 / 7500 | acc. = 10.33\n[Evaluation] step 2790 / 7500 | acc. = 10.33\n[Evaluation] step 2795 / 7500 | acc. = 10.33\n[Evaluation] step 2800 / 7500 | acc. = 10.32\n[Evaluation] step 2805 / 7500 | acc. = 10.32\n[Evaluation] step 2810 / 7500 | acc. = 10.33\n[Evaluation] step 2815 / 7500 | acc. = 10.33\n[Evaluation] step 2820 / 7500 | acc. = 10.33\n[Evaluation] step 2825 / 7500 | acc. = 10.32\n[Evaluation] step 2830 / 7500 | acc. = 10.33\n[Evaluation] step 2835 / 7500 | acc. = 10.34\n[Evaluation] step 2840 / 7500 | acc. = 10.34\n[Evaluation] step 2845 / 7500 | acc. = 10.34\n[Evaluation] step 2850 / 7500 | acc. = 10.33\n[Evaluation] step 2855 / 7500 | acc. = 10.33\n[Evaluation] step 2860 / 7500 | acc. = 10.33\n[Evaluation] step 2865 / 7500 | acc. = 10.32\n[Evaluation] step 2870 / 7500 | acc. = 10.31\n[Evaluation] step 2875 / 7500 | acc. = 10.30\n[Evaluation] step 2880 / 7500 | acc. = 10.30\n[Evaluation] step 2885 / 7500 | acc. = 10.29\n[Evaluation] step 2890 / 7500 | acc. = 10.30\n[Evaluation] step 2895 / 7500 | acc. = 10.30\n[Evaluation] step 2900 / 7500 | acc. = 10.30\n[Evaluation] step 2905 / 7500 | acc. = 10.30\n[Evaluation] step 2910 / 7500 | acc. = 10.30\n[Evaluation] step 2915 / 7500 | acc. = 10.29\n[Evaluation] step 2920 / 7500 | acc. = 10.30\n[Evaluation] step 2925 / 7500 | acc. = 10.31\n[Evaluation] step 2930 / 7500 | acc. = 10.30\n[Evaluation] step 2935 / 7500 | acc. = 10.30\n[Evaluation] step 2940 / 7500 | acc. = 10.31\n[Evaluation] step 2945 / 7500 | acc. = 10.31\n[Evaluation] step 2950 / 7500 | acc. = 10.31\n[Evaluation] step 2955 / 7500 | acc. = 10.31\n[Evaluation] step 2960 / 7500 | acc. = 10.31\n[Evaluation] step 2965 / 7500 | acc. = 10.31\n[Evaluation] step 2970 / 7500 | acc. = 10.30\n[Evaluation] step 2975 / 7500 | acc. = 10.30\n[Evaluation] step 2980 / 7500 | acc. = 10.30\n[Evaluation] step 2985 / 7500 | acc. = 10.28\n[Evaluation] step 2990 / 7500 | acc. = 10.29\n[Evaluation] step 2995 / 7500 | acc. = 10.29\n[Evaluation] step 3000 / 7500 | acc. = 10.29\n[Evaluation] step 3005 / 7500 | acc. = 10.29\n[Evaluation] step 3010 / 7500 | acc. = 10.29\n[Evaluation] step 3015 / 7500 | acc. = 10.28\n[Evaluation] step 3020 / 7500 | acc. = 10.28\n[Evaluation] step 3025 / 7500 | acc. = 10.28\n[Evaluation] step 3030 / 7500 | acc. = 10.27\n[Evaluation] step 3035 / 7500 | acc. = 10.27\n[Evaluation] step 3040 / 7500 | acc. = 10.27\n[Evaluation] step 3045 / 7500 | acc. = 10.27\n[Evaluation] step 3050 / 7500 | acc. = 10.27\n[Evaluation] step 3055 / 7500 | acc. = 10.27\n[Evaluation] step 3060 / 7500 | acc. = 10.27\n[Evaluation] step 3065 / 7500 | acc. = 10.27\n[Evaluation] step 3070 / 7500 | acc. = 10.27\n[Evaluation] step 3075 / 7500 | acc. = 10.28\n[Evaluation] step 3080 / 7500 | acc. = 10.29\n[Evaluation] step 3085 / 7500 | acc. = 10.28\n[Evaluation] step 3090 / 7500 | acc. = 10.29\n[Evaluation] step 3095 / 7500 | acc. = 10.31\n[Evaluation] step 3100 / 7500 | acc. = 10.30\n[Evaluation] step 3105 / 7500 | acc. = 10.30\n[Evaluation] step 3110 / 7500 | acc. = 10.29\n[Evaluation] step 3115 / 7500 | acc. = 10.30\n[Evaluation] step 3120 / 7500 | acc. = 10.30\n[Evaluation] step 3125 / 7500 | acc. = 10.29\n[Evaluation] step 3130 / 7500 | acc. = 10.29\n[Evaluation] step 3135 / 7500 | acc. = 10.30\n[Evaluation] step 3140 / 7500 | acc. = 10.29\n[Evaluation] step 3145 / 7500 | acc. = 10.30\n[Evaluation] step 3150 / 7500 | acc. = 10.29\n[Evaluation] step 3155 / 7500 | acc. = 10.29\n[Evaluation] step 3160 / 7500 | acc. = 10.29\n[Evaluation] step 3165 / 7500 | acc. = 10.29\n[Evaluation] step 3170 / 7500 | acc. = 10.30\n[Evaluation] step 3175 / 7500 | acc. = 10.30\n[Evaluation] step 3180 / 7500 | acc. = 10.31\n[Evaluation] step 3185 / 7500 | acc. = 10.31\n[Evaluation] step 3190 / 7500 | acc. = 10.30\n[Evaluation] step 3195 / 7500 | acc. = 10.30\n[Evaluation] step 3200 / 7500 | acc. = 10.31\n[Evaluation] step 3205 / 7500 | acc. = 10.31\n[Evaluation] step 3210 / 7500 | acc. = 10.31\n[Evaluation] step 3215 / 7500 | acc. = 10.31\n[Evaluation] step 3220 / 7500 | acc. = 10.31\n[Evaluation] step 3225 / 7500 | acc. = 10.32\n[Evaluation] step 3230 / 7500 | acc. = 10.33\n[Evaluation] step 3235 / 7500 | acc. = 10.33\n[Evaluation] step 3240 / 7500 | acc. = 10.32\n[Evaluation] step 3245 / 7500 | acc. = 10.32\n[Evaluation] step 3250 / 7500 | acc. = 10.33\n[Evaluation] step 3255 / 7500 | acc. = 10.33\n[Evaluation] step 3260 / 7500 | acc. = 10.33\n[Evaluation] step 3265 / 7500 | acc. = 10.33\n[Evaluation] step 3270 / 7500 | acc. = 10.31\n[Evaluation] step 3275 / 7500 | acc. = 10.31\n[Evaluation] step 3280 / 7500 | acc. = 10.30\n[Evaluation] step 3285 / 7500 | acc. = 10.30\n[Evaluation] step 3290 / 7500 | acc. = 10.31\n[Evaluation] step 3295 / 7500 | acc. = 10.31\n[Evaluation] step 3300 / 7500 | acc. = 10.30\n[Evaluation] step 3305 / 7500 | acc. = 10.31\n[Evaluation] step 3310 / 7500 | acc. = 10.32\n[Evaluation] step 3315 / 7500 | acc. = 10.32\n[Evaluation] step 3320 / 7500 | acc. = 10.32\n[Evaluation] step 3325 / 7500 | acc. = 10.31\n[Evaluation] step 3330 / 7500 | acc. = 10.30\n[Evaluation] step 3335 / 7500 | acc. = 10.30\n[Evaluation] step 3340 / 7500 | acc. = 10.30\n[Evaluation] step 3345 / 7500 | acc. = 10.30\n[Evaluation] step 3350 / 7500 | acc. = 10.30\n[Evaluation] step 3355 / 7500 | acc. = 10.29\n[Evaluation] step 3360 / 7500 | acc. = 10.29\n[Evaluation] step 3365 / 7500 | acc. = 10.29\n[Evaluation] step 3370 / 7500 | acc. = 10.30\n[Evaluation] step 3375 / 7500 | acc. = 10.30\n[Evaluation] step 3380 / 7500 | acc. = 10.29\n[Evaluation] step 3385 / 7500 | acc. = 10.30\n[Evaluation] step 3390 / 7500 | acc. = 10.30\n[Evaluation] step 3395 / 7500 | acc. = 10.30\n[Evaluation] step 3400 / 7500 | acc. = 10.29\n[Evaluation] step 3405 / 7500 | acc. = 10.28\n[Evaluation] step 3410 / 7500 | acc. = 10.28\n[Evaluation] step 3415 / 7500 | acc. = 10.28\n[Evaluation] step 3420 / 7500 | acc. = 10.29\n[Evaluation] step 3425 / 7500 | acc. = 10.29\n[Evaluation] step 3430 / 7500 | acc. = 10.30\n[Evaluation] step 3435 / 7500 | acc. = 10.29\n[Evaluation] step 3440 / 7500 | acc. = 10.29\n[Evaluation] step 3445 / 7500 | acc. = 10.29\n[Evaluation] step 3450 / 7500 | acc. = 10.28\n[Evaluation] step 3455 / 7500 | acc. = 10.29\n[Evaluation] step 3460 / 7500 | acc. = 10.29\n[Evaluation] step 3465 / 7500 | acc. = 10.29\n[Evaluation] step 3470 / 7500 | acc. = 10.28\n[Evaluation] step 3475 / 7500 | acc. = 10.27\n[Evaluation] step 3480 / 7500 | acc. = 10.27\n[Evaluation] step 3485 / 7500 | acc. = 10.27\n[Evaluation] step 3490 / 7500 | acc. = 10.26\n[Evaluation] step 3495 / 7500 | acc. = 10.26\n[Evaluation] step 3500 / 7500 | acc. = 10.25\n[Evaluation] step 3505 / 7500 | acc. = 10.25\n[Evaluation] step 3510 / 7500 | acc. = 10.26\n[Evaluation] step 3515 / 7500 | acc. = 10.26\n[Evaluation] step 3520 / 7500 | acc. = 10.26\n[Evaluation] step 3525 / 7500 | acc. = 10.26\n[Evaluation] step 3530 / 7500 | acc. = 10.25\n[Evaluation] step 3535 / 7500 | acc. = 10.25\n[Evaluation] step 3540 / 7500 | acc. = 10.24\n[Evaluation] step 3545 / 7500 | acc. = 10.25\n[Evaluation] step 3550 / 7500 | acc. = 10.24\n[Evaluation] step 3555 / 7500 | acc. = 10.24\n[Evaluation] step 3560 / 7500 | acc. = 10.25\n[Evaluation] step 3565 / 7500 | acc. = 10.24\n[Evaluation] step 3570 / 7500 | acc. = 10.25\n[Evaluation] step 3575 / 7500 | acc. = 10.25\n[Evaluation] step 3580 / 7500 | acc. = 10.25\n[Evaluation] step 3585 / 7500 | acc. = 10.25\n[Evaluation] step 3590 / 7500 | acc. = 10.25\n[Evaluation] step 3595 / 7500 | acc. = 10.26\n[Evaluation] step 3600 / 7500 | acc. = 10.26\n[Evaluation] step 3605 / 7500 | acc. = 10.26\n[Evaluation] step 3610 / 7500 | acc. = 10.27\n[Evaluation] step 3615 / 7500 | acc. = 10.27\n[Evaluation] step 3620 / 7500 | acc. = 10.27\n[Evaluation] step 3625 / 7500 | acc. = 10.27\n[Evaluation] step 3630 / 7500 | acc. = 10.28\n[Evaluation] step 3635 / 7500 | acc. = 10.27\n[Evaluation] step 3640 / 7500 | acc. = 10.26\n[Evaluation] step 3645 / 7500 | acc. = 10.26\n[Evaluation] step 3650 / 7500 | acc. = 10.27\n[Evaluation] step 3655 / 7500 | acc. = 10.27\n[Evaluation] step 3660 / 7500 | acc. = 10.28\n[Evaluation] step 3665 / 7500 | acc. = 10.28\n[Evaluation] step 3670 / 7500 | acc. = 10.28\n[Evaluation] step 3675 / 7500 | acc. = 10.27\n[Evaluation] step 3680 / 7500 | acc. = 10.28\n[Evaluation] step 3685 / 7500 | acc. = 10.28\n[Evaluation] step 3690 / 7500 | acc. = 10.28\n[Evaluation] step 3695 / 7500 | acc. = 10.27\n[Evaluation] step 3700 / 7500 | acc. = 10.27\n[Evaluation] step 3705 / 7500 | acc. = 10.27\n[Evaluation] step 3710 / 7500 | acc. = 10.26\n[Evaluation] step 3715 / 7500 | acc. = 10.26\n[Evaluation] step 3720 / 7500 | acc. = 10.26\n[Evaluation] step 3725 / 7500 | acc. = 10.26\n[Evaluation] step 3730 / 7500 | acc. = 10.25\n[Evaluation] step 3735 / 7500 | acc. = 10.25\n[Evaluation] step 3740 / 7500 | acc. = 10.26\n[Evaluation] step 3745 / 7500 | acc. = 10.26\n[Evaluation] step 3750 / 7500 | acc. = 10.27\n[Evaluation] step 3755 / 7500 | acc. = 10.28\n[Evaluation] step 3760 / 7500 | acc. = 10.27\n[Evaluation] step 3765 / 7500 | acc. = 10.29\n[Evaluation] step 3770 / 7500 | acc. = 10.29\n[Evaluation] step 3775 / 7500 | acc. = 10.29\n[Evaluation] step 3780 / 7500 | acc. = 10.30\n[Evaluation] step 3785 / 7500 | acc. = 10.30\n[Evaluation] step 3790 / 7500 | acc. = 10.30\n[Evaluation] step 3795 / 7500 | acc. = 10.30\n[Evaluation] step 3800 / 7500 | acc. = 10.29\n[Evaluation] step 3805 / 7500 | acc. = 10.30\n[Evaluation] step 3810 / 7500 | acc. = 10.30\n[Evaluation] step 3815 / 7500 | acc. = 10.30\n[Evaluation] step 3820 / 7500 | acc. = 10.31\n[Evaluation] step 3825 / 7500 | acc. = 10.32\n[Evaluation] step 3830 / 7500 | acc. = 10.32\n[Evaluation] step 3835 / 7500 | acc. = 10.32\n[Evaluation] step 3840 / 7500 | acc. = 10.32\n[Evaluation] step 3845 / 7500 | acc. = 10.31\n[Evaluation] step 3850 / 7500 | acc. = 10.32\n[Evaluation] step 3855 / 7500 | acc. = 10.32\n[Evaluation] step 3860 / 7500 | acc. = 10.32\n[Evaluation] step 3865 / 7500 | acc. = 10.31\n[Evaluation] step 3870 / 7500 | acc. = 10.31\n[Evaluation] step 3875 / 7500 | acc. = 10.31\n[Evaluation] step 3880 / 7500 | acc. = 10.30\n[Evaluation] step 3885 / 7500 | acc. = 10.30\n[Evaluation] step 3890 / 7500 | acc. = 10.30\n[Evaluation] step 3895 / 7500 | acc. = 10.30\n[Evaluation] step 3900 / 7500 | acc. = 10.31\n[Evaluation] step 3905 / 7500 | acc. = 10.29\n[Evaluation] step 3910 / 7500 | acc. = 10.30\n[Evaluation] step 3915 / 7500 | acc. = 10.30\n[Evaluation] step 3920 / 7500 | acc. = 10.29\n[Evaluation] step 3925 / 7500 | acc. = 10.29\n[Evaluation] step 3930 / 7500 | acc. = 10.29\n[Evaluation] step 3935 / 7500 | acc. = 10.29\n[Evaluation] step 3940 / 7500 | acc. = 10.29\n[Evaluation] step 3945 / 7500 | acc. = 10.31\n[Evaluation] step 3950 / 7500 | acc. = 10.31\n[Evaluation] step 3955 / 7500 | acc. = 10.31\n[Evaluation] step 3960 / 7500 | acc. = 10.30\n[Evaluation] step 3965 / 7500 | acc. = 10.30\n[Evaluation] step 3970 / 7500 | acc. = 10.30\n[Evaluation] step 3975 / 7500 | acc. = 10.30\n[Evaluation] step 3980 / 7500 | acc. = 10.31\n[Evaluation] step 3985 / 7500 | acc. = 10.31\n[Evaluation] step 3990 / 7500 | acc. = 10.31\n[Evaluation] step 3995 / 7500 | acc. = 10.30\n[Evaluation] step 4000 / 7500 | acc. = 10.29\n[Evaluation] step 4005 / 7500 | acc. = 10.29\n[Evaluation] step 4010 / 7500 | acc. = 10.28\n[Evaluation] step 4015 / 7500 | acc. = 10.29\n[Evaluation] step 4020 / 7500 | acc. = 10.30\n[Evaluation] step 4025 / 7500 | acc. = 10.30\n[Evaluation] step 4030 / 7500 | acc. = 10.32\n[Evaluation] step 4035 / 7500 | acc. = 10.32\n[Evaluation] step 4040 / 7500 | acc. = 10.33\n[Evaluation] step 4045 / 7500 | acc. = 10.33\n[Evaluation] step 4050 / 7500 | acc. = 10.32\n[Evaluation] step 4055 / 7500 | acc. = 10.32\n[Evaluation] step 4060 / 7500 | acc. = 10.32\n[Evaluation] step 4065 / 7500 | acc. = 10.32\n[Evaluation] step 4070 / 7500 | acc. = 10.31\n[Evaluation] step 4075 / 7500 | acc. = 10.31\n[Evaluation] step 4080 / 7500 | acc. = 10.31\n[Evaluation] step 4085 / 7500 | acc. = 10.30\n[Evaluation] step 4090 / 7500 | acc. = 10.31\n[Evaluation] step 4095 / 7500 | acc. = 10.30\n[Evaluation] step 4100 / 7500 | acc. = 10.30\n[Evaluation] step 4105 / 7500 | acc. = 10.29\n[Evaluation] step 4110 / 7500 | acc. = 10.29\n[Evaluation] step 4115 / 7500 | acc. = 10.30\n[Evaluation] step 4120 / 7500 | acc. = 10.30\n[Evaluation] step 4125 / 7500 | acc. = 10.29\n[Evaluation] step 4130 / 7500 | acc. = 10.29\n[Evaluation] step 4135 / 7500 | acc. = 10.29\n[Evaluation] step 4140 / 7500 | acc. = 10.29\n[Evaluation] step 4145 / 7500 | acc. = 10.28\n[Evaluation] step 4150 / 7500 | acc. = 10.28\n[Evaluation] step 4155 / 7500 | acc. = 10.28\n[Evaluation] step 4160 / 7500 | acc. = 10.29\n[Evaluation] step 4165 / 7500 | acc. = 10.28\n[Evaluation] step 4170 / 7500 | acc. = 10.28\n[Evaluation] step 4175 / 7500 | acc. = 10.29\n[Evaluation] step 4180 / 7500 | acc. = 10.29\n[Evaluation] step 4185 / 7500 | acc. = 10.28\n[Evaluation] step 4190 / 7500 | acc. = 10.28\n[Evaluation] step 4195 / 7500 | acc. = 10.28\n[Evaluation] step 4200 / 7500 | acc. = 10.28\n[Evaluation] step 4205 / 7500 | acc. = 10.27\n[Evaluation] step 4210 / 7500 | acc. = 10.27\n[Evaluation] step 4215 / 7500 | acc. = 10.26\n[Evaluation] step 4220 / 7500 | acc. = 10.26\n[Evaluation] step 4225 / 7500 | acc. = 10.27\n[Evaluation] step 4230 / 7500 | acc. = 10.26\n[Evaluation] step 4235 / 7500 | acc. = 10.26\n[Evaluation] step 4240 / 7500 | acc. = 10.27\n[Evaluation] step 4245 / 7500 | acc. = 10.27\n[Evaluation] step 4250 / 7500 | acc. = 10.27\n[Evaluation] step 4255 / 7500 | acc. = 10.27\n[Evaluation] step 4260 / 7500 | acc. = 10.27\n[Evaluation] step 4265 / 7500 | acc. = 10.28\n[Evaluation] step 4270 / 7500 | acc. = 10.28\n[Evaluation] step 4275 / 7500 | acc. = 10.27\n[Evaluation] step 4280 / 7500 | acc. = 10.28\n[Evaluation] step 4285 / 7500 | acc. = 10.28\n[Evaluation] step 4290 / 7500 | acc. = 10.28\n[Evaluation] step 4295 / 7500 | acc. = 10.28\n[Evaluation] step 4300 / 7500 | acc. = 10.28\n[Evaluation] step 4305 / 7500 | acc. = 10.28\n[Evaluation] step 4310 / 7500 | acc. = 10.27\n[Evaluation] step 4315 / 7500 | acc. = 10.28\n[Evaluation] step 4320 / 7500 | acc. = 10.27\n[Evaluation] step 4325 / 7500 | acc. = 10.27\n[Evaluation] step 4330 / 7500 | acc. = 10.26\n[Evaluation] step 4335 / 7500 | acc. = 10.27\n[Evaluation] step 4340 / 7500 | acc. = 10.26\n[Evaluation] step 4345 / 7500 | acc. = 10.26\n[Evaluation] step 4350 / 7500 | acc. = 10.26\n[Evaluation] step 4355 / 7500 | acc. = 10.26\n[Evaluation] step 4360 / 7500 | acc. = 10.26\n[Evaluation] step 4365 / 7500 | acc. = 10.26\n[Evaluation] step 4370 / 7500 | acc. = 10.27\n[Evaluation] step 4375 / 7500 | acc. = 10.28\n[Evaluation] step 4380 / 7500 | acc. = 10.27\n[Evaluation] step 4385 / 7500 | acc. = 10.28\n[Evaluation] step 4390 / 7500 | acc. = 10.28\n[Evaluation] step 4395 / 7500 | acc. = 10.28\n[Evaluation] step 4400 / 7500 | acc. = 10.28\n[Evaluation] step 4405 / 7500 | acc. = 10.28\n[Evaluation] step 4410 / 7500 | acc. = 10.29\n[Evaluation] step 4415 / 7500 | acc. = 10.29\n[Evaluation] step 4420 / 7500 | acc. = 10.30\n[Evaluation] step 4425 / 7500 | acc. = 10.29\n[Evaluation] step 4430 / 7500 | acc. = 10.30\n[Evaluation] step 4435 / 7500 | acc. = 10.29\n[Evaluation] step 4440 / 7500 | acc. = 10.29\n[Evaluation] step 4445 / 7500 | acc. = 10.29\n[Evaluation] step 4450 / 7500 | acc. = 10.29\n[Evaluation] step 4455 / 7500 | acc. = 10.29\n[Evaluation] step 4460 / 7500 | acc. = 10.28\n[Evaluation] step 4465 / 7500 | acc. = 10.28\n[Evaluation] step 4470 / 7500 | acc. = 10.28\n[Evaluation] step 4475 / 7500 | acc. = 10.28\n[Evaluation] step 4480 / 7500 | acc. = 10.27\n[Evaluation] step 4485 / 7500 | acc. = 10.28\n[Evaluation] step 4490 / 7500 | acc. = 10.27\n[Evaluation] step 4495 / 7500 | acc. = 10.28\n[Evaluation] step 4500 / 7500 | acc. = 10.27\n[Evaluation] step 4505 / 7500 | acc. = 10.27\n[Evaluation] step 4510 / 7500 | acc. = 10.27\n[Evaluation] step 4515 / 7500 | acc. = 10.27\n[Evaluation] step 4520 / 7500 | acc. = 10.27\n[Evaluation] step 4525 / 7500 | acc. = 10.27\n[Evaluation] step 4530 / 7500 | acc. = 10.27\n[Evaluation] step 4535 / 7500 | acc. = 10.27\n[Evaluation] step 4540 / 7500 | acc. = 10.27\n[Evaluation] step 4545 / 7500 | acc. = 10.27\n[Evaluation] step 4550 / 7500 | acc. = 10.27\n[Evaluation] step 4555 / 7500 | acc. = 10.27\n[Evaluation] step 4560 / 7500 | acc. = 10.27\n[Evaluation] step 4565 / 7500 | acc. = 10.27\n[Evaluation] step 4570 / 7500 | acc. = 10.27\n[Evaluation] step 4575 / 7500 | acc. = 10.26\n[Evaluation] step 4580 / 7500 | acc. = 10.26\n[Evaluation] step 4585 / 7500 | acc. = 10.26\n[Evaluation] step 4590 / 7500 | acc. = 10.26\n[Evaluation] step 4595 / 7500 | acc. = 10.27\n[Evaluation] step 4600 / 7500 | acc. = 10.26\n[Evaluation] step 4605 / 7500 | acc. = 10.27\n[Evaluation] step 4610 / 7500 | acc. = 10.28\n[Evaluation] step 4615 / 7500 | acc. = 10.28\n[Evaluation] step 4620 / 7500 | acc. = 10.28\n[Evaluation] step 4625 / 7500 | acc. = 10.29\n[Evaluation] step 4630 / 7500 | acc. = 10.29\n[Evaluation] step 4635 / 7500 | acc. = 10.30\n[Evaluation] step 4640 / 7500 | acc. = 10.30\n[Evaluation] step 4645 / 7500 | acc. = 10.30\n[Evaluation] step 4650 / 7500 | acc. = 10.30\n[Evaluation] step 4655 / 7500 | acc. = 10.30\n[Evaluation] step 4660 / 7500 | acc. = 10.30\n[Evaluation] step 4665 / 7500 | acc. = 10.29\n[Evaluation] step 4670 / 7500 | acc. = 10.29\n[Evaluation] step 4675 / 7500 | acc. = 10.29\n[Evaluation] step 4680 / 7500 | acc. = 10.29\n[Evaluation] step 4685 / 7500 | acc. = 10.30\n[Evaluation] step 4690 / 7500 | acc. = 10.30\n[Evaluation] step 4695 / 7500 | acc. = 10.30\n[Evaluation] step 4700 / 7500 | acc. = 10.30\n[Evaluation] step 4705 / 7500 | acc. = 10.30\n[Evaluation] step 4710 / 7500 | acc. = 10.30\n[Evaluation] step 4715 / 7500 | acc. = 10.30\n[Evaluation] step 4720 / 7500 | acc. = 10.30\n[Evaluation] step 4725 / 7500 | acc. = 10.30\n[Evaluation] step 4730 / 7500 | acc. = 10.30\n[Evaluation] step 4735 / 7500 | acc. = 10.30\n[Evaluation] step 4740 / 7500 | acc. = 10.30\n[Evaluation] step 4745 / 7500 | acc. = 10.30\n[Evaluation] step 4750 / 7500 | acc. = 10.30\n[Evaluation] step 4755 / 7500 | acc. = 10.29\n[Evaluation] step 4760 / 7500 | acc. = 10.30\n[Evaluation] step 4765 / 7500 | acc. = 10.30\n[Evaluation] step 4770 / 7500 | acc. = 10.29\n[Evaluation] step 4775 / 7500 | acc. = 10.29\n[Evaluation] step 4780 / 7500 | acc. = 10.29\n[Evaluation] step 4785 / 7500 | acc. = 10.29\n[Evaluation] step 4790 / 7500 | acc. = 10.29\n[Evaluation] step 4795 / 7500 | acc. = 10.29\n[Evaluation] step 4800 / 7500 | acc. = 10.29\n[Evaluation] step 4805 / 7500 | acc. = 10.29\n[Evaluation] step 4810 / 7500 | acc. = 10.29\n[Evaluation] step 4815 / 7500 | acc. = 10.29\n[Evaluation] step 4820 / 7500 | acc. = 10.28\n[Evaluation] step 4825 / 7500 | acc. = 10.28\n[Evaluation] step 4830 / 7500 | acc. = 10.28\n[Evaluation] step 4835 / 7500 | acc. = 10.28\n[Evaluation] step 4840 / 7500 | acc. = 10.27\n[Evaluation] step 4845 / 7500 | acc. = 10.27\n[Evaluation] step 4850 / 7500 | acc. = 10.27\n[Evaluation] step 4855 / 7500 | acc. = 10.27\n[Evaluation] step 4860 / 7500 | acc. = 10.27\n[Evaluation] step 4865 / 7500 | acc. = 10.27\n[Evaluation] step 4870 / 7500 | acc. = 10.26\n[Evaluation] step 4875 / 7500 | acc. = 10.27\n[Evaluation] step 4880 / 7500 | acc. = 10.28\n[Evaluation] step 4885 / 7500 | acc. = 10.28\n[Evaluation] step 4890 / 7500 | acc. = 10.28\n[Evaluation] step 4895 / 7500 | acc. = 10.28\n[Evaluation] step 4900 / 7500 | acc. = 10.28\n[Evaluation] step 4905 / 7500 | acc. = 10.28\n[Evaluation] step 4910 / 7500 | acc. = 10.28\n[Evaluation] step 4915 / 7500 | acc. = 10.28\n[Evaluation] step 4920 / 7500 | acc. = 10.27\n[Evaluation] step 4925 / 7500 | acc. = 10.27\n[Evaluation] step 4930 / 7500 | acc. = 10.27\n[Evaluation] step 4935 / 7500 | acc. = 10.27\n[Evaluation] step 4940 / 7500 | acc. = 10.27\n[Evaluation] step 4945 / 7500 | acc. = 10.28\n[Evaluation] step 4950 / 7500 | acc. = 10.28\n[Evaluation] step 4955 / 7500 | acc. = 10.27\n[Evaluation] step 4960 / 7500 | acc. = 10.27\n[Evaluation] step 4965 / 7500 | acc. = 10.26\n[Evaluation] step 4970 / 7500 | acc. = 10.26\n[Evaluation] step 4975 / 7500 | acc. = 10.26\n[Evaluation] step 4980 / 7500 | acc. = 10.26\n[Evaluation] step 4985 / 7500 | acc. = 10.26\n[Evaluation] step 4990 / 7500 | acc. = 10.27\n[Evaluation] step 4995 / 7500 | acc. = 10.26\n[Evaluation] step 5000 / 7500 | acc. = 10.26\n[Evaluation] step 5005 / 7500 | acc. = 10.26\n[Evaluation] step 5010 / 7500 | acc. = 10.26\n[Evaluation] step 5015 / 7500 | acc. = 10.26\n[Evaluation] step 5020 / 7500 | acc. = 10.26\n[Evaluation] step 5025 / 7500 | acc. = 10.27\n[Evaluation] step 5030 / 7500 | acc. = 10.27\n[Evaluation] step 5035 / 7500 | acc. = 10.27\n[Evaluation] step 5040 / 7500 | acc. = 10.26\n[Evaluation] step 5045 / 7500 | acc. = 10.26\n[Evaluation] step 5050 / 7500 | acc. = 10.26\n[Evaluation] step 5055 / 7500 | acc. = 10.25\n[Evaluation] step 5060 / 7500 | acc. = 10.25\n[Evaluation] step 5065 / 7500 | acc. = 10.25\n[Evaluation] step 5070 / 7500 | acc. = 10.25\n[Evaluation] step 5075 / 7500 | acc. = 10.25\n[Evaluation] step 5080 / 7500 | acc. = 10.26\n[Evaluation] step 5085 / 7500 | acc. = 10.26\n[Evaluation] step 5090 / 7500 | acc. = 10.25\n[Evaluation] step 5095 / 7500 | acc. = 10.25\n[Evaluation] step 5100 / 7500 | acc. = 10.24\n[Evaluation] step 5105 / 7500 | acc. = 10.24\n[Evaluation] step 5110 / 7500 | acc. = 10.24\n[Evaluation] step 5115 / 7500 | acc. = 10.24\n[Evaluation] step 5120 / 7500 | acc. = 10.24\n[Evaluation] step 5125 / 7500 | acc. = 10.24\n[Evaluation] step 5130 / 7500 | acc. = 10.24\n[Evaluation] step 5135 / 7500 | acc. = 10.23\n[Evaluation] step 5140 / 7500 | acc. = 10.23\n[Evaluation] step 5145 / 7500 | acc. = 10.23\n[Evaluation] step 5150 / 7500 | acc. = 10.23\n[Evaluation] step 5155 / 7500 | acc. = 10.23\n[Evaluation] step 5160 / 7500 | acc. = 10.23\n[Evaluation] step 5165 / 7500 | acc. = 10.22\n[Evaluation] step 5170 / 7500 | acc. = 10.22\n[Evaluation] step 5175 / 7500 | acc. = 10.22\n[Evaluation] step 5180 / 7500 | acc. = 10.22\n[Evaluation] step 5185 / 7500 | acc. = 10.22\n[Evaluation] step 5190 / 7500 | acc. = 10.22\n[Evaluation] step 5195 / 7500 | acc. = 10.22\n[Evaluation] step 5200 / 7500 | acc. = 10.23\n[Evaluation] step 5205 / 7500 | acc. = 10.23\n[Evaluation] step 5210 / 7500 | acc. = 10.23\n[Evaluation] step 5215 / 7500 | acc. = 10.24\n[Evaluation] step 5220 / 7500 | acc. = 10.25\n[Evaluation] step 5225 / 7500 | acc. = 10.24\n[Evaluation] step 5230 / 7500 | acc. = 10.24\n[Evaluation] step 5235 / 7500 | acc. = 10.24\n[Evaluation] step 5240 / 7500 | acc. = 10.26\n[Evaluation] step 5245 / 7500 | acc. = 10.25\n[Evaluation] step 5250 / 7500 | acc. = 10.25\n[Evaluation] step 5255 / 7500 | acc. = 10.26\n[Evaluation] step 5260 / 7500 | acc. = 10.26\n[Evaluation] step 5265 / 7500 | acc. = 10.27\n[Evaluation] step 5270 / 7500 | acc. = 10.28\n[Evaluation] step 5275 / 7500 | acc. = 10.28\n[Evaluation] step 5280 / 7500 | acc. = 10.28\n[Evaluation] step 5285 / 7500 | acc. = 10.28\n[Evaluation] step 5290 / 7500 | acc. = 10.28\n[Evaluation] step 5295 / 7500 | acc. = 10.29\n[Evaluation] step 5300 / 7500 | acc. = 10.29\n[Evaluation] step 5305 / 7500 | acc. = 10.28\n[Evaluation] step 5310 / 7500 | acc. = 10.28\n[Evaluation] step 5315 / 7500 | acc. = 10.28\n[Evaluation] step 5320 / 7500 | acc. = 10.28\n[Evaluation] step 5325 / 7500 | acc. = 10.28\n[Evaluation] step 5330 / 7500 | acc. = 10.27\n[Evaluation] step 5335 / 7500 | acc. = 10.28\n[Evaluation] step 5340 / 7500 | acc. = 10.28\n[Evaluation] step 5345 / 7500 | acc. = 10.28\n[Evaluation] step 5350 / 7500 | acc. = 10.28\n[Evaluation] step 5355 / 7500 | acc. = 10.28\n[Evaluation] step 5360 / 7500 | acc. = 10.28\n[Evaluation] step 5365 / 7500 | acc. = 10.29\n[Evaluation] step 5370 / 7500 | acc. = 10.29\n[Evaluation] step 5375 / 7500 | acc. = 10.28\n[Evaluation] step 5380 / 7500 | acc. = 10.28\n[Evaluation] step 5385 / 7500 | acc. = 10.29\n[Evaluation] step 5390 / 7500 | acc. = 10.28\n[Evaluation] step 5395 / 7500 | acc. = 10.28\n[Evaluation] step 5400 / 7500 | acc. = 10.27\n[Evaluation] step 5405 / 7500 | acc. = 10.28\n[Evaluation] step 5410 / 7500 | acc. = 10.28\n[Evaluation] step 5415 / 7500 | acc. = 10.28\n[Evaluation] step 5420 / 7500 | acc. = 10.28\n[Evaluation] step 5425 / 7500 | acc. = 10.29\n[Evaluation] step 5430 / 7500 | acc. = 10.29\n[Evaluation] step 5435 / 7500 | acc. = 10.28\n[Evaluation] step 5440 / 7500 | acc. = 10.28\n[Evaluation] step 5445 / 7500 | acc. = 10.29\n[Evaluation] step 5450 / 7500 | acc. = 10.29\n[Evaluation] step 5455 / 7500 | acc. = 10.29\n[Evaluation] step 5460 / 7500 | acc. = 10.29\n[Evaluation] step 5465 / 7500 | acc. = 10.28\n[Evaluation] step 5470 / 7500 | acc. = 10.28\n[Evaluation] step 5475 / 7500 | acc. = 10.28\n[Evaluation] step 5480 / 7500 | acc. = 10.27\n[Evaluation] step 5485 / 7500 | acc. = 10.27\n[Evaluation] step 5490 / 7500 | acc. = 10.27\n[Evaluation] step 5495 / 7500 | acc. = 10.28\n[Evaluation] step 5500 / 7500 | acc. = 10.28\n[Evaluation] step 5505 / 7500 | acc. = 10.27\n[Evaluation] step 5510 / 7500 | acc. = 10.28\n[Evaluation] step 5515 / 7500 | acc. = 10.27\n[Evaluation] step 5520 / 7500 | acc. = 10.27\n[Evaluation] step 5525 / 7500 | acc. = 10.27\n[Evaluation] step 5530 / 7500 | acc. = 10.27\n[Evaluation] step 5535 / 7500 | acc. = 10.27\n[Evaluation] step 5540 / 7500 | acc. = 10.27\n[Evaluation] step 5545 / 7500 | acc. = 10.28\n[Evaluation] step 5550 / 7500 | acc. = 10.28\n[Evaluation] step 5555 / 7500 | acc. = 10.28\n[Evaluation] step 5560 / 7500 | acc. = 10.28\n[Evaluation] step 5565 / 7500 | acc. = 10.28\n[Evaluation] step 5570 / 7500 | acc. = 10.28\n[Evaluation] step 5575 / 7500 | acc. = 10.28\n[Evaluation] step 5580 / 7500 | acc. = 10.29\n[Evaluation] step 5585 / 7500 | acc. = 10.28\n[Evaluation] step 5590 / 7500 | acc. = 10.28\n[Evaluation] step 5595 / 7500 | acc. = 10.28\n[Evaluation] step 5600 / 7500 | acc. = 10.28\n[Evaluation] step 5605 / 7500 | acc. = 10.28\n[Evaluation] step 5610 / 7500 | acc. = 10.28\n[Evaluation] step 5615 / 7500 | acc. = 10.28\n[Evaluation] step 5620 / 7500 | acc. = 10.29\n[Evaluation] step 5625 / 7500 | acc. = 10.28\n[Evaluation] step 5630 / 7500 | acc. = 10.28\n[Evaluation] step 5635 / 7500 | acc. = 10.28\n[Evaluation] step 5640 / 7500 | acc. = 10.29\n[Evaluation] step 5645 / 7500 | acc. = 10.29\n[Evaluation] step 5650 / 7500 | acc. = 10.29\n[Evaluation] step 5655 / 7500 | acc. = 10.28\n[Evaluation] step 5660 / 7500 | acc. = 10.29\n[Evaluation] step 5665 / 7500 | acc. = 10.29\n[Evaluation] step 5670 / 7500 | acc. = 10.29\n[Evaluation] step 5675 / 7500 | acc. = 10.29\n[Evaluation] step 5680 / 7500 | acc. = 10.29\n[Evaluation] step 5685 / 7500 | acc. = 10.29\n[Evaluation] step 5690 / 7500 | acc. = 10.29\n[Evaluation] step 5695 / 7500 | acc. = 10.29\n[Evaluation] step 5700 / 7500 | acc. = 10.29\n[Evaluation] step 5705 / 7500 | acc. = 10.29\n[Evaluation] step 5710 / 7500 | acc. = 10.29\n[Evaluation] step 5715 / 7500 | acc. = 10.30\n[Evaluation] step 5720 / 7500 | acc. = 10.30\n[Evaluation] step 5725 / 7500 | acc. = 10.30\n[Evaluation] step 5730 / 7500 | acc. = 10.30\n[Evaluation] step 5735 / 7500 | acc. = 10.29\n[Evaluation] step 5740 / 7500 | acc. = 10.30\n[Evaluation] step 5745 / 7500 | acc. = 10.30\n[Evaluation] step 5750 / 7500 | acc. = 10.30\n[Evaluation] step 5755 / 7500 | acc. = 10.30\n[Evaluation] step 5760 / 7500 | acc. = 10.30\n[Evaluation] step 5765 / 7500 | acc. = 10.30\n[Evaluation] step 5770 / 7500 | acc. = 10.30\n[Evaluation] step 5775 / 7500 | acc. = 10.30\n[Evaluation] step 5780 / 7500 | acc. = 10.30\n[Evaluation] step 5785 / 7500 | acc. = 10.29\n[Evaluation] step 5790 / 7500 | acc. = 10.30\n[Evaluation] step 5795 / 7500 | acc. = 10.30\n[Evaluation] step 5800 / 7500 | acc. = 10.30\n[Evaluation] step 5805 / 7500 | acc. = 10.30\n[Evaluation] step 5810 / 7500 | acc. = 10.30\n[Evaluation] step 5815 / 7500 | acc. = 10.30\n[Evaluation] step 5820 / 7500 | acc. = 10.30\n[Evaluation] step 5825 / 7500 | acc. = 10.30\n[Evaluation] step 5830 / 7500 | acc. = 10.30\n[Evaluation] step 5835 / 7500 | acc. = 10.29\n[Evaluation] step 5840 / 7500 | acc. = 10.30\n[Evaluation] step 5845 / 7500 | acc. = 10.29\n[Evaluation] step 5850 / 7500 | acc. = 10.30\n[Evaluation] step 5855 / 7500 | acc. = 10.30\n[Evaluation] step 5860 / 7500 | acc. = 10.30\n[Evaluation] step 5865 / 7500 | acc. = 10.30\n[Evaluation] step 5870 / 7500 | acc. = 10.30\n[Evaluation] step 5875 / 7500 | acc. = 10.30\n[Evaluation] step 5880 / 7500 | acc. = 10.30\n[Evaluation] step 5885 / 7500 | acc. = 10.30\n[Evaluation] step 5890 / 7500 | acc. = 10.30\n[Evaluation] step 5895 / 7500 | acc. = 10.30\n[Evaluation] step 5900 / 7500 | acc. = 10.30\n[Evaluation] step 5905 / 7500 | acc. = 10.29\n[Evaluation] step 5910 / 7500 | acc. = 10.29\n[Evaluation] step 5915 / 7500 | acc. = 10.30\n[Evaluation] step 5920 / 7500 | acc. = 10.29\n[Evaluation] step 5925 / 7500 | acc. = 10.29\n[Evaluation] step 5930 / 7500 | acc. = 10.29\n[Evaluation] step 5935 / 7500 | acc. = 10.29\n[Evaluation] step 5940 / 7500 | acc. = 10.29\n[Evaluation] step 5945 / 7500 | acc. = 10.29\n[Evaluation] step 5950 / 7500 | acc. = 10.29\n[Evaluation] step 5955 / 7500 | acc. = 10.29\n[Evaluation] step 5960 / 7500 | acc. = 10.29\n[Evaluation] step 5965 / 7500 | acc. = 10.30\n[Evaluation] step 5970 / 7500 | acc. = 10.30\n[Evaluation] step 5975 / 7500 | acc. = 10.31\n[Evaluation] step 5980 / 7500 | acc. = 10.31\n[Evaluation] step 5985 / 7500 | acc. = 10.31\n[Evaluation] step 5990 / 7500 | acc. = 10.31\n[Evaluation] step 5995 / 7500 | acc. = 10.31\n[Evaluation] step 6000 / 7500 | acc. = 10.31\n[Evaluation] step 6005 / 7500 | acc. = 10.31\n[Evaluation] step 6010 / 7500 | acc. = 10.31\n[Evaluation] step 6015 / 7500 | acc. = 10.32\n[Evaluation] step 6020 / 7500 | acc. = 10.32\n[Evaluation] step 6025 / 7500 | acc. = 10.32\n[Evaluation] step 6030 / 7500 | acc. = 10.32\n[Evaluation] step 6035 / 7500 | acc. = 10.31\n[Evaluation] step 6040 / 7500 | acc. = 10.31\n[Evaluation] step 6045 / 7500 | acc. = 10.31\n[Evaluation] step 6050 / 7500 | acc. = 10.31\n[Evaluation] step 6055 / 7500 | acc. = 10.31\n[Evaluation] step 6060 / 7500 | acc. = 10.32\n[Evaluation] step 6065 / 7500 | acc. = 10.31\n[Evaluation] step 6070 / 7500 | acc. = 10.31\n[Evaluation] step 6075 / 7500 | acc. = 10.32\n[Evaluation] step 6080 / 7500 | acc. = 10.32\n[Evaluation] step 6085 / 7500 | acc. = 10.31\n[Evaluation] step 6090 / 7500 | acc. = 10.32\n[Evaluation] step 6095 / 7500 | acc. = 10.32\n[Evaluation] step 6100 / 7500 | acc. = 10.32\n[Evaluation] step 6105 / 7500 | acc. = 10.32\n[Evaluation] step 6110 / 7500 | acc. = 10.32\n[Evaluation] step 6115 / 7500 | acc. = 10.32\n[Evaluation] step 6120 / 7500 | acc. = 10.32\n[Evaluation] step 6125 / 7500 | acc. = 10.32\n[Evaluation] step 6130 / 7500 | acc. = 10.32\n[Evaluation] step 6135 / 7500 | acc. = 10.31\n[Evaluation] step 6140 / 7500 | acc. = 10.32\n[Evaluation] step 6145 / 7500 | acc. = 10.32\n[Evaluation] step 6150 / 7500 | acc. = 10.32\n[Evaluation] step 6155 / 7500 | acc. = 10.32\n[Evaluation] step 6160 / 7500 | acc. = 10.32\n[Evaluation] step 6165 / 7500 | acc. = 10.31\n[Evaluation] step 6170 / 7500 | acc. = 10.31\n[Evaluation] step 6175 / 7500 | acc. = 10.31\n[Evaluation] step 6180 / 7500 | acc. = 10.31\n[Evaluation] step 6185 / 7500 | acc. = 10.31\n[Evaluation] step 6190 / 7500 | acc. = 10.30\n[Evaluation] step 6195 / 7500 | acc. = 10.31\n[Evaluation] step 6200 / 7500 | acc. = 10.31\n[Evaluation] step 6205 / 7500 | acc. = 10.31\n[Evaluation] step 6210 / 7500 | acc. = 10.32\n[Evaluation] step 6215 / 7500 | acc. = 10.31\n[Evaluation] step 6220 / 7500 | acc. = 10.32\n[Evaluation] step 6225 / 7500 | acc. = 10.32\n[Evaluation] step 6230 / 7500 | acc. = 10.32\n[Evaluation] step 6235 / 7500 | acc. = 10.32\n[Evaluation] step 6240 / 7500 | acc. = 10.32\n[Evaluation] step 6245 / 7500 | acc. = 10.32\n[Evaluation] step 6250 / 7500 | acc. = 10.32\n[Evaluation] step 6255 / 7500 | acc. = 10.32\n[Evaluation] step 6260 / 7500 | acc. = 10.32\n[Evaluation] step 6265 / 7500 | acc. = 10.32\n[Evaluation] step 6270 / 7500 | acc. = 10.32\n[Evaluation] step 6275 / 7500 | acc. = 10.32\n[Evaluation] step 6280 / 7500 | acc. = 10.31\n[Evaluation] step 6285 / 7500 | acc. = 10.31\n[Evaluation] step 6290 / 7500 | acc. = 10.31\n[Evaluation] step 6295 / 7500 | acc. = 10.31\n[Evaluation] step 6300 / 7500 | acc. = 10.30\n[Evaluation] step 6305 / 7500 | acc. = 10.30\n[Evaluation] step 6310 / 7500 | acc. = 10.30\n[Evaluation] step 6315 / 7500 | acc. = 10.29\n[Evaluation] step 6320 / 7500 | acc. = 10.29\n[Evaluation] step 6325 / 7500 | acc. = 10.29\n[Evaluation] step 6330 / 7500 | acc. = 10.29\n[Evaluation] step 6335 / 7500 | acc. = 10.29\n[Evaluation] step 6340 / 7500 | acc. = 10.29\n[Evaluation] step 6345 / 7500 | acc. = 10.29\n[Evaluation] step 6350 / 7500 | acc. = 10.29\n[Evaluation] step 6355 / 7500 | acc. = 10.29\n[Evaluation] step 6360 / 7500 | acc. = 10.29\n[Evaluation] step 6365 / 7500 | acc. = 10.29\n[Evaluation] step 6370 / 7500 | acc. = 10.29\n[Evaluation] step 6375 / 7500 | acc. = 10.28\n[Evaluation] step 6380 / 7500 | acc. = 10.29\n[Evaluation] step 6385 / 7500 | acc. = 10.29\n[Evaluation] step 6390 / 7500 | acc. = 10.28\n[Evaluation] step 6395 / 7500 | acc. = 10.28\n[Evaluation] step 6400 / 7500 | acc. = 10.28\n[Evaluation] step 6405 / 7500 | acc. = 10.28\n[Evaluation] step 6410 / 7500 | acc. = 10.28\n[Evaluation] step 6415 / 7500 | acc. = 10.29\n[Evaluation] step 6420 / 7500 | acc. = 10.29\n[Evaluation] step 6425 / 7500 | acc. = 10.28\n[Evaluation] step 6430 / 7500 | acc. = 10.28\n[Evaluation] step 6435 / 7500 | acc. = 10.29\n[Evaluation] step 6440 / 7500 | acc. = 10.29\n[Evaluation] step 6445 / 7500 | acc. = 10.30\n[Evaluation] step 6450 / 7500 | acc. = 10.30\n[Evaluation] step 6455 / 7500 | acc. = 10.30\n[Evaluation] step 6460 / 7500 | acc. = 10.30\n[Evaluation] step 6465 / 7500 | acc. = 10.30\n[Evaluation] step 6470 / 7500 | acc. = 10.29\n[Evaluation] step 6475 / 7500 | acc. = 10.29\n[Evaluation] step 6480 / 7500 | acc. = 10.29\n[Evaluation] step 6485 / 7500 | acc. = 10.29\n[Evaluation] step 6490 / 7500 | acc. = 10.29\n[Evaluation] step 6495 / 7500 | acc. = 10.29\n[Evaluation] step 6500 / 7500 | acc. = 10.29\n[Evaluation] step 6505 / 7500 | acc. = 10.29\n[Evaluation] step 6510 / 7500 | acc. = 10.29\n[Evaluation] step 6515 / 7500 | acc. = 10.29\n[Evaluation] step 6520 / 7500 | acc. = 10.29\n[Evaluation] step 6525 / 7500 | acc. = 10.29\n[Evaluation] step 6530 / 7500 | acc. = 10.29\n[Evaluation] step 6535 / 7500 | acc. = 10.29\n[Evaluation] step 6540 / 7500 | acc. = 10.30\n[Evaluation] step 6545 / 7500 | acc. = 10.29\n[Evaluation] step 6550 / 7500 | acc. = 10.30\n[Evaluation] step 6555 / 7500 | acc. = 10.30\n[Evaluation] step 6560 / 7500 | acc. = 10.30\n[Evaluation] step 6565 / 7500 | acc. = 10.30\n[Evaluation] step 6570 / 7500 | acc. = 10.29\n[Evaluation] step 6575 / 7500 | acc. = 10.30\n[Evaluation] step 6580 / 7500 | acc. = 10.30\n[Evaluation] step 6585 / 7500 | acc. = 10.29\n[Evaluation] step 6590 / 7500 | acc. = 10.30\n[Evaluation] step 6595 / 7500 | acc. = 10.30\n[Evaluation] step 6600 / 7500 | acc. = 10.30\n[Evaluation] step 6605 / 7500 | acc. = 10.30\n[Evaluation] step 6610 / 7500 | acc. = 10.30\n[Evaluation] step 6615 / 7500 | acc. = 10.30\n[Evaluation] step 6620 / 7500 | acc. = 10.30\n[Evaluation] step 6625 / 7500 | acc. = 10.30\n[Evaluation] step 6630 / 7500 | acc. = 10.29\n[Evaluation] step 6635 / 7500 | acc. = 10.30\n[Evaluation] step 6640 / 7500 | acc. = 10.30\n[Evaluation] step 6645 / 7500 | acc. = 10.30\n[Evaluation] step 6650 / 7500 | acc. = 10.30\n[Evaluation] step 6655 / 7500 | acc. = 10.30\n[Evaluation] step 6660 / 7500 | acc. = 10.30\n[Evaluation] step 6665 / 7500 | acc. = 10.30\n[Evaluation] step 6670 / 7500 | acc. = 10.30\n[Evaluation] step 6675 / 7500 | acc. = 10.30\n[Evaluation] step 6680 / 7500 | acc. = 10.30\n[Evaluation] step 6685 / 7500 | acc. = 10.30\n[Evaluation] step 6690 / 7500 | acc. = 10.30\n[Evaluation] step 6695 / 7500 | acc. = 10.30\n[Evaluation] step 6700 / 7500 | acc. = 10.30\n[Evaluation] step 6705 / 7500 | acc. = 10.30\n[Evaluation] step 6710 / 7500 | acc. = 10.31\n[Evaluation] step 6715 / 7500 | acc. = 10.31\n[Evaluation] step 6720 / 7500 | acc. = 10.31\n[Evaluation] step 6725 / 7500 | acc. = 10.31\n[Evaluation] step 6730 / 7500 | acc. = 10.32\n[Evaluation] step 6735 / 7500 | acc. = 10.32\n[Evaluation] step 6740 / 7500 | acc. = 10.32\n[Evaluation] step 6745 / 7500 | acc. = 10.32\n[Evaluation] step 6750 / 7500 | acc. = 10.31\n[Evaluation] step 6755 / 7500 | acc. = 10.31\n[Evaluation] step 6760 / 7500 | acc. = 10.31\n[Evaluation] step 6765 / 7500 | acc. = 10.32\n[Evaluation] step 6770 / 7500 | acc. = 10.32\n[Evaluation] step 6775 / 7500 | acc. = 10.32\n[Evaluation] step 6780 / 7500 | acc. = 10.32\n[Evaluation] step 6785 / 7500 | acc. = 10.32\n[Evaluation] step 6790 / 7500 | acc. = 10.32\n[Evaluation] step 6795 / 7500 | acc. = 10.32\n[Evaluation] step 6800 / 7500 | acc. = 10.32\n[Evaluation] step 6805 / 7500 | acc. = 10.32\n[Evaluation] step 6810 / 7500 | acc. = 10.32\n[Evaluation] step 6815 / 7500 | acc. = 10.33\n[Evaluation] step 6820 / 7500 | acc. = 10.33\n[Evaluation] step 6825 / 7500 | acc. = 10.32\n[Evaluation] step 6830 / 7500 | acc. = 10.33\n[Evaluation] step 6835 / 7500 | acc. = 10.33\n[Evaluation] step 6840 / 7500 | acc. = 10.33\n[Evaluation] step 6845 / 7500 | acc. = 10.33\n[Evaluation] step 6850 / 7500 | acc. = 10.33\n[Evaluation] step 6855 / 7500 | acc. = 10.33\n[Evaluation] step 6860 / 7500 | acc. = 10.33\n[Evaluation] step 6865 / 7500 | acc. = 10.33\n[Evaluation] step 6870 / 7500 | acc. = 10.33\n[Evaluation] step 6875 / 7500 | acc. = 10.33\n[Evaluation] step 6880 / 7500 | acc. = 10.33\n[Evaluation] step 6885 / 7500 | acc. = 10.32\n[Evaluation] step 6890 / 7500 | acc. = 10.32\n[Evaluation] step 6895 / 7500 | acc. = 10.32\n[Evaluation] step 6900 / 7500 | acc. = 10.32\n[Evaluation] step 6905 / 7500 | acc. = 10.32\n[Evaluation] step 6910 / 7500 | acc. = 10.31\n[Evaluation] step 6915 / 7500 | acc. = 10.32\n[Evaluation] step 6920 / 7500 | acc. = 10.32\n[Evaluation] step 6925 / 7500 | acc. = 10.32\n[Evaluation] step 6930 / 7500 | acc. = 10.32\n[Evaluation] step 6935 / 7500 | acc. = 10.32\n[Evaluation] step 6940 / 7500 | acc. = 10.32\n[Evaluation] step 6945 / 7500 | acc. = 10.32\n[Evaluation] step 6950 / 7500 | acc. = 10.32\n[Evaluation] step 6955 / 7500 | acc. = 10.32\n[Evaluation] step 6960 / 7500 | acc. = 10.32\n[Evaluation] step 6965 / 7500 | acc. = 10.32\n[Evaluation] step 6970 / 7500 | acc. = 10.32\n[Evaluation] step 6975 / 7500 | acc. = 10.32\n[Evaluation] step 6980 / 7500 | acc. = 10.32\n[Evaluation] step 6985 / 7500 | acc. = 10.32\n[Evaluation] step 6990 / 7500 | acc. = 10.32\n[Evaluation] step 6995 / 7500 | acc. = 10.32\n[Evaluation] step 7000 / 7500 | acc. = 10.32\n[Evaluation] step 7005 / 7500 | acc. = 10.32\n[Evaluation] step 7010 / 7500 | acc. = 10.32\n[Evaluation] step 7015 / 7500 | acc. = 10.32\n[Evaluation] step 7020 / 7500 | acc. = 10.32\n[Evaluation] step 7025 / 7500 | acc. = 10.32\n[Evaluation] step 7030 / 7500 | acc. = 10.32\n[Evaluation] step 7035 / 7500 | acc. = 10.31\n[Evaluation] step 7040 / 7500 | acc. = 10.31\n[Evaluation] step 7045 / 7500 | acc. = 10.31\n[Evaluation] step 7050 / 7500 | acc. = 10.32\n[Evaluation] step 7055 / 7500 | acc. = 10.32\n[Evaluation] step 7060 / 7500 | acc. = 10.32\n[Evaluation] step 7065 / 7500 | acc. = 10.32\n[Evaluation] step 7070 / 7500 | acc. = 10.32\n[Evaluation] step 7075 / 7500 | acc. = 10.32\n[Evaluation] step 7080 / 7500 | acc. = 10.32\n[Evaluation] step 7085 / 7500 | acc. = 10.32\n[Evaluation] step 7090 / 7500 | acc. = 10.32\n[Evaluation] step 7095 / 7500 | acc. = 10.32\n[Evaluation] step 7100 / 7500 | acc. = 10.32\n[Evaluation] step 7105 / 7500 | acc. = 10.33\n[Evaluation] step 7110 / 7500 | acc. = 10.33\n[Evaluation] step 7115 / 7500 | acc. = 10.33\n[Evaluation] step 7120 / 7500 | acc. = 10.33\n[Evaluation] step 7125 / 7500 | acc. = 10.33\n[Evaluation] step 7130 / 7500 | acc. = 10.33\n[Evaluation] step 7135 / 7500 | acc. = 10.32\n[Evaluation] step 7140 / 7500 | acc. = 10.32\n[Evaluation] step 7145 / 7500 | acc. = 10.32\n[Evaluation] step 7150 / 7500 | acc. = 10.32\n[Evaluation] step 7155 / 7500 | acc. = 10.32\n[Evaluation] step 7160 / 7500 | acc. = 10.32\n[Evaluation] step 7165 / 7500 | acc. = 10.32\n[Evaluation] step 7170 / 7500 | acc. = 10.32\n[Evaluation] step 7175 / 7500 | acc. = 10.32\n[Evaluation] step 7180 / 7500 | acc. = 10.32\n[Evaluation] step 7185 / 7500 | acc. = 10.32\n[Evaluation] step 7190 / 7500 | acc. = 10.32\n[Evaluation] step 7195 / 7500 | acc. = 10.32\n[Evaluation] step 7200 / 7500 | acc. = 10.32\n[Evaluation] step 7205 / 7500 | acc. = 10.32\n[Evaluation] step 7210 / 7500 | acc. = 10.32\n[Evaluation] step 7215 / 7500 | acc. = 10.32\n[Evaluation] step 7220 / 7500 | acc. = 10.32\n[Evaluation] step 7225 / 7500 | acc. = 10.32\n[Evaluation] step 7230 / 7500 | acc. = 10.32\n[Evaluation] step 7235 / 7500 | acc. = 10.32\n[Evaluation] step 7240 / 7500 | acc. = 10.32\n[Evaluation] step 7245 / 7500 | acc. = 10.32\n[Evaluation] step 7250 / 7500 | acc. = 10.32\n[Evaluation] step 7255 / 7500 | acc. = 10.32\n[Evaluation] step 7260 / 7500 | acc. = 10.33\n[Evaluation] step 7265 / 7500 | acc. = 10.33\n[Evaluation] step 7270 / 7500 | acc. = 10.33\n[Evaluation] step 7275 / 7500 | acc. = 10.34\n[Evaluation] step 7280 / 7500 | acc. = 10.34\n[Evaluation] step 7285 / 7500 | acc. = 10.34\n[Evaluation] step 7290 / 7500 | acc. = 10.34\n[Evaluation] step 7295 / 7500 | acc. = 10.33\n[Evaluation] step 7300 / 7500 | acc. = 10.33\n[Evaluation] step 7305 / 7500 | acc. = 10.33\n[Evaluation] step 7310 / 7500 | acc. = 10.33\n[Evaluation] step 7315 / 7500 | acc. = 10.33\n[Evaluation] step 7320 / 7500 | acc. = 10.33\n[Evaluation] step 7325 / 7500 | acc. = 10.33\n[Evaluation] step 7330 / 7500 | acc. = 10.33\n[Evaluation] step 7335 / 7500 | acc. = 10.33\n[Evaluation] step 7340 / 7500 | acc. = 10.33\n[Evaluation] step 7345 / 7500 | acc. = 10.33\n[Evaluation] step 7350 / 7500 | acc. = 10.33\n[Evaluation] step 7355 / 7500 | acc. = 10.33\n[Evaluation] step 7360 / 7500 | acc. = 10.33\n[Evaluation] step 7365 / 7500 | acc. = 10.33\n[Evaluation] step 7370 / 7500 | acc. = 10.33\n[Evaluation] step 7375 / 7500 | acc. = 10.33\n[Evaluation] step 7380 / 7500 | acc. = 10.33\n[Evaluation] step 7385 / 7500 | acc. = 10.33\n[Evaluation] step 7390 / 7500 | acc. = 10.34\n[Evaluation] step 7395 / 7500 | acc. = 10.34\n[Evaluation] step 7400 / 7500 | acc. = 10.34\n[Evaluation] step 7405 / 7500 | acc. = 10.34\n[Evaluation] step 7410 / 7500 | acc. = 10.34\n[Evaluation] step 7415 / 7500 | acc. = 10.34\n[Evaluation] step 7420 / 7500 | acc. = 10.34\n[Evaluation] step 7425 / 7500 | acc. = 10.34\n[Evaluation] step 7430 / 7500 | acc. = 10.34\n[Evaluation] step 7435 / 7500 | acc. = 10.35\n[Evaluation] step 7440 / 7500 | acc. = 10.34\n[Evaluation] step 7445 / 7500 | acc. = 10.34\n[Evaluation] step 7450 / 7500 | acc. = 10.34\n[Evaluation] step 7455 / 7500 | acc. = 10.35\n[Evaluation] step 7460 / 7500 | acc. = 10.34\n[Evaluation] step 7465 / 7500 | acc. = 10.34\n[Evaluation] step 7470 / 7500 | acc. = 10.34\n[Evaluation] step 7475 / 7500 | acc. = 10.34\n[Evaluation] step 7480 / 7500 | acc. = 10.34\n[Evaluation] step 7485 / 7500 | acc. = 10.34\n[Evaluation] step 7490 / 7500 | acc. = 10.35\n[Evaluation] step 7495 / 7500 | acc. = 10.34\n[Evaluation] step 7500 / 7500 | acc. = 10.35\n\n --------------- Average First Failure Round --------------- \n0.09090909090909091 / 10\n --------------- Overall acc. --------------- \n10.34947132628435\n --------------- Overall VD acc. --------------- \n0.0\n --------------- quest Prog. Acc --------------- \n4.325391005213403\n --------------- Per round Acc --------------- \n1: 0.0 %\n2: 8.326666666666666 %\n3: 8.706666666666667 %\n4: 8.0 %\n5: 5.253333333333334 %\n6: 5.113333333333333 %\n7: 5.28 %\n8: 2.9066666666666667 %\n9: 8.16 %\n10: 0.0 %\n\n --------------- Per quest Type Acc --------------- \nseek-attr-rel-imm: 3.5758323057953145 %\nseek-attr-imm2: 12.285086722714535 %\ncount-obj-rel-early: 0.0 %\ncount-obj-exclude-early: 0.0 %\nexist-obj-exclude-early: 0.0 %\nseek-attr-early: 9.012180131858308 %\nexist-obj-rel-early: 0.0 %\nseek-attr-rel-early: 6.701980654076463 %\nseek-attr-imm: 12.623860483551328 %\nexist-obj-rel-imm: 0.0 %\nexist-obj-rel-imm2: 0.0 %\ncount-all: 0.0 %\nexist-attribute-group: 0.0 %\ncount-other: 0.0 %\nexist-obj-exclude-imm: 0.0 %\nexist-attribute: 0.0 %\nexist-other: 0.0 %\ncount-obj-rel-imm: 0.0 %\ncount-attribute: 0.0 %\ncount-obj-exclude-imm: 0.0 %\ncount-obj-rel-imm2: 0.0 %\ncount-attribute-group: 0.0 %\n\n --------------- Per quest Category Acc --------------- \nseek: 8.624444444444444 %\ncount: 0.0 %\nexist: 0.0 %\n\n --------------- Done --------------- \n\n[INFO] Done ...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}