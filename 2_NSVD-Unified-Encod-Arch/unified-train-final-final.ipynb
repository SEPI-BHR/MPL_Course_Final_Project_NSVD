{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-01-15T08:21:13.081056Z","iopub.status.busy":"2024-01-15T08:21:13.080540Z","iopub.status.idle":"2024-01-15T08:21:13.169248Z","shell.execute_reply":"2024-01-15T08:21:13.168532Z","shell.execute_reply.started":"2024-01-15T08:21:13.081031Z"}},"source":["##### for cleaning the CPU ram\n","import gc\n","gc.collect()\n","\n","%reset -f"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.272150Z","iopub.status.busy":"2024-02-13T14:44:14.271788Z","iopub.status.idle":"2024-02-13T14:44:14.276777Z","shell.execute_reply":"2024-02-13T14:44:14.275537Z","shell.execute_reply.started":"2024-02-13T14:44:14.272122Z"},"trusted":true},"outputs":[],"source":["#for cleaning the GPU ram\n","import torch \n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.278974Z","iopub.status.busy":"2024-02-13T14:44:14.278687Z","iopub.status.idle":"2024-02-13T14:44:14.290861Z","shell.execute_reply":"2024-02-13T14:44:14.290083Z","shell.execute_reply.started":"2024-02-13T14:44:14.278951Z"},"trusted":true},"outputs":[],"source":["TOTAL_ITER = 1000\n","VALID_EVE =100"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.292237Z","iopub.status.busy":"2024-02-13T14:44:14.291948Z","iopub.status.idle":"2024-02-13T14:44:14.302719Z","shell.execute_reply":"2024-02-13T14:44:14.301873Z","shell.execute_reply.started":"2024-02-13T14:44:14.292212Z"},"trusted":true},"outputs":[],"source":["import h5py\n","import json\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","import argparse#***"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.304675Z","iopub.status.busy":"2024-02-13T14:44:14.304386Z","iopub.status.idle":"2024-02-13T14:44:14.312809Z","shell.execute_reply":"2024-02-13T14:44:14.312093Z","shell.execute_reply.started":"2024-02-13T14:44:14.304653Z"},"trusted":true},"outputs":[],"source":["def invertDict(_dict):\n","    return {v: k for k, v in _dict.items()}"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.313954Z","iopub.status.busy":"2024-02-13T14:44:14.313714Z","iopub.status.idle":"2024-02-13T14:44:14.324194Z","shell.execute_reply":"2024-02-13T14:44:14.323290Z","shell.execute_reply.started":"2024-02-13T14:44:14.313932Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogDataset(Dataset):\n","    def __init__(self, dataPath, vocabPath, split, indStart=0, indEnd=-1):\n","        super(ClevrDialogDataset, self).__init__()\n","        self.data = h5py.File(dataPath, \"r\")\n","        with open(vocabPath, \"r\") as f:\n","            self.vocab = json.load(f)\n","        self.vocab[\"idx_text_to_token\"] = invertDict(self.vocab[\"text_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.lenVocabText = len(self.vocab[\"text_token_to_idx\"])\n","        self.lenVocabProg = len(self.vocab[\"prog_token_to_idx\"])\n","\n","        self.split = split\n","        self.indStart = indStart\n","        self.indEnd = indEnd\n","        self.maxSamples = indEnd - indStart\n","        self.maxLenProg = 6\n","\n","    def __len__(self):\n","        raise NotImplementedError\n","\n","    def __getitem__(self, index):\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.325763Z","iopub.status.busy":"2024-02-13T14:44:14.325328Z","iopub.status.idle":"2024-02-13T14:44:14.339361Z","shell.execute_reply":"2024-02-13T14:44:14.338403Z","shell.execute_reply.started":"2024-02-13T14:44:14.325735Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogUnifiedDataset(ClevrDialogDataset):\n","    def __init__(self, dataPath, vocabPath, split, name, train=True, indStart=0, indEnd=-1):\n","        super(ClevrDialogUnifiedDataset, self).__init__(dataPath, vocabPath, split, indStart=indStart, indEnd=indEnd)\n","        #self.captions = torch.LongTensor(np.asarray(self.data[\"captions\"], dtype=np.int64)[indStart: indEnd])\n","        #self.captionsPrgs = torch.LongTensor(np.asarray(self.data[\"captionProgs\"], dtype=np.int64)[indStart: indEnd])\n","\n","        self.questions = torch.LongTensor(np.asarray(self.data[\"questions\"], dtype=np.int64)[indStart: indEnd])\n","        self.quesProgs = torch.LongTensor(np.asarray(self.data[\"questionProgs\"], dtype=np.int64)[indStart: indEnd])\n","        self.questionRounds = torch.LongTensor(np.asarray(self.data[\"questionRounds\"], dtype=np.int64)[indStart: indEnd])\n","        self.questionImgIdx = torch.LongTensor(np.asarray(self.data[\"questionImgIdx\"], dtype=np.int64)[indStart: indEnd])\n","        self.histories = torch.LongTensor(np.asarray(self.data[\"histories\"], dtype=np.int64)[indStart: indEnd])\n","        self.historiesProgs = torch.LongTensor(np.asarray(self.data[\"historiesProg\"], dtype=np.int64)[indStart: indEnd])\n","\n","        self.answers = torch.LongTensor(np.asarray(self.data[\"answers\"], dtype=np.int64)[indStart: indEnd])\n","        self.name = name\n","        self.train = train\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        assert idx < len(self)\n","        question = self.questions[idx]\n","        questionPrg = self.quesProgs[idx]\n","        questionImgIdx = self.questionImgIdx[idx]\n","        questionRound = self.questionRounds[idx]\n","\n","        history = self.histories[idx]\n","        historiesProg = self.historiesProgs[idx]\n","\n","        answer = self.answers[idx]\n","        if self.train:\n","            #return caption, captionPrg, question, questionPrg, questionRound, history, answer\n","            return question, questionPrg, questionRound, history,historiesProg, answer\n","        else:\n","            return question, questionPrg, questionRound, history,historiesProg, answer"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.373515Z","iopub.status.busy":"2024-02-13T14:44:14.373219Z","iopub.status.idle":"2024-02-13T14:44:14.384659Z","shell.execute_reply":"2024-02-13T14:44:14.383774Z","shell.execute_reply.started":"2024-02-13T14:44:14.373490Z"},"trusted":true},"outputs":[],"source":["COLORS = [\"blue\", \"brown\", \"cyan\", \"gray\", \"green\", \"purple\", \"red\", \"yellow\"]\n","MATERIALS = [\"rubber\", \"metal\"]\n","SHAPES = [\"cube\", \"cylinder\", \"sphere\"]\n","SIZES = [\"large\", \"small\"]\n","\n","ATTRIBUTES_ALL = COLORS + MATERIALS + SHAPES + SIZES\n","\n","ANSWER_CANDIDATES = {\n","    # Count questions\n","    \"count-all\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-other\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-all-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-attribute\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-attribure-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-obj-rel-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-rel-imm2\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-rel-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-exclude-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-exclude-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","\n","    # Existence questions\n","    \"exist-other\": [\"yes\", \"no\"],\n","    \"exist-attribute\": [\"yes\", \"no\"],\n","    \"exist-attribute-group\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-imm\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-imm2\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-early\": [\"yes\", \"no\"],\n","    \"exist-obj-exclude-imm\": [\"yes\", \"no\"],\n","    \"exist-obj-exclude-early\": [\"yes\", \"no\"],\n","\n","    # Seek questions\n","    \"seek-attr-imm\": ATTRIBUTES_ALL,\n","    \"seek-attr-imm2\": ATTRIBUTES_ALL,\n","    \"seek-attr-early\": ATTRIBUTES_ALL,\n","    \"seek-attr-sim-early\": ATTRIBUTES_ALL,\n","    \"seek-attr-rel-imm\": ATTRIBUTES_ALL,\n","    \"seek-attr-rel-early\": ATTRIBUTES_ALL,\n","}\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.386839Z","iopub.status.busy":"2024-02-13T14:44:14.386573Z","iopub.status.idle":"2024-02-13T14:44:14.404410Z","shell.execute_reply":"2024-02-13T14:44:14.403598Z","shell.execute_reply.started":"2024-02-13T14:44:14.386812Z"},"trusted":true},"outputs":[],"source":["import json\n","import numpy as np\n","\n","\n","def merge_captions_question_programs(path_cap, path_ques, caption_first=True):\n","    with open(path_cap, \"r\"):\n","        c_progs = path_cap.readlines()\n","    with open(path_ques, \"r\"):\n","        q_progs = path_ques.readlines()\n","\n","    all_merged_progs = []\n","    i = 0\n","    while i < len(q_progs):\n","        cap_idx = i % 11 if caption_first else i % 10\n","        start_idx_p = i + 1 if caption_first else i\n","        end_idx_p = start_idx_p + 12 if caption_first else  start_idx_p + 11\n","        temp = c_progs[cap_idx] + q_progs[start_idx_p, end_idx_p]\n","        all_merged_progs.append(temp)\n","        i = end_idx_p\n","\n","\n","def load_clevr_scenes(scenes_json):\n","    with open(scenes_json) as f:\n","        scenes_raw = json.load(f)\n","    if type(scenes_raw) == dict:\n","        scenes_raw = scenes_raw[\"scenes\"]\n","\n","    scenes = []\n","    for s in scenes_raw:\n","        table = []\n","        for i, o in enumerate(s['objects']):\n","            item = {}\n","            item['id'] = '%d-%d' % (s['image_index'], i)\n","            if '3d_coords' in o:\n","                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n","                                    np.dot(o['3d_coords'], s['directions']['front']),\n","                                    o['3d_coords'][2]]\n","            else:\n","                item['position'] = o['position']\n","            item['color'] = o['color']\n","            item['material'] = o['material']\n","            item['shape'] = o['shape']\n","            item['size'] = o['size']\n","            table.append(item)\n","        scenes.append(table)\n","    return scenes\n","\n","\n","def load_minecraft_scenes(scenes_json):\n","    with open(scenes_json) as f:\n","        scenes_raw = json.load(f)\n","    if type(scenes_raw) == dict:\n","        scenes_raw = scenes_raw[\"scenes\"]\n","\n","    scenes = []\n","    for s in scenes_raw:\n","        table = []\n","        for i, o in enumerate(s['objects']):\n","            item = {}\n","            item['id'] = '%d-%d' % (s['image_index'], i)\n","            if '3d_coords' in o:\n","                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n","                                    np.dot(o['3d_coords'], s['directions']['front']),\n","                                    o['3d_coords'][2]]\n","            else:\n","                item['position'] = o['position']\n","            item['nature'] = o['nature']\n","            item['class'] = o['class']\n","            item['direction'] = \"facing_\"\n","            if o['direction'] == \"front\":\n","                item['direction'] += \"forward\"\n","            elif o['direction'] == \"back\":\n","                item['direction'] += \"backward\"\n","            elif o['direction'] == \"right\":\n","                item['direction'] += \"right\"\n","            elif o['direction'] == \"left\":\n","                item['direction'] += \"left\"\n","            table.append(item)\n","        scenes.append(table)\n","    return scenes"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.476052Z","iopub.status.busy":"2024-02-13T14:44:14.475771Z","iopub.status.idle":"2024-02-13T14:44:14.753529Z","shell.execute_reply":"2024-02-13T14:44:14.752318Z","shell.execute_reply.started":"2024-02-13T14:44:14.476029Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from copy import deepcopy\n","\n","\n","#from executor.clevr_statics import COLORS, MATERIALS, SHAPES, SIZES\n","#from executor.clevr_statics import ANSWER_CANDIDATES as ANSWER_CANDIDATES_CLEVR\n","#from executor.clevr_statics import ATTRIBUTES_ALL as ATTRIBUTES_ALL_CLEVR\n","\n","#from utils_m import load_clevr_scenes\n","\n","\n","class SymbolicExecutorClevr(object):\n","    \"\"\"Symbolic executor for clevr-dialog\n","    \"\"\"\n","    def __init__(self, scenesPath):\n","        super(SymbolicExecutorClevr, self).__init__()\n","        self.functions = {}\n","        self.registerFunctions()\n","        self.uniqueObjFlag = False\n","        self.colors = COLORS\n","        self.materials = MATERIALS\n","        self.shapes = SHAPES\n","        self.sizes = SIZES\n","        self.answer_candidates = ANSWER_CANDIDATES#***\n","        self.attribute_all = ATTRIBUTES_ALL#***\n","        self.scenes = load_clevr_scenes(scenesPath)\n","\n","    def reset(self, sceneIdx):\n","        \"\"\"Resets the scene\n","\n","        Args:\n","            sceneIdx: The index of the new scene\n","        \"\"\"\n","        self.scene = self.scenes[sceneIdx]\n","        for _obj in self.scene:\n","            _obj[\"identifier\"] = None\n","        # store previous objects in a list to better answer\n","        # xxx-imm, xxx-imm2, xxx-group and xxx-early questions.\n","        self.objs = []\n","        self.groups = []\n","        self.visited = []\n","        self.currentObj = None\n","        self.currentGrp = []\n","        self.uniqueObjFlag = False\n","\n","    def registerFunctions(self):\n","        \"\"\"Registers the available functions of the executor.\n","        \"\"\"\n","        # Captions - extreme location\n","        self.functions[\"extreme-right\"] = self.extremeRight\n","        self.functions[\"extreme-left\"] = self.extremeLeft\n","        self.functions[\"extreme-behind\"] = self.extremeBehind\n","        self.functions[\"extreme-front\"] = self.extremeFront\n","        self.functions[\"extreme-center\"] = self.extremeCenter\n","\n","        # Captions - multiple objects\n","        self.functions[\"count-att\"] = self.countAttributeCaption\n","\n","        # Captions - object relations\n","        self.functions[\"obj-relation\"] = self.objRelation\n","\n","        # Captions - unique object\n","        self.functions[\"unique-obj\"] = self.uniqueObject\n","\n","        # Questions - Count\n","        self.functions[\"count-all\"] = self.countAll\n","        self.functions[\"count-other\"] = self.countOther\n","        self.functions[\"count-all-group\"] = self.countAllGroup\n","        self.functions[\"count-attribute\"] = self.countAttribute\n","        self.functions[\"count-attribute-group\"] = self.countAttributeGroup\n","        self.functions[\"count-obj-rel-imm\"] = self.countObjRelImm\n","        self.functions[\"count-obj-rel-imm2\"] = self.countObjRelImm2\n","        self.functions[\"count-obj-rel-early\"] = self.countObjRelEarly\n","        self.functions[\"count-obj-exclude-imm\"] = self.countObjExcludeImm\n","        self.functions[\"count-obj-exclude-early\"] = self.countObjExcludeEarly\n","\n","        # Questions - Exist\n","        self.functions[\"exist-other\"] = self.existOther\n","        self.functions[\"exist-attribute\"] = self.existAttribute\n","        self.functions[\"exist-attribute-group\"] = self.existAttributeGroup\n","        self.functions[\"exist-obj-rel-imm\"] = self.existObjRelImm\n","        self.functions[\"exist-obj-rel-imm2\"] = self.existObjRelImm\n","        self.functions[\"exist-obj-rel-early\"] = self.existObjRelEarly\n","        self.functions[\"exist-obj-exclude-imm\"] = self.existObjExcludeImm\n","        self.functions[\"exist-obj-exclude-early\"] = self.existObjExcludeEarly\n","\n","        # Questions - Seek\n","        self.functions[\"seek-attr-imm\"] = self.seekAttrImm\n","        self.functions[\"seek-attr-imm2\"] = self.seekAttrImm\n","        self.functions[\"seek-attr-early\"] = self.seekAttributeEarly\n","        self.functions[\"seek-attr-rel-imm\"] = self.seekAttributeRelImm\n","        self.functions[\"seek-attr-rel-early\"] = self.seekAttributeRelEarly\n","\n","\n","    ########################################################\n","    #                   Helper functions                   #\n","    ########################################################\n","    def getAttributeType(self, attribute):\n","        assert attribute in self.attribute_all, \"The attribute {} is unkown\".format(\n","            attribute)\n","        if attribute in self.colors:\n","            return \"color\"\n","        elif attribute in self.materials:\n","            return \"material\"\n","        elif attribute in self.shapes:\n","            return \"shape\"\n","        elif attribute in self.sizes:\n","            return \"size\"\n","\n","    def execute(self, functionLabel, functionArgs):\n","        assert functionLabel in self.functions, \"{} is not a valid function\".format(\n","            functionLabel)\n","        function = self.functions[functionLabel]\n","        answer = function(*functionArgs)\n","        return answer\n","\n","    def updateCurrentObj(self, obj):\n","        self.currentObj = obj\n","        objsCopy = deepcopy(self.objs)\n","        for i, _obj in enumerate(objsCopy):\n","            if _obj[\"id\"] == obj[\"id\"]:\n","                del self.objs[i]\n","        # Current obj is always kept at the end of the visited objs\n","        self.objs.append(obj)\n","\n","    def updateVisited(self, obj):\n","        if len(self.visited) == 0:\n","            self.visited.append(obj)\n","        else:\n","            newObjFlag = True\n","            for _obj in self.visited:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    newObjFlag = False\n","                    break\n","            if newObjFlag:\n","                self.visited.append(obj)\n","\n","    def getOther(self):\n","        others = []\n","        if len(self.visited) < len(self.scene):\n","            for _obj in self.scene:\n","                notExisting = True\n","                for __obj in self.visited:\n","                    if __obj[\"id\"] == _obj[\"id\"]:\n","                        notExisting = False\n","                        break\n","                if notExisting:\n","                    others.append(_obj)\n","        return others\n","\n","    def updateIdentifier(self, obj, attribute):\n","        if obj[\"identifier\"] is None:\n","            obj[\"identifier\"] = attribute\n","        else:\n","            identifiers = obj[\"identifier\"].split(\"-\")\n","            if attribute not in identifiers:\n","                identifiers.append(attribute)\n","                obj[\"identifier\"] = \"-\".join(identifiers)\n","\n","\n","    ########################################################\n","    #                   Caption programs                   #\n","    ########################################################\n","\n","    def extremeRight(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        leftToRight = deepcopy(self.scene)\n","        leftToRight.sort(key=lambda o: o[\"position\"][0])\n","        extremeRightObj = leftToRight[-1]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeRightObj[attributeType] == attribute\n","            self.updateIdentifier(extremeRightObj, attribute)\n","\n","        self.updateCurrentObj(extremeRightObj)\n","        self.updateVisited(extremeRightObj)\n","        del leftToRight\n","\n","    def extremeLeft(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        leftToRight = deepcopy(self.scene)\n","        leftToRight.sort(key=lambda o: o[\"position\"][0])\n","        extremeLeftObj = leftToRight[0]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeLeftObj[attributeType] == attribute\n","            self.updateIdentifier(extremeLeftObj, attribute)\n","\n","        self.updateCurrentObj(extremeLeftObj)\n","        self.updateVisited(extremeLeftObj)\n","        del leftToRight\n","\n","    def extremeFront(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        backToFront = deepcopy(self.scene)\n","        backToFront.sort(key=lambda o: o[\"position\"][1])\n","        extremeFrontObj = backToFront[-1]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeFrontObj[attributeType] == attribute\n","            self.updateIdentifier(extremeFrontObj, attribute)\n","\n","        self.updateCurrentObj(extremeFrontObj)\n","        self.updateVisited(extremeFrontObj)\n","        del backToFront\n","\n","    def extremeBehind(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        backToFront = deepcopy(self.scene)\n","        backToFront.sort(key=lambda o: o[\"position\"][1])\n","        extremeBehindObj = backToFront[0]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeBehindObj[attributeType] == attribute\n","            self.updateIdentifier(extremeBehindObj, attribute)\n","\n","        self.updateCurrentObj(extremeBehindObj)\n","        self.updateVisited(extremeBehindObj)\n","        del backToFront\n","\n","    def extremeCenter(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","        numObjs = len(self.scene)\n","\n","        frontToBack = deepcopy(self.scene)\n","        frontToBack.sort(key=lambda o: o[\"position\"][1], reverse=True)\n","\n","        rightToLeft = deepcopy(self.scene)\n","        rightToLeft.sort(key=lambda o: o[\"position\"][0], reverse=True)\n","\n","        prelimenaryCandidates = []\n","\n","        for i, objFrontToBack in enumerate(frontToBack):\n","            numObjsInFront = i\n","            numObjsBehind = len(rightToLeft) - i - 1\n","            if numObjsInFront <= numObjs / 2 and numObjsBehind <= numObjs / 2:\n","                prelimenaryCandidates.append(objFrontToBack)\n","        foundCenter = False\n","        for _obj in prelimenaryCandidates:\n","            for i, objRightToLeft in enumerate(rightToLeft):\n","                if _obj[\"id\"] == objRightToLeft[\"id\"]:\n","                    numObjsToTheRight = i\n","                    numObjsToTheLeft = len(frontToBack) - i - 1\n","                    if numObjsToTheRight <= numObjs / 2 and numObjsToTheLeft <= numObjs / 2:\n","                        foundCenter = True\n","                        for attributeType, attribute in zip(attributeTypes, attributes):\n","                            if _obj[attributeType] != attribute:\n","                                foundCenter = False\n","                                break\n","                        break\n","            if foundCenter:\n","                break\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            self.updateIdentifier(_obj, attribute)\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","        del rightToLeft, frontToBack\n","\n","    def countAttributeCaption(self, attribute):\n","        attributeType = self.getAttributeType(attribute)\n","        objs = []\n","        for _obj in self.scene:\n","            if _obj[attributeType] == attribute:\n","                objs.append(deepcopy(_obj))\n","        for _obj in objs:\n","            self.updateIdentifier(_obj, attribute)\n","        # update the current group\n","        self.currentGrp = objs\n","\n","        # update the visited objects list\n","        for _obj in objs:\n","            self.updateVisited(_obj)\n","\n","    def getAnchorAttribute(self, attribute_1, attribute_2, scene):\n","        # The anchor object is unique. If we filter the object list\n","        # based on the attribute anchor, we must find only one object.\n","        filterAttribute_1 = self.filterAttribute(scene, attribute_1)\n","        if len(filterAttribute_1) == 1:\n","            return attribute_1\n","        else:\n","            return attribute_2\n","\n","    def objRelation(self, attribute, attributeAnchor, relation):\n","        assert relation in [\"left\", \"right\", \"front\", \"behind\"]\n","        # find the anchor object\n","        if attributeAnchor != self.getAnchorAttribute(attribute, attributeAnchor, self.scene):\n","            temp = deepcopy(attribute)\n","            attribute = deepcopy(attributeAnchor)\n","            attributeAnchor = temp\n","            if relation == \"left\":\n","                relation = \"right\"\n","            elif relation == \"right\":\n","                relation = \"left\"\n","            elif relation == \"behind\":\n","                relation = \"front\"\n","            elif relation == \"front\":\n","                relation = \"behind\"\n","\n","        # Order the objects in the scene w.r.t. the relation\n","        sceneCopy = deepcopy(self.scene)\n","\n","        if relation in [\"left\", \"right\"]:\n","            sceneCopy.sort(key=lambda o: o[\"position\"][0])\n","        else:\n","            sceneCopy.sort(key=lambda o: o[\"position\"][1])\n","\n","        # get the anchor object\n","        attributeTypeAnchor = self.getAttributeType(attributeAnchor)\n","        for i, _obj in enumerate(sceneCopy):\n","            if _obj[attributeTypeAnchor] == attributeAnchor:\n","                break\n","        # save the anchor object before the main object\n","        anchorObj = _obj\n","        self.updateIdentifier(anchorObj, attributeAnchor)\n","        self.updateCurrentObj(anchorObj)\n","        self.updateVisited(anchorObj)\n","\n","        if relation in [\"left\", \"behind\"]:\n","            sceneCopy = list(reversed(sceneCopy[:i]))\n","        else:\n","            sceneCopy = sceneCopy[i+1:]\n","\n","        attributeType = self.getAttributeType(attribute)\n","        # get the main object\n","        for _obj in sceneCopy:\n","            # and not equalDicts(_obj, anchorObj):\n","            if _obj[attributeType] == attribute:\n","                break\n","        self.updateIdentifier(_obj, attribute)\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","        del sceneCopy\n","\n","    def uniqueObject(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        for _obj in self.scene:\n","            found = True\n","            for attributeType, attribute in zip(attributeTypes, attributes):\n","                if _obj[attributeType] != attribute:\n","                    found = False\n","                    break\n","\n","            if found:\n","                break\n","        for att in attributes:\n","            self.updateIdentifier(_obj, att)\n","\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","\n","    ######################################## Question Programs ########################################\n","    def filterOutObj(self, scene, obj):\n","        sceneCopy = deepcopy(scene)\n","        for i, _obj in enumerate(scene):\n","            if obj[\"id\"] == _obj[\"id\"]:\n","                break\n","        del sceneCopy[i]\n","        return sceneCopy\n","\n","    def filterAttribute(self, scene, attribute):\n","        attributeType = self.getAttributeType(attribute)\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in scene:\n","            if _obj[attributeType] == attribute:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def excludeAttribute(self, scene, obj, attributeType):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","        for _obj in scene:\n","            if _obj[\"id\"] != obj[\"id\"] and obj[attributeType] == _obj[attributeType]:\n","                filtered.append(_obj)\n","\n","        # Update the visited objects list\n","        if len(filtered) > 0:\n","            for _obj in filtered:\n","                self.updateVisited(_obj)\n","        return filtered\n","\n","    def filterLeft(self, scene, obj):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in self.scene:\n","            # if the x-coordinate of _obj is smaller than the x-coordinate of slef.currentObj,\n","            # then _obj is located to the left of self.currentObj\n","            if _obj[\"position\"][0] < obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterRight(self, scene, obj):\n","        filtered = []\n","        for _obj in self.scene:\n","            # if the x-coordinate of _obj is bigger than the x-coordinate of slef.currentObj,\n","            # then _obj is located to the right of self.currentObj\n","            if _obj[\"position\"][0] > obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterFront(self, scene, obj):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in self.scene:\n","            # if the y-coordinate of _obj is smaller than the y-coordinate of slef.currentObj,\n","            # then _obj is located in front of self.currentObj\n","            if _obj[\"position\"][1] > obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterBehind(self, scene, obj):\n","        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in scene:\n","            # if the y-coordinate of _obj is bigger than the y-coordinate of slef.currentObj,\n","            # then _obj is located behind self.currentObj\n","            if _obj[\"position\"][1] < obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterPosition(self, scene, obj, pos):\n","        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n","        assert pos in [\"left\", \"right\", \"front\", \"behind\"]\n","        if pos == \"left\":\n","            filtered = self.filterLeft(scene, obj)\n","        elif pos == \"right\":\n","            filtered = self.filterRight(scene, obj)\n","        elif pos == \"front\":\n","            filtered = self.filterFront(scene, obj)\n","        elif pos == \"behind\":\n","            filtered = self.filterBehind(scene, obj)\n","\n","        return filtered\n","\n","    ###########################################################################\n","    #                           Counting questions                            #\n","    ###########################################################################\n","    def countAll(self):\n","        self.currentGrp = deepcopy(self.scene)\n","        self.groups.append(deepcopy(self.scene))\n","        return len(self.scene)\n","\n","    def countOther(self):\n","        others = self.getOther()\n","        if len(others) > 0:\n","            self.currentGrp = others\n","            self.groups.append(others)\n","        if len(others) == 1:\n","            obj = others[0]\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    break\n","            self.updateCurrentObj(obj)\n","\n","            self.updateVisited(obj)\n","        return len(others)\n","\n","    def countAllGroup(self):\n","        return len(self.currentGrp)\n","\n","    def countAttribute(self, attribute, updateCurrentObj=True):\n","        filtered = self.filterAttribute(self.scene, attribute)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            self.updateIdentifier(obj, attribute)\n","            self.updateVisited(obj)\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.groups.append(filtered)\n","        self.currentGrp = filtered\n","        return len(filtered)\n","\n","    def countAttributeGroup(self, attribute, updateCurrentObj=True):\n","        filtered = self.filterAttribute(self.currentGrp, attribute)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            self.updateIdentifier(obj, attribute)\n","            self.updateVisited(obj)\n","\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.groups.append(filtered)\n","        self.currentGrp = filtered\n","        return len(filtered)\n","\n","    def countObjRelImm(self, pos, updateCurrentObj=True):\n","        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","                self.uniqueObjFlag = True\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        return len(filtered)\n","\n","    def countObjRelImm2(self, pos):\n","        if self.uniqueObjFlag:\n","            # del self.objs[-1]\n","            self.updateCurrentObj(self.objs[-2])\n","            self.uniqueObjFlag = False\n","        return self.countObjRelImm(pos)\n","\n","    def countObjRelEarly(self, pos, earlyObjAttribute, updateCurrentObj=True):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","        filtered = self.filterPosition(self.scene, objEarly, pos)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        else:\n","            self.updateCurrentObj(objEarly)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    def countObjExcludeImm(self, attributeType, updateCurrentObj=True):\n","        filtered = self.excludeAttribute(\n","            self.scene, self.currentObj, attributeType)\n","        if len(filtered) == 0:\n","            return 0\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    def countObjExcludeEarly(self, attributeType, earlyObjAttribute, updateCurrentObj=True):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n","        if len(filtered) == 0:\n","            return 0\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        else:\n","            self.updateCurrentObj(objEarly)\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    ###########################################################################\n","    #                           Existence questions                           #\n","    ###########################################################################\n","\n","    def existOther(self):\n","        others = self.getOther()\n","        numOther = len(others)\n","        if numOther > 0:\n","            self.currentGrp = others\n","            self.groups.append(others)\n","            for _obj in others:\n","                self.updateVisited(_obj)\n","        return \"yes\" if numOther > 0 else \"no\"\n","\n","    def existAttribute(self, attribute):\n","        filtered = self.filterAttribute(self.scene, attribute)\n","        numAttribute = len(filtered)\n","        if numAttribute == 0:\n","            return \"no\"\n","\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    self.updateIdentifier(_obj, attribute)\n","                    new = False\n","                    break\n","            if new:\n","                self.updateIdentifier(obj, attribute)\n","                self.objs.append(obj)\n","                # self.updateCurrentObj(obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return \"yes\"\n","\n","    def existAttributeGroup(self, attribute):\n","        numAttributeGrp = self.countAttributeGroup(\n","            attribute, updateCurrentObj=False)\n","        return \"yes\" if numAttributeGrp > 0 else \"no\"\n","\n","    def existObjRelImm(self, pos):\n","        numObjs = self.countObjRelImm(pos, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjRelEarly(self, pos, earlyObjAttribute):\n","        numObjs = self.countObjRelEarly(\n","            pos, earlyObjAttribute, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjExcludeImm(self, attributeType):\n","        numObjs = self.countObjExcludeImm(\n","            attributeType, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjExcludeEarly(self, attributeType, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n","        numObjs = len(filtered)\n","        if numObjs == 0:\n","            return \"no\"\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return \"yes\"\n","\n","    ###########################################################################\n","    #                             Seek questions                              #\n","    ###########################################################################\n","\n","    def seekAttrImm(self, attributeType):\n","        assert attributeType in self.currentObj, \"Attributre <{}> is not valid\"\n","        self.updateIdentifier(self.currentObj, self.currentObj[attributeType])\n","        return self.currentObj[attributeType]\n","\n","    def seekAttributeEarly(self, attributeType, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","        self.updateIdentifier(objEarly, objEarly[attributeType])\n","        self.updateCurrentObj(objEarly)\n","        self.updateVisited(objEarly)\n","        return objEarly[attributeType]\n","\n","    def seekAttributeRelImm(self, attributeType, pos):\n","        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n","        if len(filtered) == 0:\n","            return \"none\"\n","        else:\n","            # Get the closest object to slef.obj\n","            if pos == \"left\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[-1]\n","            elif pos == \"right\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[0]\n","            elif pos == \"front\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[0]\n","            elif pos == \"behind\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[-1]\n","\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj[\"identifier\"] = _obj[\"identifier\"]\n","                    break\n","            self.updateIdentifier(obj, obj[attributeType])\n","            self.updateCurrentObj(obj)\n","            self.updateVisited(obj)\n","            return obj[attributeType]\n","\n","    def seekAttributeRelEarly(self, attributeType, pos, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.filterPosition(self.scene, objEarly, pos)\n","        if len(filtered) == 0:\n","            return \"none\"\n","        else:\n","            # Get the closest object to slef.obj\n","            if pos == \"left\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[-1]\n","            elif pos == \"right\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[0]\n","            elif pos == \"front\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[0]\n","            elif pos == \"behind\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[-1]\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj[\"identifier\"] = _obj[\"identifier\"]\n","                    break\n","            self.updateIdentifier(obj, obj[attributeType])\n","            self.updateCurrentObj(obj)\n","            self.updateVisited(obj)\n","            return obj[attributeType]\n","\n"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.756500Z","iopub.status.busy":"2024-02-13T14:44:14.756121Z","iopub.status.idle":"2024-02-13T14:44:14.768572Z","shell.execute_reply":"2024-02-13T14:44:14.767619Z","shell.execute_reply.started":"2024-02-13T14:44:14.756451Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","#import utils_m"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.770187Z","iopub.status.busy":"2024-02-13T14:44:14.769918Z","iopub.status.idle":"2024-02-13T14:44:14.779502Z","shell.execute_reply":"2024-02-13T14:44:14.778588Z","shell.execute_reply.started":"2024-02-13T14:44:14.770164Z"},"trusted":true},"outputs":[],"source":["#!touch \"pkl-small/quastion-train\" res.txt"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.780908Z","iopub.status.busy":"2024-02-13T14:44:14.780634Z","iopub.status.idle":"2024-02-13T14:44:14.813900Z","shell.execute_reply":"2024-02-13T14:44:14.812921Z","shell.execute_reply.started":"2024-02-13T14:44:14.780886Z"},"trusted":true},"outputs":[],"source":["class OptionsC():#changed optiopn class as Option_c to differentiate it with the one belong to question\n","    def __init__(self):\n","        self.parser = argparse.ArgumentParser()\n","        self.initialized = False\n","\n","    def initialize(self):\n","        self.parser.add_argument(\n","            '--mode',\n","            default=\"train\",#*** in the training mode.\n","            # required=True,\n","            type=str,\n","            choices=['train', 'test'],\n","            help='The mode of the experiment')\n","\n","        self.parser.add_argument(\n","            '--run_dir',\n","            default=\"pkl-small/quastion-train\",#for saving the results of the small dataset\n","            # required=True,\n","            type=str,\n","            help='The experiment directory')\n","\n","        self.parser.add_argument(\n","            '--load_checkpoint_path',\n","            default='None',#*** training mode\n","            type=str,\n","            help='The path the the pretrained CaptionNet')\n","\n","        self.parser.add_argument(\n","            '--res_path',\n","            default=\"pkl-small/quastion-train\",#for saving the results of the small dataset\n","            # required=True,\n","            type=str,\n","            help='Path where to log the predicted caption programs')\n","\n","        self.parser.add_argument(\n","            '--gpu_ids',\n","            default='0',\n","            type=str,\n","            help='Id of the gpu to be used')\n","\n","        self.parser.add_argument(\n","            '--seed',\n","            default=42,\n","            type=int,\n","            help='The seed used in training')\n","\n","        self.parser.add_argument(\n","            '--dataPathTr',\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/train_concat_half.h5\",\n","            # required=True,\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n","\n","        self.parser.add_argument(\n","            '--dataPathVal',\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/val_concat_half.h5\",\n","            # required=True,\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n","\n","        self.parser.add_argument(\n","            '--dataPathTest',\n","            # required=True,\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/test_concat_75000.h5\", \n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n","\n","        self.parser.add_argument(\n","            '--vocabPath',\n","            default='/kaggle/input/nsvd-dataset/train_concat/vocab_output.json', #small dataset\n","            # required=True,\n","            type=str,\n","            help='Path to the generated vocabulary')\n","\n","        self.parser.add_argument(\n","            '--batch_size',\n","            default=64,\n","            type=int,\n","            help='Batch size')\n","\n","        self.parser.add_argument(\n","            '--num_workers',\n","            default=0,\n","            type=int,\n","            help='Number of workers for loading')\n","\n","        self.parser.add_argument(\n","            '--num_iters',\n","            #default=5000,\n","            default=TOTAL_ITER,\n","            type=int,\n","            help='Total number of iterations')\n","\n","        self.parser.add_argument(\n","            '--display_every',\n","            default=5,\n","            type=int,\n","            help='Display training information every N iterations')\n","\n","        self.parser.add_argument(\n","            '--debug_every',\n","            default=100,\n","            type=int,\n","            help='Display debug message every N iterations')\n","\n","        self.parser.add_argument(\n","            '--validate_every',\n","            default=VALID_EVE,\n","            #default=200,\n","            type=int,\n","            help='Validate every N iterations')\n","\n","        self.parser.add_argument(\n","            '--shuffle_data',\n","            default=1,\n","            type=int,\n","            help='Activate to shuffle the training data')\n","\n","        self.parser.add_argument(\n","            '--optim',\n","            default='adam',\n","            type=str,\n","            help='The name of the optimizer to be used')\n","\n","        self.parser.add_argument(\n","            '--lr',\n","            default=1e-3, #A version\n","            #default=1e-1,#just change to be synced with the OptionQ\n","            type=float,\n","            help='Base learning rate')\n","\n","        self.parser.add_argument(\n","            '--betas',\n","            default='0.9, 0.98',\n","            type=str,\n","            help='Adam optimizer\\'s betas')\n","\n","        self.parser.add_argument(\n","            '--eps',\n","            default='1e-9',\n","            type=float,\n","            help='Adam optimizer\\'s epsilon')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_marks',\n","            default='50000, 55000',\n","            type=str,\n","            help='Learing rate decay marks')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_factor',\n","            #default=0.5,\n","            default=0.3,\n","            type=float,\n","            help='Learning rate decay factor')\n","\n","        self.parser.add_argument(\n","            '--weight_decay',\n","            default=1e-6, # the original value\n","            #default=1e-2, # To reach to a better accuracy\n","            type=float,\n","            help='Weight decay')\n","\n","        self.parser.add_argument(\n","            '--embedDim',\n","            default=300,\n","            type=int,\n","            help='Embedding dimension')\n","\n","        self.parser.add_argument(\n","            '--hiddenDim',\n","            default=512,\n","            type=int,\n","            help='LSTM hidden dimension')\n","\n","        self.parser.add_argument(\n","            '--numLayers',\n","            default=2,\n","            # default=1,#to sync with the ques train\n","            type=int,\n","            help='Number of hidden LSTM layers')\n","\n","        self.parser.add_argument(\n","            '--dropout',\n","            default=0.1, #original value\n","            # default=0.2, # to make it sync with ques_train\n","            type=float,\n","            help='Dropout value')\n","\n","        self.parser.add_argument(\n","            '--multiHead',\n","            default=8,\n","            type=int,\n","            help='Number of attention heads')\n","\n","        self.parser.add_argument(\n","            '--hiddenSizeHead',\n","            default=64,\n","            type=int,\n","            help='Dimension of each attention head')\n","\n","        self.parser.add_argument(\n","            '--FeedForwardSize',\n","            default=2048,\n","            type=int,\n","            help='Dimension of the feed forward layer')\n","\n","        self.parser.add_argument(\n","            '--FlatMLPSize',\n","            default=512,\n","            type=int,\n","            help='MLP flatten size')\n","\n","        self.parser.add_argument(\n","            '--FlatGlimpses',\n","            default=1,\n","            type=int,\n","            help='Number of flatten glimpses')\n","\n","        self.parser.add_argument(\n","            '--FlatOutSize',\n","            default=512,\n","            type=int,\n","            help='Final attention reduction dimension')\n","\n","        self.parser.add_argument(\n","            '--layers',\n","            default=6,#A'original\n","            #default=8,#to sync with questrain\n","            type=int,\n","            help='Number of self attention layers')\n","\n","        self.parser.add_argument(\n","            '--bidirectional',\n","            default=1,\n","            type=int,\n","            help='Activate to use bidirectional LSTMs')\n","\n","        self.initialized = True\n","\n","    def parse(self):\n","        # initialize parser\n","        if not self.initialized:\n","            self.initialize()\n","       # self.opts = self.parser.parse_args()\n","        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n","\n","        # parse gpu id list\n","        str_gpu_ids = self.opts.gpu_ids.split(',')\n","        self.opts.gpu_ids = []\n","        for str_id in str_gpu_ids:\n","            if str_id.isdigit() and int(str_id) >= 0:\n","                self.opts.gpu_ids.append(int(str_id))\n","        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n","            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n","        else:\n","            print('\\n[INFO] Using cpu ...')\n","            self.opts.gpu_ids = []\n","\n","        # parse the optimizer's betas and lr decay marks\n","        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n","        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n","        for i in range(1, len(lr_decay_marks)):\n","            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n","        self.opts.lr_decay_marks = lr_decay_marks\n","\n","        # print and save options\n","        args = vars(self.opts)\n","        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n","        # for k, v in args.items():\n","            # print('%s: %s' % (str(k), str(v)))\n","\n","        if not os.path.isdir(self.opts.run_dir):\n","            os.makedirs(self.opts.run_dir)\n","        filename = 'opts_c.txt'\n","        file_path = os.path.join(self.opts.run_dir, filename)\n","        with open(file_path, 'wt') as fout:\n","            fout.write('| options\\n')\n","            for k, v in sorted(args.items()):\n","                fout.write('%s: %s\\n' % (str(k), str(v)))\n","        return self.opts\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.817837Z","iopub.status.busy":"2024-02-13T14:44:14.817269Z","iopub.status.idle":"2024-02-13T14:44:14.830213Z","shell.execute_reply":"2024-02-13T14:44:14.829268Z","shell.execute_reply.started":"2024-02-13T14:44:14.817801Z"},"trusted":true},"outputs":[],"source":["import torch\n","import math\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.831922Z","iopub.status.busy":"2024-02-13T14:44:14.831383Z","iopub.status.idle":"2024-02-13T14:44:14.841146Z","shell.execute_reply":"2024-02-13T14:44:14.840283Z","shell.execute_reply.started":"2024-02-13T14:44:14.831888Z"},"trusted":true},"outputs":[],"source":["class FC(nn.Module):\n","    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n","        super(FC, self).__init__()\n","        self.dropout_r = dropout_r\n","        self.use_relu = use_relu\n","\n","        self.linear = nn.Linear(in_size, out_size)\n","\n","        if use_relu:\n","            self.relu = nn.ReLU(inplace=True)\n","\n","        if dropout_r > 0:\n","            self.dropout = nn.Dropout(dropout_r)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","\n","        if self.use_relu:\n","            x = self.relu(x)\n","\n","        if self.dropout_r > 0:\n","            x = self.dropout(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.842786Z","iopub.status.busy":"2024-02-13T14:44:14.842475Z","iopub.status.idle":"2024-02-13T14:44:14.855866Z","shell.execute_reply":"2024-02-13T14:44:14.854970Z","shell.execute_reply.started":"2024-02-13T14:44:14.842758Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n","        super(MLP, self).__init__()\n","\n","        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n","        self.linear = nn.Linear(mid_size, out_size)\n","\n","    def forward(self, x):\n","        return self.linear(self.fc(x))"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.857555Z","iopub.status.busy":"2024-02-13T14:44:14.857223Z","iopub.status.idle":"2024-02-13T14:44:14.866559Z","shell.execute_reply":"2024-02-13T14:44:14.865689Z","shell.execute_reply.started":"2024-02-13T14:44:14.857526Z"},"trusted":true},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, size, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.eps = eps\n","\n","        self.a_2 = nn.Parameter(torch.ones(size))\n","        self.b_2 = nn.Parameter(torch.zeros(size))\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","\n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.868222Z","iopub.status.busy":"2024-02-13T14:44:14.867895Z","iopub.status.idle":"2024-02-13T14:44:14.882793Z","shell.execute_reply":"2024-02-13T14:44:14.881346Z","shell.execute_reply.started":"2024-02-13T14:44:14.868194Z"},"trusted":true},"outputs":[],"source":["class MHAtt(nn.Module):\n","    def __init__(self, opts):\n","        super(MHAtt, self).__init__()\n","        self.opts = opts\n","\n","        self.linear_v = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_k = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_q = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_merge = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","\n","        self.dropout = nn.Dropout(opts.dropout)\n","\n","    def forward(self, v, k, q, mask):\n","        n_batches = q.size(0)\n","\n","        v = self.linear_v(v).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        k = self.linear_k(k).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        q = self.linear_q(q).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        atted = self.att(v, k, q, mask)\n","        atted = atted.transpose(1, 2).contiguous().view(\n","            n_batches,\n","            -1,\n","            self.opts.hiddenDim\n","        )\n","\n","        atted = self.linear_merge(atted)\n","\n","        return atted\n","\n","    def att(self, value, key, query, mask):\n","        d_k = query.size(-1)\n","\n","        scores = torch.matmul(\n","            query, key.transpose(-2, -1)\n","        ) / math.sqrt(d_k)\n","\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, -1e9)\n","\n","        att_map = F.softmax(scores, dim=-1)\n","        att_map = self.dropout(att_map)\n","\n","        return torch.matmul(att_map, value)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.884259Z","iopub.status.busy":"2024-02-13T14:44:14.884003Z","iopub.status.idle":"2024-02-13T14:44:14.897014Z","shell.execute_reply":"2024-02-13T14:44:14.896108Z","shell.execute_reply.started":"2024-02-13T14:44:14.884237Z"},"trusted":true},"outputs":[],"source":["class FFN(nn.Module):\n","    def __init__(self, opts):\n","        super(FFN, self).__init__()\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FeedForwardSize,\n","            out_size=opts.hiddenDim,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.898333Z","iopub.status.busy":"2024-02-13T14:44:14.898071Z","iopub.status.idle":"2024-02-13T14:44:14.908868Z","shell.execute_reply":"2024-02-13T14:44:14.907885Z","shell.execute_reply.started":"2024-02-13T14:44:14.898310Z"},"trusted":true},"outputs":[],"source":["class SA(nn.Module):\n","    def __init__(self, opts):\n","        super(SA, self).__init__()\n","        self.mhatt = MHAtt(opts)\n","        self.ffn = FFN(opts)\n","\n","        self.dropout1 = nn.Dropout(opts.dropout)\n","        self.norm1 = LayerNorm(opts.hiddenDim)\n","\n","        self.dropout2 = nn.Dropout(opts.dropout)\n","        self.norm2 = LayerNorm(opts.hiddenDim)\n","\n","    def forward(self, x, x_mask):\n","        x = self.norm1(x + self.dropout1(\n","            self.mhatt(x, x, x, x_mask)\n","        ))\n","\n","        x = self.norm2(x + self.dropout2(\n","            self.ffn(x)\n","        ))\n","\n","        return x"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.910826Z","iopub.status.busy":"2024-02-13T14:44:14.910111Z","iopub.status.idle":"2024-02-13T14:44:14.926242Z","shell.execute_reply":"2024-02-13T14:44:14.925236Z","shell.execute_reply.started":"2024-02-13T14:44:14.910794Z"},"trusted":true},"outputs":[],"source":["class AttFlat(nn.Module):\n","    def __init__(self, opts):\n","        super(AttFlat, self).__init__()\n","        self.opts = opts\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FlatMLPSize,\n","            out_size=opts.FlatGlimpses,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","        # FLAT_GLIMPSES = 1\n","        self.linear_merge = nn.Linear(\n","            opts.hiddenDim * opts.FlatGlimpses,\n","            opts.FlatOutSize\n","        )\n","\n","    def forward(self, x, x_mask):\n","        att = self.mlp(x)\n","        att = att.masked_fill(\n","            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n","            -1e9\n","        )\n","        att = F.softmax(att, dim=1)\n","\n","        att_list = []\n","        for i in range(self.opts.FlatGlimpses):\n","            att_list.append(\n","                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n","            )\n","\n","        x_atted = torch.cat(att_list, dim=1)\n","        x_atted = self.linear_merge(x_atted)\n","\n","        return x_atted"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.928220Z","iopub.status.busy":"2024-02-13T14:44:14.927893Z","iopub.status.idle":"2024-02-13T14:44:14.948791Z","shell.execute_reply":"2024-02-13T14:44:14.947764Z","shell.execute_reply.started":"2024-02-13T14:44:14.928190Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, opts, textVocabSize):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding_Cap = nn.Embedding(textVocabSize, opts.embedDim)\n","        bidirectional = opts.bidirectional > 0\n","        self.lstmC = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","\n","\n","        self.embedding_Quest = nn.Embedding(textVocabSize, opts.embedDim)\n","        self.lstmQ = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            bidirectional=bidirectional,\n","            batch_first=True\n","        )\n","\n","        self.lstmH = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            bidirectional=bidirectional,\n","            batch_first=True)\n","#++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        if bidirectional:\n","            opts.hiddenDim *= 2\n","            opts.hiddenSizeHead *= 2\n","            opts.FlatOutSize *= 2\n","\n","        self.attCap = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","        self.attFlatCap = AttFlat(opts)\n","        self.fc_Cap = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","#++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","        self.attQues = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","        self.attHist = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","\n","        self.attFlatQuest = AttFlat(opts)\n","        self.fc_Quest = nn.Linear(2 * opts.hiddenDim, opts.hiddenDim)\n","\n","\n","    def capForward(self, cap, hist=None):\n","        capMask = self.make_mask(cap.unsqueeze(2))\n","        cap = self.embedding_Cap(cap)\n","        cap, (_, _) = self.lstmC(cap)\n","        capO = cap.detach().clone()\n","\n","        for attC in self.attCap:\n","            cap = attC(cap, capMask)\n","        # (batchSize, 512)\n","        cap = self.attFlatCap(cap, capMask)\n","        encOut = self.fc_Cap(cap)\n","        return encOut, capO\n","    \n","    def questForward(self, quest, hist):\n","        questMask = self.make_mask(quest.unsqueeze(2))\n","        histMask = self.make_mask(hist.unsqueeze(2))\n","\n","        # quest = F.tanh(self.embedding(quest))\n","        quest = self.embedding_Quest(quest)\n","\n","        quest, (_, _) = self.lstmQ(quest)\n","        questO = quest.detach().clone()\n","\n","        hist = self.embedding_Quest(hist)\n","        hist, (_, _) = self.lstmH(hist)\n","\n","        for attQ, attH in zip(self.attQues, self.attHist):\n","            quest = attQ(quest, questMask)\n","            hist = attH(hist, histMask)\n","        # (batchSize, 512)\n","        quest = self.attFlatQuest(quest, questMask)\n","\n","        # hist: (batchSize, length, 512)\n","        attWeights = torch.sum(torch.mul(hist, quest.unsqueeze(1)), -1)\n","        attWeights = torch.softmax(attWeights, -1)\n","        hist = torch.sum(torch.mul(hist, attWeights.unsqueeze(2)), 1)\n","        encOut = self.fc_Quest(torch.cat([quest, hist], -1))\n","\n","        return encOut, questO\n","\n","    def forward(self, cap, quest, hist):\n","        capEncOut, capO = self.capForward(cap)\n","        questEncOut, questO = self.questForward(quest, hist)\n","\n","        return capEncOut, questEncOut, capO, questO\n","\n","    # Masking\n","    def make_mask(self, feature):\n","        return (torch.sum(\n","            torch.abs(feature),\n","            dim=-1\n","        ) == 0).unsqueeze(1).unsqueeze(2)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.953934Z","iopub.status.busy":"2024-02-13T14:44:14.953679Z","iopub.status.idle":"2024-02-13T14:44:14.970816Z","shell.execute_reply":"2024-02-13T14:44:14.969778Z","shell.execute_reply.started":"2024-02-13T14:44:14.953912Z"},"trusted":true},"outputs":[],"source":["#*** ->for qiansu: copy and paste the whole class\n","class Decoder(nn.Module):\n","    def __init__(self, opts, progVocabSize, maxLen, startID=1, endID=2):\n","        super(Decoder, self).__init__()\n","        self.numLayers = opts.numLayers\n","        self.bidirectional = opts.bidirectional > 0\n","        self.maxLen = maxLen\n","        self.startID = startID\n","        self.endID = endID\n","\n","        self.embedding = nn.Embedding(progVocabSize, opts.embedDim)\n","        self.lstmProg = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=2*opts.hiddenDim if self.bidirectional else opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            #bidirectional=self.bidirectional,#???????\n","        )\n","        hiddenDim = opts.hiddenDim\n","        if self.bidirectional:\n","            hiddenDim *= 2\n","\n","        self.fcAtt = nn.Linear(2*hiddenDim, hiddenDim)\n","        self.fcOut = nn.Linear(hiddenDim, progVocabSize)\n","\n","    def initPrgHidden(self, encOut):\n","        hidden = [encOut for _ in range(self.numLayers)]\n","        hidden = torch.stack(hidden, 0).contiguous()\n","        return hidden, hidden\n","\n","    def forwardStep(self, prog, progH, questO):\n","        #**********************************************our error relates to this prog cause in our case it is not acting as tensor anymore.\n","        batchSize = prog.size(0)\n","        inputDim = questO.size(1)\n","        prog = self.embedding(prog)\n","        outProg, progH = self.lstmProg(prog, progH)\n","\n","        att = torch.bmm(outProg, questO.transpose(1, 2))\n","        att = F.softmax(att.view(-1, inputDim), 1).view(batchSize, -1, inputDim)\n","        context = torch.bmm(att, questO)\n","        # (batchSize, progLength, hiddenDim)\n","        out = F.tanh(self.fcAtt(torch.cat([outProg, context], dim=-1)))\n","\n","        # (batchSize, progLength, progVocabSize)\n","        out = self.fcOut(out)\n","        predSoftmax = F.log_softmax(out, 2)\n","        return predSoftmax, progH\n","\n","    def forward(self, prog, encOut, questO):\n","        progH = self.initPrgHidden(encOut)\n","        predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","\n","        return predSoftmax, progH\n","\n","    def sample(self, encOut, questO):\n","        batchSize = encOut.size(0)\n","        cudaFlag = encOut.is_cuda\n","        progH = self.initPrgHidden(encOut)\n","        # prog = progCopy[:, 0:3]\n","        prog = torch.LongTensor(batchSize, 1).fill_(self.startID)\n","        # prog = torch.cat((progStart, progEnd), -1)\n","        if cudaFlag:\n","            prog = prog.cuda()\n","        outputLogProbs = []\n","        outputTokens = []\n","     \n","\n","        def decode(i, output):\n","            tokens = output.topk(1, dim=-1)[1].view(batchSize, -1)\n","            #print(\"This is inside of the decode local function and this is the tockens=\", tokens)\n","            return tokens\n","\n","        for i in range(self.maxLen):\n","            predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","            prog = decode(i, predSoftmax)\n","            prog_flat = list(chain(*prog))\n","            flat_list = [item.item() for item in prog_flat]\n","\n","        #****************************************my modification\n","            outputTokens.append(flat_list)#new\n","       #print(\"lets check what is inside outputTocken\", outputTokens)    \n","       # print(\"-----------------------------------------\")\n","        return outputTokens, outputLogProbs\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.972743Z","iopub.status.busy":"2024-02-13T14:44:14.972429Z","iopub.status.idle":"2024-02-13T14:44:14.985674Z","shell.execute_reply":"2024-02-13T14:44:14.984787Z","shell.execute_reply.started":"2024-02-13T14:44:14.972720Z"},"trusted":true},"outputs":[],"source":["class SeqToSeqUnified(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(SeqToSeqUnified, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, cap, quest, questProg, capProg, hist):\n","        capEncOut, questEncOut, capO, questO = self.encoder(cap, quest, hist)\n","\n","        # unitEncOut = torch.cat((capEncOut, questEncOut), dim = 0)\n","        #++++++++++++++++++++++++\n","        #print(\"The shape of the capProg\", capProg.shape)\n","        #print(\"The shape of the questProg\", questProg.shape)\n","        #--------------------------\n","        #capProg = capProg[:, :-1]\n","        # unitO = torch.cat((capO, questO), dim = 0)\n","        # unitProg = torch.cat((capProg, questProg), dim = 0)\n","\n","        # predSoftmax, progHC = self.decoder(unitProg, unitEncOut, unitO)\n","        predSoftmaxCap, progHCCap = self.decoder(capProg, capEncOut, capO)\n","        predSoftmaxQuest, progHCQuest = self.decoder(questProg, questEncOut, questO)\n","        # [changed]\n","        predSoftmax = torch.cat((predSoftmaxCap, predSoftmaxQuest), dim = 1)\n","        \n","        # predSoftmax = torch.cat((predSoftmaxCap, predSoftmaxQuest), dim = 0)\n","        return predSoftmax, progHCCap\n","\n","    def sample(self, cap, quest, hist):\n","        with torch.no_grad():\n","            capEncOut, questEncOut, capO, questO  = self.encoder(cap, quest, hist)\n","\n","            outputTokensC, outputLogProbsC = self.decoder.sample(capEncOut, capO)\n","            outputTokensQ, outputLogProbsQ = self.decoder.sample(questEncOut, questO)\n","            \n","            # before: \n","            # outputTokens = torch.cat((torch.tensor(outputTokensC), torch.tensor(outputTokensQ)), dim = 1)\n","        # outputTokens_t = [[row[i] for row in outputTokens] for i in range(len(outputTokens[0]))]\n","        \n","        outputTokens_t_c = [[row[i] for row in outputTokensC] for i in range(len(outputTokensC[0]))]\n","        outputTokens_t_q = [[row[i] for row in outputTokensQ] for i in range(len(outputTokensQ[0]))]\n","\n","        # outputTokens_t = torch.cat((torch.tensor(outputTokens_t_c), torch.tensor(outputTokens_t_q)), dim = 1)\n","        outputTokens_t = torch.cat((torch.tensor(outputTokens_t_q), torch.tensor(outputTokens_t_c)), dim = 1)\n","        return outputTokens_t"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:14.986931Z","iopub.status.busy":"2024-02-13T14:44:14.986687Z","iopub.status.idle":"2024-02-13T14:44:15.000295Z","shell.execute_reply":"2024-02-13T14:44:14.999351Z","shell.execute_reply.started":"2024-02-13T14:44:14.986910Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.optim as Optim\n","from itertools import chain #***"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.001732Z","iopub.status.busy":"2024-02-13T14:44:15.001096Z","iopub.status.idle":"2024-02-13T14:44:15.013907Z","shell.execute_reply":"2024-02-13T14:44:15.013078Z","shell.execute_reply.started":"2024-02-13T14:44:15.001707Z"},"trusted":true},"outputs":[],"source":["class WarmupOptimizer(object):\n","    def __init__(self, lr_base, optimizer, data_size, batch_size):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.lr_base = lr_base\n","        self._rate = 0\n","        self.data_size = data_size\n","        self.batch_size = batch_size\n","\n","    def step(self):\n","        self._step += 1\n","\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","\n","        self.optimizer.step()\n","\n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","\n","    def rate(self, step=None):\n","        if step is None:\n","            step = self._step\n","\n","        if step <= int(self.data_size / self.batch_size * 1):\n","            r = self.lr_base * 1/2.\n","        else:\n","            r = self.lr_base\n","\n","        return r\n","\n","\n","def get_optim(opts, model, data_size, lr_base=None):\n","    if lr_base is None:\n","        lr_base = opts.lr\n","\n","    if opts.optim == 'adam':\n","        optim = Optim.Adam(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                betas=opts.betas,\n","                eps=opts.eps,\n","\n","            )\n","    elif opts.optim == 'rmsprop':\n","        optim = Optim.RMSprop(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                eps=opts.eps,\n","                weight_decay=opts.weight_decay\n","            )\n","    else:\n","        raise ValueError('{} optimizer is not supported'.fromat(opts.optim))\n","    return WarmupOptimizer(\n","        lr_base,\n","        optim,\n","        data_size,\n","        opts.batch_size\n","    )\n","\n","def adjust_lr(optim, decay_r):\n","    optim.lr_base *= decay_r\n"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.015220Z","iopub.status.busy":"2024-02-13T14:44:15.014931Z","iopub.status.idle":"2024-02-13T14:44:15.026593Z","shell.execute_reply":"2024-02-13T14:44:15.025724Z","shell.execute_reply.started":"2024-02-13T14:44:15.015189Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","#import utils_m\n","import torch"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.028236Z","iopub.status.busy":"2024-02-13T14:44:15.027957Z","iopub.status.idle":"2024-02-13T14:44:15.067774Z","shell.execute_reply":"2024-02-13T14:44:15.066723Z","shell.execute_reply.started":"2024-02-13T14:44:15.028214Z"},"trusted":true},"outputs":[],"source":["class OptionsQ():#changed optiopn class as Option_q to differentiate it with the one belong to caption\n","    def __init__(self):\n","        self.parser = argparse.ArgumentParser()\n","        self.initialized = False\n","        \n","\n","    def initialize(self):\n","        self.parser.add_argument(\n","            '--mode',\n","            #required=True,\n","            default='train',#***-> this is for train-concat and train-stack\n","            type=str,\n","            #choices=['train', 'test_with_gt', 'test_with_pred'],\n","            help='The mode of the experiment')\n","        self.parser.add_argument(\n","            '--type',\n","            default= 'q',\n","            help='The encoder type is caption encoder.'\n","        )\n","\n","        self.parser.add_argument(\n","            '--run_dir',\n","            default = '/kaggle/working/',\n","            type=str,\n","            help='The experiment directory')\n","        #***\n","        self.parser.add_argument(\n","            '--useCuda',\n","            default=1,\n","            type=int,\n","            help='hahahaha')\n","        #***\n","       \n","\n","         #***\n","        self.parser.add_argument(\n","            '--text_log_dir',\n","            default=\"/kaggle/working/\",#for saving the results of the small dataset\n","            type=str,\n","            help='File to save the logged text')\n","\n","        self.parser.add_argument(\n","            '--questionNetPath',\n","            default=\"None\",#fixed this it should have not been None.\n","            type=str,\n","            help='Path to the pretrained QuestionNet that will be used for testing.')\n","        #*********\n","        self.parser.add_argument(\n","            '--trainedUnifiedNetPath',\n","            #default=\"/kaggle/working\",\n","            default=\"None\",#fixed this it should have not been None.\n","            type=str,\n","            help='Path to the pretrained trainedUnifiedNetPath that will be used for testing.')\n","        #*********\n","\n","        self.parser.add_argument(\n","            '--captionNetPath',\n","            default= 'None',\n","            type=str,\n","            help='Path to the pretrained CaptionNet that will be used for testing.')\n","\n","        self.parser.add_argument(\n","            '--dialogLen',\n","            default=10,\n","            type=int,\n","            help='Length of the dialogs to be used for testing. We used 10, 15, and 20 in our experiments.')\n","\n","        self.parser.add_argument(\n","            '--last_n_rounds',\n","            default=10,\n","            type=int,\n","            help='Number of the last rounds to consider in the history. We used 1, 2, 3, 4, and 10 in our experiments. ')\n","\n","        self.parser.add_argument(\n","            '--encoderType',\n","            #required=True,\n","            default=1,#***-> this is for question-concat\n","            #default= 2, #*** -> this one is for question-stack\n","            type=int,\n","            choices=[1, 2],\n","            help='Type of the encoder: 1 --> Concat, 2 --> Stack')\n","\n","        self.parser.add_argument(\n","            '--load_checkpoint_path',\n","            default='None',\n","            type=str,\n","            help='Path to a QestionNet checkpoint path to resume training')\n","\n","        self.parser.add_argument(\n","            '--gpu_ids',\n","            default='0',\n","            type=str,\n","            help='Id of the gpu to be used')\n","\n","        self.parser.add_argument(\n","            '--seed',\n","            default=42,\n","            type=int,\n","            help='The seed used in training')\n","\n","        self.parser.add_argument(\n","            '--dataPathTr',\n","            #required=True,\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/train_concat_half.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n","\n","        self.parser.add_argument(\n","            '--dataPathVal',\n","            #required=True,\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/val_concat_half.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n","\n","        self.parser.add_argument(\n","            '--dataPathTest',\n","            #required=True,\n","            default = \"/kaggle/input/nsvd-dataset/Small_Tr_Val_Test_Final/test_concat_75000.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n","\n","        self.parser.add_argument(\n","            '--scenesPath',\n","            #required=True,\n","            default = \"/kaggle/input/nsvd-dataset/data/CLEVR_train_scenes.json\",\n","            type=str,\n","            help='Path to the derendered clevr-dialog scenes')\n","\n","        self.parser.add_argument(\n","            '--vocabPath',\n","            #required=True,\n","            default= \"/kaggle/input/nsvd-dataset/train_concat/vocab_output.json\",#***for the train-mode stack\n","            type=str,\n","            help='Path to the generated vocabulary')\n","        \n","        self.parser.add_argument(\n","            '--vocabTestPath',\n","            #required=True,\n","            default= \"/kaggle/input/nsvd-dataset/test_concat/vocab_output.json\",#***for testing mode\n","            type=str,\n","            help='Path to the generated vocabulary')\n","\n","        self.parser.add_argument(\n","            '--batch_size',\n","            default=64,\n","            type=int,\n","            help='Batch size')\n","\n","        self.parser.add_argument(\n","            '--countFirstFailueRound',\n","            default=0,\n","            type=int,\n","            help='If activated, we count the first failure round')\n","\n","        self.parser.add_argument(\n","            '--maxSamples',\n","            default=-1,\n","            type=int,\n","            help='Maximum number of training samples')\n","\n","        self.parser.add_argument(\n","            '--num_workers',\n","            default=0,\n","            type=int,\n","            help='Number of workers for loading')\n","\n","        self.parser.add_argument(\n","            '--num_iters',\n","            default=TOTAL_ITER,\n","            type=int,\n","            help='Total number of iterations')\n","\n","        self.parser.add_argument(\n","            '--display_every',\n","            default=5,\n","            type=int,\n","            help='Display training information every N iterations')\n","\n","        self.parser.add_argument(\n","            '--validate_every',\n","            default=VALID_EVE,\n","            #default=200,\n","            type=int,\n","            help='Validate every N iterations')\n","\n","        self.parser.add_argument(\n","            '--shuffle_data',\n","            default=1,\n","            type=int,\n","            help='Activate to shuffle the training data')\n","\n","        self.parser.add_argument(\n","            '--optim',\n","            default='adam',\n","            type=str,\n","            help='The name of the optimizer to be used')\n","\n","        self.parser.add_argument(\n","            '--lr',\n","            default=1e-3,\n","            #default=1e-1, # to reach 51\n","            type=float,\n","            help='Base learning rate')\n","\n","        self.parser.add_argument(\n","            '--betas',\n","            default='0.9, 0.98',\n","            type=str,\n","            help='Adam optimizer\\'s betas')\n","\n","        self.parser.add_argument(\n","            '--eps',\n","            default='1e-9',\n","            type=float,\n","            help='Adam optimizer\\'s epsilon')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_marks',\n","            default='50000, 55000',\n","            type=str,\n","            help='Learing rate decay marks')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_factor',\n","            default=0.5,\n","            # default=0.3, #just trying\n","            type=float,\n","            help='Learning rate decay factor')\n","\n","        self.parser.add_argument(\n","            '--weight_decay',\n","            default=1e-6,#original\n","            #default=1e-2,#for reaching more than 51.72 pr:1e-5\n","            type=float,\n","            help='Weight decay')\n","\n","        self.parser.add_argument(\n","            '--embedDim',\n","            default=300,\n","            type=int,\n","            help='Embedding dimension')\n","\n","        self.parser.add_argument(\n","            '--hiddenDim',\n","            default=512,\n","            type=int,\n","            help='LSTM hidden dimension')\n","\n","        self.parser.add_argument(\n","            '--numLayers',\n","            default=2,\n","            # default=1,\n","            type=int,\n","            help='Number of hidden LSTM layers')\n","\n","        self.parser.add_argument(\n","            '--dropout',\n","            default=0.1,\n","            #default=0.2,\n","            type=float,\n","            help='Dropout value')\n","\n","        self.parser.add_argument(\n","            '--multiHead',\n","            default=8,\n","            type=int,\n","            help='Number of attention heads')\n","\n","        self.parser.add_argument(\n","            '--hiddenSizeHead',\n","            default=64,\n","            type=int,\n","            help='Dimension of each attention head')\n","\n","        self.parser.add_argument(\n","            '--FeedForwardSize',\n","            default=2048,\n","            type=int,\n","            help='Dimension of the feed forward layer')\n","\n","        self.parser.add_argument(\n","            '--FlatMLPSize',\n","            default=512,\n","            type=int,\n","            help='MLP flatten size')\n","\n","        self.parser.add_argument(\n","            '--FlatGlimpses',\n","            default=1,\n","            type=int,\n","            help='Number of flatten glimpses')\n","\n","        self.parser.add_argument(\n","            '--FlatOutSize',\n","            default=512,\n","            type=int,\n","            help='Final attention reduction dimension')\n","\n","        self.parser.add_argument(\n","            '--layers',\n","            default=6,\n","            #default=8, #to reach more than 51\n","            type=int,\n","            help='Number of self attention layers')\n","\n","        self.parser.add_argument(\n","            '--bidirectional',\n","            default=1,\n","            type=int,\n","            help='Activate to use bidirectional LSTMs')\n","\n","        self.initialized = True\n","\n","    def parse(self):\n","        # initialize parser\n","        if not self.initialized:\n","            self.initialize()\n","        #self.opts = self.parser.parse_args()#***\n","        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n","        # parse gpu id list\n","        str_gpu_ids = self.opts.gpu_ids.split(',')\n","        self.opts.gpu_ids = []\n","        for str_id in str_gpu_ids:\n","            if str_id.isdigit() and int(str_id) >= 0:\n","                self.opts.gpu_ids.append(int(str_id))\n","        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n","            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n","        else:\n","            print('\\n[INFO] Using cpu ...')\n","            self.opts.gpu_ids = []\n","\n","        # parse the optimizer's betas and lr decay marks\n","        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n","        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n","        for i in range(1, len(lr_decay_marks)):\n","            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n","        self.opts.lr_decay_marks = lr_decay_marks\n","\n","        # print and save options\n","        args = vars(self.opts)\n","        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n","        # for k, v in args.items():\n","            # print('%s: %s' % (str(k), str(v)))\n","\n","        if not os.path.isdir(self.opts.run_dir):\n","            os.makedirs(self.opts.run_dir)\n","        filename = 'opts.txt'\n","        file_path = os.path.join(self.opts.run_dir, filename)\n","        with open(file_path, 'wt') as fout:\n","            fout.write('| options\\n')\n","            for k, v in sorted(args.items()):\n","                fout.write('%s: %s\\n' % (str(k), str(v)))\n","        return self.opts\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.069782Z","iopub.status.busy":"2024-02-13T14:44:15.069174Z","iopub.status.idle":"2024-02-13T14:44:15.082799Z","shell.execute_reply":"2024-02-13T14:44:15.081741Z","shell.execute_reply.started":"2024-02-13T14:44:15.069757Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import json, torch, pickle, copy, time\n","import numpy as np\n","import argparse\n","import torch.nn as nn\n","import torch.utils.data as Data\n","from tensorboardX import SummaryWriter\n","from copy import deepcopy\n","#from clevrDialog_dataset import ClevrDialogQuestionDataset\n","import pickle\n","from tqdm import tqdm\n","\n","#sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n","\n","#from executor.symbolic_executor import SymbolicExecutorClevr, SymbolicExecutorMinecraft\n","#from models import SeqToSeqQ, QuestEncoder_1, QuestEncoder_2, Decoder, CaptionEncoder, SeqToSeqC\n","#from optim import get_optim, adjust_lr\n","#from options_caption_parser import Options as OptionsC\n","#from options_question_parser import Options as OptionsQ"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.084594Z","iopub.status.busy":"2024-02-13T14:44:15.084294Z","iopub.status.idle":"2024-02-13T14:44:15.245082Z","shell.execute_reply":"2024-02-13T14:44:15.244184Z","shell.execute_reply.started":"2024-02-13T14:44:15.084571Z"},"trusted":true},"outputs":[],"source":["class Execution:\n","    def __init__(self, optsQ, optsC):\n","        self.opts_Q = deepcopy(optsQ)\n","        self.opts_C = deepcopy(optsC)\n","        if self.opts_Q.useCuda > 0 and torch.cuda.is_available():\n","            self.device = torch.device(\"cuda:0\")\n","            print(\"[INFO] Using GPU {} ...\".format(torch.cuda.get_device_name(0)))\n","        else:\n","            print(\"[INFO] Using CPU ...\")\n","            self.device = torch.device(\"cpu\")\n","\n","        self.loss_fn = torch.nn.NLLLoss().to(self.device)\n","\n","        print(\"[INFO] Loading dataset ...\")\n","\n","        self.datasetTr = ClevrDialogUnifiedDataset(\n","            self.opts_Q.dataPathTr, self.opts_Q.vocabPath, \"train\", \"All tr data\")\n","        self.datasetVal = ClevrDialogUnifiedDataset(\n","            self.opts_Q.dataPathVal, self.opts_Q.vocabPath, \"val\", \"All val data\", train=False)\n","        self.datasetTest = ClevrDialogUnifiedDataset(\n","            self.opts_Q.dataPathTest, self.opts_Q.vocabTestPath, \"test\", \"All val data\", train=False)\n","           \n","\n","        self.unitNet = constructNet(\n","            self.opts_Q,\n","            self.datasetTr.lenVocabText,\n","            self.datasetTr.lenVocabProg,\n","            self.datasetTr.maxLenProg,\n","        )\n","\n","        # TODO: add argument \"trainedUnifiedNetPath\"\n","        if os.path.isfile(self.opts_Q.trainedUnifiedNetPath):\n","            print('Loading CaptionNet from {}'.format(self.opts_Q.trainedUnifiedNetPath))\n","            state_dict = torch.load(self.opts_Q.trainedUnifiedNetPath)['state_dict']\n","            self.unitNet.load_state_dict(state_dict)\n","\n","        self.unitNet.to(self.device)\n","\n","        # if os.path.isfile(self.opts_Q.load_checkpoint_path):\n","        #     print('Loading questNet from {}'.format(optsQ.load_checkpoint_path))\n","        #     state_dict = torch.load(self.opts_Q.load_checkpoint_path)['state_dict']\n","        #     self.questNet.load_state_dict(state_dict)\n","        total_params_curr = sum(p.numel() for p in self.unitNet.parameters() if p.requires_grad)\n","        print(\"The quest encoder has {} trainable parameters\".format(total_params_curr))\n","\n","        if \"minecraft\" in self.opts_Q.scenesPath:\n","            self.symbolicExecutor = SymbolicExecutorMinecraft(self.opts_Q.scenesPath)\n","        else:\n","            self.symbolicExecutor = SymbolicExecutorClevr(self.opts_Q.scenesPath)\n","\n","        tb_path = os.path.join(self.opts_Q.run_dir, \"tb_logdir\")\n","        if not os.path.isdir(tb_path):\n","            os.makedirs(tb_path)\n","\n","        self.ckpt_path = os.path.join(self.opts_Q.run_dir, \"ckpt_dir\")\n","        if not os.path.isdir(self.ckpt_path):\n","            os.makedirs(self.ckpt_path)\n","        if not os.path.isdir(self.opts_Q.text_log_dir):\n","            os.makedirs(self.opts_Q.text_log_dir)\n","\n","        self.writer = SummaryWriter(tb_path)\n","        self.iter_val = 0\n","\n","        #if os.path.isfile(self.opts_Q.dependenciesPath):\n","           # with open(self.opts_Q.dependenciesPath, \"rb\") as f:\n","                #self.dependencies = pickle.load(f)\n","\n","    def train(self):\n","        self.unitNet.train()\n","\n","        # Define the multi-gpu training if needed\n","        if len(self.opts_Q.gpu_ids) > 1:\n","            self.unitNet = nn.DataParallel(self.unitNet, device_ids=self.opts_Q.gpu_ids)\n","\n","        # Load checkpoint if resume training\n","        if os.path.isfile(self.opts_Q.load_checkpoint_path):\n","            print(\"[INFO] Resume trainig from ckpt {} ...\".format(\n","                self.opts_Q.load_checkpoint_path\n","            ))\n","\n","            # Load the network parameters\n","            ckpt = torch.load(self.opts_Q.load_checkpoint_path)\n","            print(\"[INFO] Checkpoint successfully loaded ...\")\n","            self.unitNet.load_state_dict(ckpt['state_dict'])\n","\n","            # Load the optimizer paramters\n","            optim = get_optim(self.opts_Q, self.unitNet, len(self.datasetTr))  # , ckpt['optim'], lr_base=ckpt['lr_base'])\n","            # optim._step = int(data_size / self.__C.BATCH_SIZE * self.__C.CKPT_EPOCH)\n","            optim.optimizer.load_state_dict(ckpt['optimizer'])\n","            _iter = 0  #  ckpt['last_iter']\n","            epoch = 0  # ckpt['last_epoch']\n","\n","        else:\n","            optim = get_optim(self.opts_Q, self.unitNet, len(self.datasetTr))\n","            _iter = 0\n","            epoch = 0\n","\n","        trainTime = 0\n","        bestValAcc = float(\"-inf\")\n","        bestCkp = 0\n","        # Training loop\n","        while _iter < self.opts_Q.num_iters:\n","\n","            # Learning Rate Decay\n","            if _iter in self.opts_Q.lr_decay_marks:\n","                adjust_lr(optim, self.opts_Q.lr_decay_factor)\n","\n","            # Define multi-thread dataloader\n","            dataloader = Data.DataLoader(\n","                self.datasetTr,\n","                batch_size=self.opts_Q.batch_size,\n","                shuffle=self.opts_Q.shuffle_data,\n","                num_workers=self.opts_Q.num_workers,\n","            )\n","\n","            # Iteration\n","            time_start = 0\n","            time_end = 0\n","            #for batch_iter, (cap, capProg, quest, questProg, questionRound, hist,  _) in enumerate(dataloader):\n","            for batch_iter, (quest, questProg, questionRound, hist, historiesProgs,  _) in enumerate(dataloader):\n","                time_start = time.time()\n","                if _iter >= self.opts_Q.num_iters:\n","                    break\n","                #*************************************\n","                if hist.dim() == 3:\n","                    cap_t = hist.detach()\n","                    cap_t = cap_t[:, 0, :]\n","                    cap_t = cap_t[:, :20]   \n","                    zeros_column = torch.zeros(cap_t.size(0), 1, dtype=cap_t.dtype, device=cap_t.device)\n","                    cap = torch.cat((cap_t, zeros_column), dim=1)                       \n","                elif hist.dim() == 2:\n","                    cap_t = hist.detach()\n","                    cap_t = cap_t[:, :20]\n","                    zeros_column = torch.zeros(cap_t.size(0), 1, dtype=cap_t.dtype, device=cap_t.device)\n","                    cap = torch.cat((cap_t, zeros_column), dim=1)\n","                #************************************\n","                if historiesProgs.dim() == 3:\n","                    capProg = historiesProgs.detach()\n","                    capProg = capProg[:, 0, :]\n","                    capProg = capProg[:, :6].to(self.device)\n","                elif hist.dim() == 2:\n","                    capProg = historiesProgs.detach()\n","                    capProg = capProg[:, :6].to(self.device)\n","                #**************************************\n","                quest = quest.to(self.device)\n","                cap = cap.to(self.device)\n","                if self.opts_Q.last_n_rounds < 10:\n","                    last_n_rounds_batch = []\n","                    for i, r in enumerate(questionRound.tolist()):\n","                        startIdx = max(r - self.opts_Q.last_n_rounds, 0)\n","                        endIdx = max(r, self.opts_Q.last_n_rounds)\n","                        if hist.dim() == 3:\n","                            assert endIdx - startIdx == self.opts_Q.last_n_rounds\n","                            histBatch = hist[i, :, :]\n","                            last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n","                        elif hist.dim() == 2:\n","                            startIdx *= 20\n","                            endIdx *= 20\n","                            histBatch = hist[i, :]\n","                            temp = histBatch[startIdx:endIdx].cpu()\n","                            if r > self.opts_Q.last_n_rounds:\n","                                last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n","                            else:\n","                                last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n","                    hist = torch.stack(last_n_rounds_batch, dim=0)\n","                \n","                hist = hist.to(self.device)\n","                questProg = questProg.to(self.device)\n","                capProg = capProg.to(self.device)\n","\n","                capProg = capProg[:, 1:]\n","                questProg = questProg[:, 1:]\n","                \n","                # progTarget = questProg.clone()\n","                # [changed]\n","                progTarget = torch.cat((questProg, capProg), dim = 1)\n","                progTarget = progTarget.clone()\n","                \n","                optim.zero_grad()\n","\n","                predSoftmax, _ = self.unitNet(cap, quest, questProg, capProg, hist)\n","\n","                loss = self.loss_fn(\n","                    # predSoftmax[:, :-1, :].contiguous().view(-1, predSoftmax.size(2)),\n","                    predSoftmax.contiguous().view(-1, predSoftmax.size(2)),\n","                    progTarget.contiguous().view(-1))\n","                loss.backward()\n","\n","                if _iter % self.opts_Q.validate_every == 0 and _iter > 0:\n","                    valAcc = self.val()\n","                    if valAcc > bestValAcc:\n","                        bestValAcc = valAcc\n","                        bestCkp = _iter\n","                        print(\"\\n[INFO] Checkpointing model @ iter {} with val accuracy {}\\n\".format(_iter, valAcc))\n","                        state = {\n","                            'state_dict': self.unitNet.state_dict(),\n","                            'optimizer': optim.optimizer.state_dict(),\n","                            'lr_base': optim.lr_base,\n","                            'optim': optim.lr_base,\n","                            'last_iter': _iter,\n","                            'last_epoch': epoch,\n","                        }\n","                        # print(\"[debug] state_dict: {}\".format(state['state_dict']))\n","                        # checkpointing\n","                        torch.save(\n","                            state,\n","                            os.path.join(self.ckpt_path, 'ckpt_iter' +'_' + str(valAcc) +'_' + str(_iter) + '.pkl')\n","                        )\n","\n","                # logging\n","                self.writer.add_scalar(\n","                    'train/loss',\n","                    loss.cpu().data.numpy(),\n","                    global_step=_iter)\n","\n","                self.writer.add_scalar(\n","                    'train/lr',\n","                    optim._rate,\n","                    global_step=_iter)\n","                if _iter % self.opts_Q.display_every == 0:\n","                    time_end = time.time()\n","                    trainTime += time_end-time_start\n","\n","                    print(\"\\r[CLEVR-Dialog - %s (%d | %d)][epoch %2d][iter %4d/%4d][runtime %4f] loss: %.4f, lr: %.2e\" % (\n","                        self.datasetTr.name,\n","                        batch_iter,\n","                        len(dataloader),\n","                        epoch,\n","                        _iter,\n","                        self.opts_Q.num_iters,\n","                        trainTime,\n","                        loss.cpu().data.numpy(),\n","                        optim._rate,\n","                    ), end='          ')\n","\n","                optim.step()\n","                _iter += 1\n","\n","            epoch += 1\n","        print(\"[INFO] Avg. epoch time: {} s\".format(trainTime / epoch))\n","        print(\"[INFO] Best model achieved val acc. {} @ iter {}\".format(bestValAcc, bestCkp))\n","\n","    def val(self):\n","        self.unitNet.eval()\n","\n","        total_correct = 0\n","        total = 0\n","\n","        if len(self.opts_Q.gpu_ids) > 1:\n","            self.unitNet = nn.DataParallel(self.unitNet, device_ids=self.opts_Q.gpu_ids)\n","        self.unitNet = self.unitNet.eval()\n","        dataloader = Data.DataLoader(\n","            self.datasetVal,\n","            batch_size=self.opts_Q.batch_size,\n","            shuffle=True,\n","            num_workers=self.opts_Q.num_workers,\n","            pin_memory=False\n","        )\n","        _iterCur = 0\n","        _totalCur = len(dataloader)\n","        \n","        numAllProg = 0\n","        falsePred = 0\n","        \n","        for step, (quest, questPrg,questRounds, history, historiesProg, answer) in enumerate(dataloader):\n","            # print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","            print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","                step,\n","                int(len(dataloader)),\n","            ), end='          ')\n","            \n","            if history.dim() == 3:\n","                cap_t = history.detach()\n","                cap_t = cap_t[:, 0, :]\n","                cap_t = cap_t[:, :20]   \n","                zeros_column = torch.zeros(cap_t.size(0), 1, dtype=cap_t.dtype, device=cap_t.device)\n","                cap = torch.cat((cap_t, zeros_column), dim=1)                       \n","            elif history.dim() == 2:\n","                cap_t = history.detach()\n","                cap_t = cap_t[:, :20]\n","                zeros_column = torch.zeros(cap_t.size(0), 1, dtype=cap_t.dtype, device=cap_t.device)\n","                cap = torch.cat((cap_t, zeros_column), dim=1)\n","                #************************************\n","            if historiesProg.dim() == 3:\n","                capPrg = historiesProg.detach()\n","                capPrg = capPrg[:, 0, :]\n","                capProg = capProg[:, :6].to(self.device)\n","            elif historiesProg.dim() == 2:\n","                capPrg = historiesProg.detach()\n","                capPrg = capPrg[:, :6].to(self.device)\n","                #**************************************\n","\n","            quest = quest.to(self.device)\n","            cap  = cap.to(self.device)   \n","            if self.opts_Q.last_n_rounds is not None:\n","                last_n_rounds_batch = []\n","                for i, r in enumerate(questRounds.tolist()):\n","                    startIdx = max(r - self.opts_Q.last_n_rounds, 0)\n","                    endIdx = max(r, self.opts_Q.last_n_rounds)\n","                    if history.dim() == 3:\n","                        assert endIdx - startIdx == self.opts_Q.last_n_rounds\n","                        histBatch = history[i, :, :]\n","                        last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n","                    elif history.dim() == 2:\n","                        startIdx *= 20\n","                        endIdx *= 20\n","                        histBatch = history[i, :]\n","                        temp = histBatch[startIdx:endIdx]\n","                        if r > self.opts_Q.last_n_rounds:\n","                            last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n","                        else:\n","                            last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n","                history = torch.stack(last_n_rounds_batch, dim=0)\n","            history = history.to(self.device)\n","            questPrg = questPrg.to(self.device)\n","            capPrg = capPrg.to(self.device)\n","            \n","            capPrg = capPrg[:, 1:]\n","            questPrg = questPrg[:, 1:]\n","            \n","            # [changed]\n","            unitProg = torch.cat((capPrg, questPrg), dim = 1)\n","            \n","            #+++\n","\n","            \n","            currProgsToksPred = self.unitNet.sample(cap, quest, history)\n","            currProgsPred = decodeProg(currProgsToksPred, self.datasetVal.vocab[\"idx_prog_to_token\"])\n","            targetProgs = decodeProg(unitProg, self.datasetVal.vocab[\"idx_prog_to_token\"], target=False)\n","\n","            numAllProg += len(capPrg)\n","            numAllProg += len(questPrg)\n","            \n","            questProgsPred = currProgsToksPred[:][:6]\n","            capProgsPred = currProgsToksPred[:][6:]\n","            \n","            for targetProg, predProg in zip(questPrg, questProgsPred):\n","                mainMod = targetProg[0] == predProg[0]\n","                sameLength = len(targetProg) == len(predProg)\n","                sameArgs = False\n","                if sameLength:\n","                    sameArgs = True\n","                    for argTarget in targetProg[1:]:\n","                        if argTarget not in predProg[1:]:\n","                            sameArgs = False\n","                            break\n","\n","                if not (mainMod and sameArgs):\n","                    falsePred += 1\n","                    \n","            for targetProg, predProg in zip(capPrg, capProgsPred):\n","                mainMod = targetProg[0] == predProg[0]\n","                sameLength = len(targetProg) == len(predProg)\n","                sameArgs = False\n","                if sameLength:\n","                    sameArgs = True\n","                    for argTarget in targetProg[1:]:\n","                        if argTarget not in predProg[1:]:\n","                            sameArgs = False\n","                            break\n","\n","                if not (mainMod and sameArgs):\n","                    falsePred += 1\n","            #+++\n","            correct = [1 if pred == gt else 0 for (pred, gt) in zip(currProgsPred, targetProgs)]\n","\n","            correct = sum(correct)\n","            total_correct += correct\n","            total += len(targetProgs)\n","            self.unitNet.train()\n","\n","        # return 100.0 * (total_correct / total)\n","        return (1 - (falsePred / numAllProg)) * 100.0\n","\n","    # Evaluation\n","    def eval_with_gt(self):\n","        # Define the multi-gpu training if needed\n","        all_pred_answers = []\n","        all_gt_answers = []\n","        all_quest_types = []\n","        all_penalties = []\n","        all_pred_programs = []\n","        all_gt_programs = []\n","\n","        first_failure_round = 0\n","        total_correct = 0\n","        total_acc_pen = 0\n","        total = 0\n","        total_curr_prog_correct = 0\n","\n","        if len(self.opts_Q.gpu_ids) > 1:\n","            self.questNet = nn.DataParallel(self.questNet, device_ids=self.opts_Q.gpu_ids)\n","        self.questNet = self.questNet.eval()\n","        self.CaptionNet = self.CaptionNet.eval()\n","        if self.opts_Q.batch_size != self.opts_Q.dialogLen:\n","            print(\"[INFO] Changed batch size from {} to {}\".format(self.opts_Q.batch_size, self.opts_Q.dialogLen))\n","            self.opts_Q.batch_size = self.opts_Q.dialogLen\n","        dataloader = Data.DataLoader(\n","            self.datasetTest,\n","            batch_size=self.opts_Q.batch_size,\n","            shuffle=False,\n","            num_workers=self.opts_Q.num_workers,\n","            pin_memory=False\n","        )\n","        _iterCur = 0\n","        _totalCur = len(dataloader)\n","\n","        for step, (quest, questPrg, questImgIdx, questRounds, history, historiesProg, answer, _) in enumerate(dataloader):\n","            # print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","            #     step + 1,\n","            #     int(data_size / self.opts_Q.batch_size),\n","            # ), end='          ')\n","            # if step >= 5000:\n","            #     break\n","            batchSize = quest.size(0)\n","            quest = quest.to(self.device)\n","            # dependecy = self.dependencies[step*batchSize:(step+1)*batchSize]\n","\n","            if history.dim() == 3:\n","                caption = history.detach()\n","                caption = caption[:, 0, :]\n","                caption = caption[:, :16].to(self.device)\n","            elif history.dim() == 2:\n","                caption = history.detach()\n","                caption = caption[:, :16].to(self.device)\n","            if self.opts_Q.last_n_rounds < 10:\n","                last_n_rounds_batch = []\n","                for i, r in enumerate(questRounds.tolist()):\n","                    startIdx = max(r - self.opts_Q.last_n_rounds, 0)\n","                    endIdx = max(r, self.opts_Q.last_n_rounds)\n","                    if history.dim() == 3:\n","                        assert endIdx - startIdx == self.opts_Q.last_n_rounds\n","                        histBatch = history[i, :, :]\n","                        last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n","                    elif history.dim() == 2:\n","                        startIdx *= 20\n","                        endIdx *= 20\n","                        histBatch = history[i, :]\n","                        temp = histBatch[startIdx:endIdx]\n","                        if r > self.opts_Q.last_n_rounds:\n","                            last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n","                        else:\n","                            last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n","                history = torch.stack(last_n_rounds_batch, dim=0)\n","\n","            history = history.to(self.device)\n","            questPrg = questPrg.to(self.device)\n","            historiesProg = historiesProg.tolist()\n","            questRounds = questRounds.tolist()\n","            answer = answer.tolist()\n","            answers = list(map(lambda a: self.datasetTest.vocab[\"idx_text_to_token\"][a], answer))\n","            questImgIdx = questImgIdx.tolist()\n","            # if \"minecraft\" in self.opts_Q.scenesPath:\n","            #     questImgIdx = [idx - 1 for idx in questImgIdx]\n","            currProgsToksPred = self.questNet.sample(quest, history)\n","            capProgsToksPred = self.CaptionNet.sample(caption)\n","\n","            currProgsPred = decodeProg(currProgsToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])\n","            capProgsPred = decodeProg(capProgsToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])\n","\n","            targetProgs = decodeProg(questPrg, self.datasetTest.vocab[\"idx_prog_to_token\"], target=True)\n","            questTypes = [targetProg[0] for targetProg in targetProgs]\n","            # progHistories = getProgHistories(historiesProg[0], dataset.vocab[\"idx_prog_to_token\"])\n","            progHistories = [getProgHistories(progHistToks, self.datasetTest.vocab[\"idx_prog_to_token\"]) for progHistToks in historiesProg]\n","            pred_answers = []\n","            all_pred_programs.append([capProgsPred[0]] + currProgsPred)\n","            all_gt_programs.append([progHistories[0]] + (targetProgs))\n","\n","            for i in range(batchSize):\n","                # if capProgsPred[i][0] == \"extreme-center\":\n","                #     print(\"bla\")\n","                # print(\"idx = {}\".format(questImgIdx[i]))\n","                ans = self.getPrediction(\n","                    currProgsPred[i],\n","                    capProgsPred[i],\n","                    progHistories[i],\n","                    questImgIdx[i]\n","                )\n","                # if ans == \"Error\":\n","                #     print(capProgsPred[i])\n","                pred_answers.append(ans)\n","            # print(pred_answers)\n","            correct = [1 if pred == ans else 0 for (pred, ans) in zip(pred_answers, answers)]\n","            correct_prog = [1 if pred == ans else 0 for (pred, ans) in zip(currProgsPred, targetProgs)]\n","            idx_false = np.argwhere(np.array(correct) == 0).squeeze(-1)\n","            if idx_false.shape[-1] > 0:\n","                first_failure_round += idx_false[0] + 1\n","            else:\n","                first_failure_round += self.opts_Q.dialogLen + 1\n","\n","            correct = sum(correct)\n","            correct_prog = sum(correct_prog)\n","            total_correct += correct\n","            total_curr_prog_correct += correct_prog\n","            total += len(answers)\n","            all_pred_answers.append(pred_answers)\n","            all_gt_answers.append(answers)\n","            all_quest_types.append(questTypes)\n","            penalty = np.zeros_like(penalty)\n","            all_penalties.append(penalty)\n","            _iterCur += 1\n","            if _iterCur % self.opts_Q.display_every == 0:\n","                print(\"[Evaluation] step {0} / {1} | acc. = {2:.2f}\".format(\n","                    _iterCur, _totalCur, 100.0 * (total_correct / total)))\n","\n","        ffr = 1.0 * (first_failure_round/_totalCur)/(self.opts_Q.dialogLen + 1)\n","\n","        textOut = \"\\n --------------- Average First Failure Round --------------- \\n\"\n","        textOut += \"{} / {}\".format(ffr, self.opts_Q.dialogLen)\n","\n","        # print(total_correct, total)\n","        accuracy = total_correct / total\n","        vd_acc = total_acc_pen / total\n","        curr_prog_acc = total_curr_prog_correct / total\n","        textOut += \"\\n --------------- Overall acc. --------------- \\n\"\n","        textOut += \"{}\".format(100.0 * accuracy)\n","        textOut += \"\\n --------------- Overall VD acc. --------------- \\n\"\n","        textOut += \"{}\".format(100.0 * vd_acc)\n","        textOut += \"\\n --------------- quest Prog. Acc --------------- \\n\"\n","        textOut += \"{}\".format(100.0 * curr_prog_acc)\n","        textOut += get_per_round_acc(\n","            all_pred_answers, all_gt_answers, all_penalties)\n","\n","        textOut += get_per_quest_type_acc(\n","            all_pred_answers, all_gt_answers, all_quest_types, all_penalties)\n","\n","        # textOut += get_per_dependency_type_acc(\n","        #     all_pred_answers, all_gt_answers, all_penalties)\n","\n","        textOut += \"\\n --------------- Done --------------- \\n\"\n","        print(textOut)\n","        fname = self.opts_Q.questNetPath.split(\"/\")[-3] + \"results_{}_{}.txt\".format(self.opts_Q.last_n_rounds, self.opts_Q.dialogLen)\n","        pred_answers_fname = self.opts_Q.questNetPath.split(\"/\")[-3] + \"_pred_answers_{}_{}.pkl\".format(self.opts_Q.last_n_rounds, self.opts_Q.dialogLen)\n","        pred_answers_fname = os.path.join(\"/projects/abdessaied/clevr-dialog/output/pred_answers\", pred_answers_fname)\n","        model_name = \"NSVD_stack\" if \"stack\" in self.opts_Q.questNetPath else \"NSVD_concat\"\n","        experiment_name = \"minecraft\"\n","        # experiment_name += \"_{}\".format(self.opts_Q.dialogLen)\n","        prog_output_fname = os.path.join(\"/projects/abdessaied/clevr-dialog/output/prog_output/{}_{}.pkl\".format(model_name, experiment_name))\n","\n","        fpath = os.path.join(self.opts_Q.text_log_dir, fname)\n","        with open(fpath, \"w\") as f:\n","            f.writelines(textOut)\n","        with open(pred_answers_fname, \"wb\") as f:\n","            pickle.dump(all_pred_answers, f, protocol=pickle.HIGHEST_PROTOCOL)\n","        with open(prog_output_fname, \"wb\") as f:\n","            pickle.dump((all_gt_programs, all_pred_programs, all_pred_answers), f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# Evaluation\n","    def eval_with_pred(self):\n","        # Define the multi-gpu training if needed\n","        all_pred_answers = []\n","        all_gt_answers = []\n","        all_quest_types = []\n","        all_penalties = []\n","\n","        first_failure_round = 0\n","        total_correct = 0\n","        total_acc_pen = 0\n","        total = 0\n","\n","        samples = {}\n","\n","        if len(self.opts_Q.gpu_ids) > 1:\n","            self.questNet = nn.DataParallel(self.questNet, device_ids=self.opts_Q.gpu_ids)\n","        self.questNet = self.questNet.eval()\n","        self.CaptionNet = self.CaptionNet.eval()\n","        if self.opts_Q.batch_size != self.opts_Q.dialogLen:\n","            print(\"[INFO] Changed batch size from {} to {}\".format(self.opts_Q.batch_size, self.opts_Q.dialogLen))\n","            self.opts_Q.batch_size = self.opts_Q.dialogLen\n","        dataloader = Data.DataLoader(\n","            self.datasetTest,\n","            batch_size=self.opts_Q.batch_size,\n","            shuffle=False,\n","            num_workers=self.opts_Q.num_workers,\n","            pin_memory=False\n","        )\n","        \n","        _iterCur = 0\n","        _totalCur = len(dataloader)\n","        step = 0\n","        for step, (quest, questPrg, questImgIdx, questRounds, history, historiesProg, answer) in enumerate(dataloader):\n","            quest = quest.tolist()\n","            quests = decode(quest, self.datasetTest.vocab[\"idx_text_to_token\"], target=True)\n","            quests = list(map(lambda q: \" \".join(q), quests))\n","            targetProgs = decode(questPrg, self.datasetTest.vocab[\"idx_prog_to_token\"], target=True)\n","\n","            questTypes = [targetProg[0] for targetProg in targetProgs]\n","            targetProgs = list(map(lambda q: \" \".join(q), targetProgs))\n","\n","            historiesProg = historiesProg.tolist()\n","            progHistories = [getProgHistories(progHistToks, self.datasetTest.vocab[\"idx_prog_to_token\"]) for progHistToks in historiesProg]\n","\n","            answer = answer.tolist()\n","            answers = list(map(lambda a: self.datasetTest.vocab[\"idx_text_to_token\"][a], answer))\n","            questImgIdx = questImgIdx.tolist()\n","\n","            if self.opts_Q.encoderType == 2:\n","                histories_eval = [history[0, 0, :].tolist()]\n","                caption = history.detach()\n","                caption = caption[0, 0, :].unsqueeze(0)\n","                caption = caption[:, :16].to(self.device)\n","            elif self.opts_Q.encoderType == 1:\n","                caption = history.detach()\n","                histories_eval = [history[0, :20].tolist()]\n","                caption = caption[0, :16].unsqueeze(0).to(self.device)\n","            cap = decode(caption, self.datasetTest.vocab[\"idx_text_to_token\"], target=False)\n","            capProgToksPred = self.CaptionNet.sample(caption)\n","            capProgPred = decode(capProgToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])[0]\n","\n","            pred_answers = []\n","            pred_curr_prog = []\n","            for i, (q, prog_hist, img_idx) in enumerate(zip(quest, progHistories, questImgIdx)):\n","                _round = i + 1\n","                if _round <= self.opts_Q.last_n_rounds:\n","                    start = 0\n","                else:\n","                    start = _round - self.opts_Q.last_n_rounds\n","                end = len(histories_eval)\n","\n","                quest = torch.tensor(q).unsqueeze(0).to(self.device)\n","                if self.opts_Q.encoderType == 3:\n","                    hist = torch.stack([torch.tensor(h) for h in histories_eval[start:end]], dim=0).unsqueeze(0).to(self.device)\n","                elif self.opts_Q.encoderType == 1:\n","                    histories_eval_copy = deepcopy(histories_eval)\n","                    histories_eval_copy[-1].append(self.datasetTest.vocab[\"text_token_to_idx\"][\"<END>\"])\n","                    hist = torch.cat([torch.tensor(h) for h in histories_eval_copy[start:end]], dim=-1).unsqueeze(0).to(self.device)\n","\n","                currProgsToksPred = self.questNet.sample(quest, hist)\n","                currProgsPred = decode(currProgsToksPred, self.datasetTest.vocab[\"idx_prog_to_token\"])[0]\n","                pred_curr_prog.append(\" \".join(currProgsPred))\n","                ans = self.getPrediction(\n","                    currProgsPred,\n","                    capProgPred,\n","                    prog_hist,\n","                    img_idx\n","                    )\n","                ans_idx = self.datasetTest.vocab[\"text_token_to_idx\"].get(\n","                    ans, self.datasetTest.vocab[\"text_token_to_idx\"][\"<UNK>\"])\n","                q[q.index(self.datasetTest.vocab[\"text_token_to_idx\"][\"<END>\"])] = self.datasetTest.vocab[\"text_token_to_idx\"][\"<NULL>\"]\n","                q[-1] = self.datasetTest.vocab[\"text_token_to_idx\"][\"<END>\"]\n","                q.insert(-1, ans_idx)\n","                if self.opts_Q.encoderType == 3:\n","                    histories_eval.append(copy.deepcopy(q))\n","                elif self.opts_Q.encoderType == 0:\n","                    del q[0]\n","                    del q[-1]\n","                    histories_eval.append(copy.deepcopy(q))\n","\n","                pred_answers.append(ans)\n","\n","            correct = [1 if pred == ans else 0 for (pred, ans) in zip(pred_answers, answers)]\n","            idx_false = np.argwhere(np.array(correct) == 0).squeeze(-1)\n","            if idx_false.shape[-1] > 0:\n","                first_failure_round += idx_false[0] + 1\n","            else:\n","                first_failure_round += self.opts_Q.dialogLen + 1\n","\n","            correct = sum(correct)\n","            total_correct += correct\n","            total += len(answers)\n","            all_pred_answers.append(pred_answers)\n","            all_gt_answers.append(answers)\n","            all_quest_types.append(questTypes)\n","            _iterCur += 1\n","            if _iterCur % self.opts_Q.display_every == 0:\n","                print(\"[Evaluation] step {0} / {1} | acc. = {2:.2f}\".format(\n","                    _iterCur, _totalCur, 100.0 * (total_correct / total)\n","                ))\n","            samples[\"{}_{}\".format(questImgIdx[0], (step % 5) + 1)] = {\n","                \"caption\": \" \".join(cap[0]),\n","                \"cap_prog_gt\": \" \".join(progHistories[0][0]),\n","                \"cap_prog_pred\": \" \".join(capProgPred),\n","\n","                \"quests\": quests,\n","                \"curr_progs_gt\": targetProgs,\n","                \"curr_progs_pred\": pred_curr_prog,\n","\n","\n","                \"answers\": answers,\n","                \"preds\": pred_answers,\n","                \"acc\": correct,\n","            }\n","\n","\n","        ffr = 1.0 * self.opts_Q.dialogLen * (first_failure_round/total)\n","\n","        textOut = \"\\n --------------- Average First Failure Round --------------- \\n\"\n","        textOut += \"{} / {}\".format(ffr, self.opts_Q.dialogLen)\n","\n","        # print(total_correct, total)\n","        accuracy = total_correct / total\n","        vd_acc = total_acc_pen / total\n","        textOut += \"\\n --------------- Overall acc. --------------- \\n\"\n","        textOut += \"{}\".format(100.0 * accuracy)\n","        textOut += \"\\n --------------- Overall VD acc. --------------- \\n\"\n","        textOut += \"{}\".format(100.0 * vd_acc)\n","\n","        textOut += get_per_round_acc(\n","            all_pred_answers, all_gt_answers, all_penalties)\n","\n","        textOut += get_per_quest_type_acc(\n","            all_pred_answers, all_gt_answers, all_quest_types, all_penalties)\n","\n","        textOut += \"\\n --------------- Done --------------- \\n\"\n","        print(textOut)\n","        if step >= len(dataloader):\n","            fname = self.opts_Q.questNetPath.split(\"/\")[-3] + \"_results_{}_{}_{}.txt\".format(self.opts_Q.last_n_rounds, self.opts_Q.dialogLen, self.acc_type)\n","            pred_answers_fname = self.opts_Q.questNetPath.split(\"/\")[-3] + \"_pred_answers_{}_{}.pkl\".format(self.opts_Q.last_n_rounds, self.opts_Q.dialogLen)\n","            pred_answers_fname = os.path.join(\"/projects/abdessaied/clevr-dialog/output/pred_answers\", pred_answers_fname)\n","\n","            fpath = os.path.join(self.opts_Q.text_log_dir, fname)\n","            with open(fpath, \"w\") as f:\n","                f.writelines(textOut)\n","            with open(pred_answers_fname, \"wb\") as f:\n","                pickle.dump(all_pred_answers, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def getPrediction(self, currProgPred, capProgPred, historyProg, imgIndex):\n","        self.symbolicExecutor.reset(imgIndex)\n","        # if round one, execute the predicted caption program first then answer the quest\n","        if len(historyProg) == 1:\n","            captionFuncLabel = capProgPred[0]\n","            captionFuncArgs = capProgPred[1:]\n","\n","            questFuncLabel = currProgPred[0]\n","            questFuncArgs = currProgPred[1:]\n","\n","            try:\n","                _ = self.symbolicExecutor.execute(captionFuncLabel, captionFuncArgs)\n","            except:\n","                return \"Error\"\n","\n","            try:\n","                predAnswer = self.symbolicExecutor.execute(questFuncLabel, questFuncArgs)\n","            except:\n","                return \"Error\"\n","\n","        # If it is not the first round, we have to execute the program history and\n","        # then answer the quest.\n","        else:\n","            questFuncLabel = currProgPred[0]\n","            questFuncArgs = currProgPred[1:]\n","            for prg in historyProg:\n","                # prg = prg.split(\" \")\n","                FuncLabel = prg[0]\n","                FuncArgs = prg[1:]\n","                try:\n","                    _ = self.symbolicExecutor.execute(FuncLabel, FuncArgs)\n","                except:\n","                    return \"Error\"\n","\n","            try:\n","                predAnswer = self.symbolicExecutor.execute(questFuncLabel, questFuncArgs)\n","            except:\n","                return \"Error\"\n","        return str(predAnswer)\n","\n","    def run(self, run_mode, epoch=None):\n","        self.set_seed(self.opts_Q.seed)\n","        if run_mode == 'train':\n","            self.train()\n","    \n","        elif run_mode == 'test_with_gt':\n","            print('Testing with gt answers in history')\n","            print('Loading ckpt {}'.format(self.opts_Q.questNetPath))\n","            state_dict = torch.load(self.opts_Q.questNetPath)['state_dict']\n","            self.questNet.load_state_dict(state_dict)\n","            self.eval_with_gt()\n","\n","        elif run_mode == 'test_with_pred':\n","            print('Testing with predicted answers in history')\n","            print('Loading ckpt {}'.format(self.opts_Q.questNetPath))\n","            state_dict = torch.load(self.opts_Q.questNetPath)['state_dict']\n","            self.questNet.load_state_dict(state_dict)\n","            self.eval_with_pred()\n","        else:\n","            exit(-1)\n","\n","    def set_seed(self, seed):\n","        \"\"\"Sets the seed for reproducibility.\n","        Args:\n","            seed (int): The seed used\n","        \"\"\"\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        print('[INFO] Seed set to {}...'.format(seed))\n","\n","\n","def constructquestNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n","    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n","    if opts_Q.encoderType == 1:\n","        encoder = currEncoder_1(opts_Q, lenVocabText)\n","    elif opts_Q.encoderType == 2:\n","        encoder = currEncoder_2(opts_Q, lenVocabText)\n","\n","    net = SeqToSeqQ(encoder, decoder)\n","    return net\n","\n","\n","def constructCaptionNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n","    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n","    encoder = CaptionEncoder(opts_Q, lenVocabText)\n","    net = SeqToSeqC(encoder, decoder)\n","    return net\n","\n","def constructNet(opts_Q, lenVocabText, lenVocabProg, maxLenProg):\n","    decoder = Decoder(opts_Q, lenVocabProg, maxLenProg)\n","    encoder = Encoder(opts_Q, lenVocabText)\n","    net = SeqToSeqUnified(encoder, decoder)\n","    return net\n","\n","def getProgHistories(progHistToks, prgIdxToToken):\n","    progHist = []\n","    temp = []\n","    for tok in progHistToks:\n","        if tok not in [0, 1, 2]:\n","            temp.append(prgIdxToToken[tok])\n","            # del progHistToks[i]\n","        if tok == 2:\n","            # del progHistToks[i]\n","            # progHist.append(\" \".join(temp))\n","            progHist.append(temp)\n","            temp = []\n","    return progHist\n","\n","\n","def getHistoriesFromStack(histToks, textIdxToToken):\n","    histories = \"\\n\"\n","    temp = []\n","    for i, roundToks in enumerate(histToks):\n","        for tok in roundToks:\n","            if tok not in [0, 1, 2]:\n","                temp.append(textIdxToToken[tok])\n","                # del progHistToks[i]\n","            if tok == 2:\n","                # del progHistToks[i]\n","                if i == 0:\n","                    histories += \" \".join(temp) + \".\\n\"\n","                else:\n","                    histories += \" \".join(temp[:-1]) + \"? | {}.\\n\".format(temp[-1])\n","                # histories.append(temp)\n","                temp = []\n","                break\n","    return histories\n","\n","\n","def getHistoriesFromConcat(histToks, textIdxToToken):\n","    histories = []\n","    temp = []\n","    for tok in histToks:\n","        if tok not in [0, 1, 2]:\n","            temp.append(textIdxToToken[tok])\n","            # del progHistToks[i]\n","        if tok == 2:\n","            # del progHistToks[i]\n","            histories.append(\" \".join(temp[:-1]) + \"? | {}\".format(temp[-1]))\n","            # histories.append(temp)\n","            temp = []\n","    return histories\n","\n","\n","def decodeProg(tokens, prgIdxToToken, target=False):\n","    if (target == True):#***\n","        tokensBatch = tokens.tolist()\n","    else:#***\n","        tokensBatch = tokens\n","    progsBatch = []\n","    for tokens in tokensBatch:\n","        prog = []\n","        for tok in tokens:\n","            if tok == 2:  # <END> has index 2\n","                break\n","            prog.append(prgIdxToToken.get(tok))\n","        \n","        if target:\n","            prog = prog[1:]\n","        progsBatch.append(prog)\n","    return progsBatch\n","\n","\n","def printPred(predSoftmax, gts, prgIdxToToken):\n","    assert predSoftmax.size(0) == gts.size(0)\n","    tokens = predSoftmax.topk(1)[1].squeeze(-1)\n","    tokens = tokens.tolist()\n","    gts = gts.tolist()\n","    message = \"\\n ------------------------ \\n\"\n","    for token, gt in zip(tokens, gts):\n","        message += \"Prediction: \"\n","        for tok in token:\n","            message += prgIdxToToken.get(tok) + \" \"\n","        message += \"\\n Target   : \"\n","        for tok in gt:\n","            message += prgIdxToToken.get(tok) + \" \"\n","        message += \"\\n ------------------------ \\n\"\n","    return message\n","\n","\n","def get_per_round_acc(preds, gts, penalties):\n","    res = {}\n","    for img_preds, img_gt, img_pen in zip(preds, gts, penalties):\n","        img_preds = list(img_preds)\n","        img_gt = list(img_gt)\n","        img_pen = list(img_pen)\n","        for i, (pred, gt, pen) in enumerate(zip(img_preds, img_gt, img_pen)):\n","            _round = str(i + 1)\n","            if _round not in res:\n","                res[_round] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            res[_round][\"all\"] += 1\n","            if pred == gt:\n","                res[_round][\"correct\"] += 0.5**pen\n","\n","    textOut = \"\\n --------------- Per round Acc --------------- \\n\"\n","    for k in res:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res[k][\"correct\"]/res[k][\"all\"]))\n","    return textOut\n","\n","\n","def get_per_quest_type_acc(preds, gts, qtypes, penalties):\n","    res1 = {}\n","    res2 = {}\n","\n","    for img_preds, img_gt, img_qtypes, img_pen in zip(preds, gts, qtypes, penalties):\n","        # img_preds = list(img_preds)\n","        # img_gt = list(img_gt)\n","        img_pen = list(img_pen)\n","        for pred, gt, temp, pen in zip(img_preds, img_gt, img_qtypes, img_pen):\n","            if temp not in res1:\n","                res1[temp] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            temp_cat = temp.split(\"-\")[0]\n","            if temp_cat not in res2:\n","                res2[temp_cat] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            res1[temp][\"all\"] += 1\n","            res2[temp_cat][\"all\"] += 1\n","\n","            if pred == gt:\n","                res1[temp][\"correct\"] += 0.5**pen\n","                res2[temp_cat][\"correct\"] += 0.5**pen\n","\n","    textOut = \"\\n --------------- Per quest Type Acc --------------- \\n\"\n","    for k in res1:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res1[k][\"correct\"]/res1[k][\"all\"]))\n","\n","    textOut += \"\\n --------------- Per quest Category Acc --------------- \\n\"\n","    for k in res2:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res2[k][\"correct\"]/res2[k][\"all\"]))\n","    return textOut\n","\n","\n","def decode(tokens, prgIdxToToken, target=False):\n","    if type(tokens) != list:\n","        tokens = tokens.tolist()\n","\n","    progsBatch = []\n","    for token in tokens:\n","        questProg = []\n","        for tok in token:\n","            if tok == 2:  # <END> has index 2\n","                break\n","            questProg.append(prgIdxToToken.get(tok))\n","        if target:\n","            questProg = questProg[1:]\n","        # progsBatch.append(\" \".join(questProg))\n","        progsBatch.append(questProg)\n","    return progsBatch"]},{"cell_type":"raw","metadata":{},"source":[]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.246426Z","iopub.status.busy":"2024-02-13T14:44:15.246156Z","iopub.status.idle":"2024-02-13T14:44:15.253440Z","shell.execute_reply":"2024-02-13T14:44:15.252412Z","shell.execute_reply.started":"2024-02-13T14:44:15.246403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[INFO] Using 1 CUDA device(s) ...\n","\n"," ------------------------------Opts------------------------------\n"]}],"source":["optsC = OptionsC().parse()#***"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.254837Z","iopub.status.busy":"2024-02-13T14:44:15.254556Z","iopub.status.idle":"2024-02-13T14:44:15.264865Z","shell.execute_reply":"2024-02-13T14:44:15.263839Z","shell.execute_reply.started":"2024-02-13T14:44:15.254813Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[INFO] Using 1 CUDA device(s) ...\n","\n"," ------------------------------Opts------------------------------\n"]}],"source":["optsQ = OptionsQ().parse()#***"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:15.266310Z","iopub.status.busy":"2024-02-13T14:44:15.265986Z","iopub.status.idle":"2024-02-13T14:44:42.408771Z","shell.execute_reply":"2024-02-13T14:44:42.407893Z","shell.execute_reply.started":"2024-02-13T14:44:15.266279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Using GPU Tesla T4 ...\n","[INFO] Loading dataset ...\n","The quest encoder has 202484871 trainable parameters\n"]}],"source":["\n","exe = Execution(optsQ, optsC)#***\n"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T14:44:42.410069Z","iopub.status.busy":"2024-02-13T14:44:42.409821Z","iopub.status.idle":"2024-02-13T15:17:53.314581Z","shell.execute_reply":"2024-02-13T15:17:53.313517Z","shell.execute_reply.started":"2024-02-13T14:44:42.410047Z"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Seed set to 42...\n","Evaluation: [step   19/  20]          5)][epoch  0][iter   95/1000][runtime 37.213191] loss: 1.5226, lr: 5.00e-04          \n","[INFO] Checkpointing model @ iter 100 with val accuracy 50.0\n","\n","[CLEVR-Dialog - All tr data (995 | 27325)][epoch  0][iter  995/1000][runtime 501.689706] loss: 1.4922, lr: 5.00e-04          [INFO] Avg. epoch time: 501.6897060871124 s\n","[INFO] Best model achieved val acc. 50.0 @ iter 100\n","[INFO] Done ...\n"]}],"source":["exe.run('train')\n","print(\"[INFO] Done ...\")#***"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4436528,"sourceId":7618584,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
