{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-12-26T14:40:29.325315Z","iopub.status.busy":"2023-12-26T14:40:29.324431Z","iopub.status.idle":"2023-12-26T14:40:29.352608Z","shell.execute_reply":"2023-12-26T14:40:29.351221Z","shell.execute_reply.started":"2023-12-26T14:40:29.325278Z"}},"source":["## **clevrDialog_dataset.py**\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:45.782482Z","iopub.status.busy":"2024-02-13T13:47:45.781635Z","iopub.status.idle":"2024-02-13T13:47:45.986907Z","shell.execute_reply":"2024-02-13T13:47:45.985718Z","shell.execute_reply.started":"2024-02-13T13:47:45.782436Z"},"trusted":true},"outputs":[],"source":["#for cleaning the CPU ram\n","import gc\n","gc.collect()\n","\n","%reset -f"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:45.989285Z","iopub.status.busy":"2024-02-13T13:47:45.988996Z","iopub.status.idle":"2024-02-13T13:47:45.999501Z","shell.execute_reply":"2024-02-13T13:47:45.998793Z","shell.execute_reply.started":"2024-02-13T13:47:45.989260Z"},"trusted":true},"outputs":[],"source":["# path to notebook folder, use os.path.join to concat \n","import os\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.000774Z","iopub.status.busy":"2024-02-13T13:47:46.000495Z","iopub.status.idle":"2024-02-13T13:47:46.012968Z","shell.execute_reply":"2024-02-13T13:47:46.012116Z","shell.execute_reply.started":"2024-02-13T13:47:46.000751Z"},"trusted":true},"outputs":[],"source":["#Here we set variables for number of iterations and validation\n","TOTAL_ITER = 5000\n","VALID_EVE =1000"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.015735Z","iopub.status.busy":"2024-02-13T13:47:46.015401Z","iopub.status.idle":"2024-02-13T13:47:46.023476Z","shell.execute_reply":"2024-02-13T13:47:46.022787Z","shell.execute_reply.started":"2024-02-13T13:47:46.015706Z"},"trusted":true},"outputs":[],"source":["#for cleaning the GPU ram\n","import torch \n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.025508Z","iopub.status.busy":"2024-02-13T13:47:46.024562Z","iopub.status.idle":"2024-02-13T13:47:46.036030Z","shell.execute_reply":"2024-02-13T13:47:46.035296Z","shell.execute_reply.started":"2024-02-13T13:47:46.025476Z"},"trusted":true},"outputs":[],"source":["import h5py\n","import json\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","import argparse#***"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.037457Z","iopub.status.busy":"2024-02-13T13:47:46.037114Z","iopub.status.idle":"2024-02-13T13:47:46.052060Z","shell.execute_reply":"2024-02-13T13:47:46.051382Z","shell.execute_reply.started":"2024-02-13T13:47:46.037422Z"},"trusted":true},"outputs":[],"source":["def invertDict(_dict):\n","    return {v: k for k, v in _dict.items()}"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.053606Z","iopub.status.busy":"2024-02-13T13:47:46.053284Z","iopub.status.idle":"2024-02-13T13:47:46.063013Z","shell.execute_reply":"2024-02-13T13:47:46.062253Z","shell.execute_reply.started":"2024-02-13T13:47:46.053577Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogDataset(Dataset):\n","    def __init__(self, dataPath, vocabPath, split, indStart=0, indEnd=-1):\n","        super(ClevrDialogDataset, self).__init__()\n","        self.data = h5py.File(dataPath, \"r\")\n","        with open(vocabPath, \"r\") as f:\n","            self.vocab = json.load(f)\n","        self.vocab[\"idx_text_to_token\"] = invertDict(self.vocab[\"text_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.lenVocabText = len(self.vocab[\"text_token_to_idx\"])\n","        self.lenVocabProg = len(self.vocab[\"prog_token_to_idx\"])\n","\n","        self.split = split\n","        self.indStart = indStart\n","        self.indEnd = indEnd\n","        self.maxSamples = indEnd - indStart\n","        self.maxLenProg = 6\n","\n","    def __len__(self):\n","        raise NotImplementedError\n","\n","    def __getitem__(self, index):\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.064382Z","iopub.status.busy":"2024-02-13T13:47:46.064052Z","iopub.status.idle":"2024-02-13T13:47:46.078255Z","shell.execute_reply":"2024-02-13T13:47:46.077577Z","shell.execute_reply.started":"2024-02-13T13:47:46.064358Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogQuestionDataset(ClevrDialogDataset):\n","    def __init__(self, dataPath, vocabPath, split, name, train=True, indStart=0, indEnd=-1):\n","        super(ClevrDialogQuestionDataset, self).__init__(dataPath, vocabPath, split, indStart=indStart, indEnd=indEnd)\n","        self.questions = torch.LongTensor(np.asarray(self.data[\"questions\"], dtype=np.int64)[indStart: indEnd])\n","        self.quesProgs = torch.LongTensor(np.asarray(self.data[\"questionProgs\"], dtype=np.int64)[indStart: indEnd])\n","        self.questionRounds = torch.LongTensor(np.asarray(self.data[\"questionRounds\"], dtype=np.int64)[indStart: indEnd])\n","        self.questionImgIdx = torch.LongTensor(np.asarray(self.data[\"questionImgIdx\"], dtype=np.int64)[indStart: indEnd])\n","        self.histories = torch.LongTensor(np.asarray(self.data[\"histories\"], dtype=np.int64)[indStart: indEnd])\n","        self.historiesProgs = torch.LongTensor(np.asarray(self.data[\"historiesProg\"], dtype=np.int64)[indStart: indEnd])\n","\n","        self.answers = torch.LongTensor(np.asarray(self.data[\"answers\"], dtype=np.int64)[indStart: indEnd])\n","        self.name = name\n","        self.train = train\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        assert idx < len(self)\n","        question = self.questions[idx]\n","        questionPrg = self.quesProgs[idx]\n","        questionImgIdx = self.questionImgIdx[idx]\n","        questionRound = self.questionRounds[idx]\n","\n","        history = self.histories[idx]\n","        historiesProg = self.historiesProgs[idx]\n","\n","        answer = self.answers[idx]\n","        if self.train:\n","            return question, history, questionPrg, questionRound, answer\n","        else:\n","            return question, questionPrg, questionImgIdx, questionRound, history, historiesProg, answer"]},{"cell_type":"markdown","metadata":{},"source":["## **Clevr_statistics**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.079822Z","iopub.status.busy":"2024-02-13T13:47:46.079538Z","iopub.status.idle":"2024-02-13T13:47:46.096735Z","shell.execute_reply":"2024-02-13T13:47:46.095911Z","shell.execute_reply.started":"2024-02-13T13:47:46.079799Z"},"trusted":true},"outputs":[],"source":["COLORS = [\"blue\", \"brown\", \"cyan\", \"gray\", \"green\", \"purple\", \"red\", \"yellow\"]\n","MATERIALS = [\"rubber\", \"metal\"]\n","SHAPES = [\"cube\", \"cylinder\", \"sphere\"]\n","SIZES = [\"large\", \"small\"]\n","\n","ATTRIBUTES_ALL = COLORS + MATERIALS + SHAPES + SIZES\n","\n","ANSWER_CANDIDATES = {\n","    # Count questions\n","    \"count-all\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-other\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-all-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-attribute\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-attribure-group\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"],\n","    \"count-obj-rel-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-rel-imm2\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-rel-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-exclude-imm\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","    \"count-obj-exclude-early\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n","\n","    # Existence questions\n","    \"exist-other\": [\"yes\", \"no\"],\n","    \"exist-attribute\": [\"yes\", \"no\"],\n","    \"exist-attribute-group\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-imm\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-imm2\": [\"yes\", \"no\"],\n","    \"exist-obj-rel-early\": [\"yes\", \"no\"],\n","    \"exist-obj-exclude-imm\": [\"yes\", \"no\"],\n","    \"exist-obj-exclude-early\": [\"yes\", \"no\"],\n","\n","    # Seek questions\n","    \"seek-attr-imm\": ATTRIBUTES_ALL,\n","    \"seek-attr-imm2\": ATTRIBUTES_ALL,\n","    \"seek-attr-early\": ATTRIBUTES_ALL,\n","    \"seek-attr-sim-early\": ATTRIBUTES_ALL,\n","    \"seek-attr-rel-imm\": ATTRIBUTES_ALL,\n","    \"seek-attr-rel-early\": ATTRIBUTES_ALL,\n","}\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Utils_m** just a function"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.100589Z","iopub.status.busy":"2024-02-13T13:47:46.100324Z","iopub.status.idle":"2024-02-13T13:47:46.117453Z","shell.execute_reply":"2024-02-13T13:47:46.116609Z","shell.execute_reply.started":"2024-02-13T13:47:46.100567Z"},"trusted":true},"outputs":[],"source":["import json\n","import numpy as np\n","\n","\n","def merge_captions_question_programs(path_cap, path_ques, caption_first=True):\n","    with open(path_cap, \"r\"):\n","        c_progs = path_cap.readlines()\n","    with open(path_ques, \"r\"):\n","        q_progs = path_ques.readlines()\n","\n","    all_merged_progs = []\n","    i = 0\n","    while i < len(q_progs):\n","        cap_idx = i % 11 if caption_first else i % 10\n","        start_idx_p = i + 1 if caption_first else i\n","        end_idx_p = start_idx_p + 12 if caption_first else  start_idx_p + 11\n","        temp = c_progs[cap_idx] + q_progs[start_idx_p, end_idx_p]\n","        all_merged_progs.append(temp)\n","        i = end_idx_p\n","\n","\n","def load_clevr_scenes(scenes_json):\n","    with open(scenes_json) as f:\n","        scenes_raw = json.load(f)\n","    if type(scenes_raw) == dict:\n","        scenes_raw = scenes_raw[\"scenes\"]\n","\n","    scenes = []\n","    for s in scenes_raw:\n","        table = []\n","        for i, o in enumerate(s['objects']):\n","            item = {}\n","            item['id'] = '%d-%d' % (s['image_index'], i)\n","            if '3d_coords' in o:\n","                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n","                                    np.dot(o['3d_coords'], s['directions']['front']),\n","                                    o['3d_coords'][2]]\n","            else:\n","                item['position'] = o['position']\n","            item['color'] = o['color']\n","            item['material'] = o['material']\n","            item['shape'] = o['shape']\n","            item['size'] = o['size']\n","            table.append(item)\n","        scenes.append(table)\n","    return scenes\n","\n","\n","def load_minecraft_scenes(scenes_json):\n","    with open(scenes_json) as f:\n","        scenes_raw = json.load(f)\n","    if type(scenes_raw) == dict:\n","        scenes_raw = scenes_raw[\"scenes\"]\n","\n","    scenes = []\n","    for s in scenes_raw:\n","        table = []\n","        for i, o in enumerate(s['objects']):\n","            item = {}\n","            item['id'] = '%d-%d' % (s['image_index'], i)\n","            if '3d_coords' in o:\n","                item['position'] = [np.dot(o['3d_coords'], s['directions']['right']),\n","                                    np.dot(o['3d_coords'], s['directions']['front']),\n","                                    o['3d_coords'][2]]\n","            else:\n","                item['position'] = o['position']\n","            item['nature'] = o['nature']\n","            item['class'] = o['class']\n","            item['direction'] = \"facing_\"\n","            if o['direction'] == \"front\":\n","                item['direction'] += \"forward\"\n","            elif o['direction'] == \"back\":\n","                item['direction'] += \"backward\"\n","            elif o['direction'] == \"right\":\n","                item['direction'] += \"right\"\n","            elif o['direction'] == \"left\":\n","                item['direction'] += \"left\"\n","            table.append(item)\n","        scenes.append(table)\n","    return scenes"]},{"cell_type":"markdown","metadata":{},"source":["## **Symbolic_executor**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.119637Z","iopub.status.busy":"2024-02-13T13:47:46.119044Z","iopub.status.idle":"2024-02-13T13:47:46.240120Z","shell.execute_reply":"2024-02-13T13:47:46.239442Z","shell.execute_reply.started":"2024-02-13T13:47:46.119566Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from copy import deepcopy\n","\n","\n","\n","class SymbolicExecutorClevr(object):\n","    \"\"\"Symbolic executor for clevr-dialog\n","    \"\"\"\n","    def __init__(self, scenesPath):\n","        super(SymbolicExecutorClevr, self).__init__()\n","        self.functions = {}\n","        self.registerFunctions()\n","        self.uniqueObjFlag = False\n","        self.colors = COLORS\n","        self.materials = MATERIALS\n","        self.shapes = SHAPES\n","        self.sizes = SIZES\n","        self.answer_candidates = ANSWER_CANDIDATES#***\n","        self.attribute_all = ATTRIBUTES_ALL#***\n","        self.scenes = load_clevr_scenes(scenesPath)\n","\n","    def reset(self, sceneIdx):\n","        \"\"\"Resets the scene\n","\n","        Args:\n","            sceneIdx: The index of the new scene\n","        \"\"\"\n","        self.scene = self.scenes[sceneIdx]\n","        for _obj in self.scene:\n","            _obj[\"identifier\"] = None\n","        # store previous objects in a list to better answer\n","        # xxx-imm, xxx-imm2, xxx-group and xxx-early questions.\n","        self.objs = []\n","        self.groups = []\n","        self.visited = []\n","        self.currentObj = None\n","        self.currentGrp = []\n","        self.uniqueObjFlag = False\n","\n","    def registerFunctions(self):\n","        \"\"\"Registers the available functions of the executor.\n","        \"\"\"\n","        # Captions - extreme location\n","        self.functions[\"extreme-right\"] = self.extremeRight\n","        self.functions[\"extreme-left\"] = self.extremeLeft\n","        self.functions[\"extreme-behind\"] = self.extremeBehind\n","        self.functions[\"extreme-front\"] = self.extremeFront\n","        self.functions[\"extreme-center\"] = self.extremeCenter\n","\n","        # Captions - multiple objects\n","        self.functions[\"count-att\"] = self.countAttributeCaption\n","\n","        # Captions - object relations\n","        self.functions[\"obj-relation\"] = self.objRelation\n","\n","        # Captions - unique object\n","        self.functions[\"unique-obj\"] = self.uniqueObject\n","\n","        # Questions - Count\n","        self.functions[\"count-all\"] = self.countAll\n","        self.functions[\"count-other\"] = self.countOther\n","        self.functions[\"count-all-group\"] = self.countAllGroup\n","        self.functions[\"count-attribute\"] = self.countAttribute\n","        self.functions[\"count-attribute-group\"] = self.countAttributeGroup\n","        self.functions[\"count-obj-rel-imm\"] = self.countObjRelImm\n","        self.functions[\"count-obj-rel-imm2\"] = self.countObjRelImm2\n","        self.functions[\"count-obj-rel-early\"] = self.countObjRelEarly\n","        self.functions[\"count-obj-exclude-imm\"] = self.countObjExcludeImm\n","        self.functions[\"count-obj-exclude-early\"] = self.countObjExcludeEarly\n","\n","        # Questions - Exist\n","        self.functions[\"exist-other\"] = self.existOther\n","        self.functions[\"exist-attribute\"] = self.existAttribute\n","        self.functions[\"exist-attribute-group\"] = self.existAttributeGroup\n","        self.functions[\"exist-obj-rel-imm\"] = self.existObjRelImm\n","        self.functions[\"exist-obj-rel-imm2\"] = self.existObjRelImm\n","        self.functions[\"exist-obj-rel-early\"] = self.existObjRelEarly\n","        self.functions[\"exist-obj-exclude-imm\"] = self.existObjExcludeImm\n","        self.functions[\"exist-obj-exclude-early\"] = self.existObjExcludeEarly\n","\n","        # Questions - Seek\n","        self.functions[\"seek-attr-imm\"] = self.seekAttrImm\n","        self.functions[\"seek-attr-imm2\"] = self.seekAttrImm\n","        self.functions[\"seek-attr-early\"] = self.seekAttributeEarly\n","        self.functions[\"seek-attr-rel-imm\"] = self.seekAttributeRelImm\n","        self.functions[\"seek-attr-rel-early\"] = self.seekAttributeRelEarly\n","\n","\n","    ########################################################\n","    #                   Helper functions                   #\n","    ########################################################\n","    def getAttributeType(self, attribute):\n","        assert attribute in self.attribute_all, \"The attribute {} is unkown\".format(\n","            attribute)\n","        if attribute in self.colors:\n","            return \"color\"\n","        elif attribute in self.materials:\n","            return \"material\"\n","        elif attribute in self.shapes:\n","            return \"shape\"\n","        elif attribute in self.sizes:\n","            return \"size\"\n","\n","    def execute(self, functionLabel, functionArgs):\n","        assert functionLabel in self.functions, \"{} is not a valid function\".format(\n","            functionLabel)\n","        function = self.functions[functionLabel]\n","        answer = function(*functionArgs)\n","        return answer\n","\n","    def updateCurrentObj(self, obj):\n","        self.currentObj = obj\n","        objsCopy = deepcopy(self.objs)\n","        for i, _obj in enumerate(objsCopy):\n","            if _obj[\"id\"] == obj[\"id\"]:\n","                del self.objs[i]\n","        # Current obj is always kept at the end of the visited objs\n","        self.objs.append(obj)\n","\n","    def updateVisited(self, obj):\n","        if len(self.visited) == 0:\n","            self.visited.append(obj)\n","        else:\n","            newObjFlag = True\n","            for _obj in self.visited:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    newObjFlag = False\n","                    break\n","            if newObjFlag:\n","                self.visited.append(obj)\n","\n","    def getOther(self):\n","        others = []\n","        if len(self.visited) < len(self.scene):\n","            for _obj in self.scene:\n","                notExisting = True\n","                for __obj in self.visited:\n","                    if __obj[\"id\"] == _obj[\"id\"]:\n","                        notExisting = False\n","                        break\n","                if notExisting:\n","                    others.append(_obj)\n","        return others\n","\n","    def updateIdentifier(self, obj, attribute):\n","        if obj[\"identifier\"] is None:\n","            obj[\"identifier\"] = attribute\n","        else:\n","            identifiers = obj[\"identifier\"].split(\"-\")\n","            if attribute not in identifiers:\n","                identifiers.append(attribute)\n","                obj[\"identifier\"] = \"-\".join(identifiers)\n","\n","\n","    ########################################################\n","    #                   Caption programs                   #\n","    ########################################################\n","\n","    def extremeRight(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        leftToRight = deepcopy(self.scene)\n","        leftToRight.sort(key=lambda o: o[\"position\"][0])\n","        extremeRightObj = leftToRight[-1]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeRightObj[attributeType] == attribute\n","            self.updateIdentifier(extremeRightObj, attribute)\n","\n","        self.updateCurrentObj(extremeRightObj)\n","        self.updateVisited(extremeRightObj)\n","        del leftToRight\n","\n","    def extremeLeft(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        leftToRight = deepcopy(self.scene)\n","       \n","        leftToRight.sort(key=lambda o: o[\"position\"][0])\n","        extremeLeftObj = leftToRight[0]\n","        \n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeLeftObj[attributeType] == attribute\n","            self.updateIdentifier(extremeLeftObj, attribute)\n","\n","        self.updateCurrentObj(extremeLeftObj)\n","        self.updateVisited(extremeLeftObj)\n","        del leftToRight\n","\n","    def extremeFront(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        backToFront = deepcopy(self.scene)\n","        backToFront.sort(key=lambda o: o[\"position\"][1])\n","        extremeFrontObj = backToFront[-1]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","        \n","\n","            assert extremeFrontObj[attributeType] == attribute\n","            self.updateIdentifier(extremeFrontObj, attribute)\n","\n","        self.updateCurrentObj(extremeFrontObj)\n","        self.updateVisited(extremeFrontObj)\n","        del backToFront\n","\n","    def extremeBehind(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        backToFront = deepcopy(self.scene)\n","        backToFront.sort(key=lambda o: o[\"position\"][1])\n","        extremeBehindObj = backToFront[0]\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            assert extremeBehindObj[attributeType] == attribute\n","            self.updateIdentifier(extremeBehindObj, attribute)\n","\n","        self.updateCurrentObj(extremeBehindObj)\n","        self.updateVisited(extremeBehindObj)\n","        del backToFront\n","\n","    def extremeCenter(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","        numObjs = len(self.scene)\n","\n","        frontToBack = deepcopy(self.scene)\n","        frontToBack.sort(key=lambda o: o[\"position\"][1], reverse=True)\n","\n","        rightToLeft = deepcopy(self.scene)\n","        rightToLeft.sort(key=lambda o: o[\"position\"][0], reverse=True)\n","\n","        prelimenaryCandidates = []\n","\n","        for i, objFrontToBack in enumerate(frontToBack):\n","            numObjsInFront = i\n","            numObjsBehind = len(rightToLeft) - i - 1\n","            if numObjsInFront <= numObjs / 2 and numObjsBehind <= numObjs / 2:\n","                prelimenaryCandidates.append(objFrontToBack)\n","        foundCenter = False\n","        for _obj in prelimenaryCandidates:\n","            for i, objRightToLeft in enumerate(rightToLeft):\n","                if _obj[\"id\"] == objRightToLeft[\"id\"]:\n","                    numObjsToTheRight = i\n","                    numObjsToTheLeft = len(frontToBack) - i - 1\n","                    if numObjsToTheRight <= numObjs / 2 and numObjsToTheLeft <= numObjs / 2:\n","                        foundCenter = True\n","                        for attributeType, attribute in zip(attributeTypes, attributes):\n","                            if _obj[attributeType] != attribute:\n","                                foundCenter = False\n","                                break\n","                        break\n","            if foundCenter:\n","                break\n","        for attributeType, attribute in zip(attributeTypes, attributes):\n","            self.updateIdentifier(_obj, attribute)\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","        del rightToLeft, frontToBack\n","\n","    def countAttributeCaption(self, attribute):\n","        attributeType = self.getAttributeType(attribute)\n","        objs = []\n","        for _obj in self.scene:\n","            if _obj[attributeType] == attribute:\n","                objs.append(deepcopy(_obj))\n","        for _obj in objs:\n","            self.updateIdentifier(_obj, attribute)\n","        # update the current group\n","        self.currentGrp = objs\n","\n","        # update the visited objects list\n","        for _obj in objs:\n","            self.updateVisited(_obj)\n","\n","    def getAnchorAttribute(self, attribute_1, attribute_2, scene):\n","        # The anchor object is unique. If we filter the object list\n","        # based on the attribute anchor, we must find only one object.\n","        filterAttribute_1 = self.filterAttribute(scene, attribute_1)\n","        if len(filterAttribute_1) == 1:\n","            return attribute_1\n","        else:\n","            return attribute_2\n","\n","    def objRelation(self, attribute, attributeAnchor, relation):\n","        assert relation in [\"left\", \"right\", \"front\", \"behind\"]\n","        # find the anchor object\n","        if attributeAnchor != self.getAnchorAttribute(attribute, attributeAnchor, self.scene):\n","            temp = deepcopy(attribute)\n","            attribute = deepcopy(attributeAnchor)\n","            attributeAnchor = temp\n","            if relation == \"left\":\n","                relation = \"right\"\n","            elif relation == \"right\":\n","                relation = \"left\"\n","            elif relation == \"behind\":\n","                relation = \"front\"\n","            elif relation == \"front\":\n","                relation = \"behind\"\n","\n","        # Order the objects in the scene w.r.t. the relation\n","        sceneCopy = deepcopy(self.scene)\n","\n","        if relation in [\"left\", \"right\"]:\n","            sceneCopy.sort(key=lambda o: o[\"position\"][0])\n","        else:\n","            sceneCopy.sort(key=lambda o: o[\"position\"][1])\n","\n","        # get the anchor object\n","        attributeTypeAnchor = self.getAttributeType(attributeAnchor)\n","        for i, _obj in enumerate(sceneCopy):\n","            if _obj[attributeTypeAnchor] == attributeAnchor:\n","                break\n","        # save the anchor object before the main object\n","        anchorObj = _obj\n","        self.updateIdentifier(anchorObj, attributeAnchor)\n","        self.updateCurrentObj(anchorObj)\n","        self.updateVisited(anchorObj)\n","\n","        if relation in [\"left\", \"behind\"]:\n","            sceneCopy = list(reversed(sceneCopy[:i]))\n","        else:\n","            sceneCopy = sceneCopy[i+1:]\n","\n","        attributeType = self.getAttributeType(attribute)\n","        # get the main object\n","        for _obj in sceneCopy:\n","            # and not equalDicts(_obj, anchorObj):\n","            if _obj[attributeType] == attribute:\n","                break\n","        self.updateIdentifier(_obj, attribute)\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","        del sceneCopy\n","\n","    def uniqueObject(self, *attributes):\n","        attributes = list(attributes)\n","        attributeTypes = list(\n","            map(lambda att: self.getAttributeType(att), attributes))\n","\n","        for _obj in self.scene:\n","            found = True\n","            for attributeType, attribute in zip(attributeTypes, attributes):\n","                if _obj[attributeType] != attribute:\n","                    found = False\n","                    break\n","\n","            if found:\n","                break\n","        for att in attributes:\n","            self.updateIdentifier(_obj, att)\n","\n","        self.updateCurrentObj(_obj)\n","        self.updateVisited(_obj)\n","\n","    ######################################## Question Programs ########################################\n","    def filterOutObj(self, scene, obj):\n","        sceneCopy = deepcopy(scene)\n","        for i, _obj in enumerate(scene):\n","            if obj[\"id\"] == _obj[\"id\"]:\n","                break\n","        del sceneCopy[i]\n","        return sceneCopy\n","\n","    def filterAttribute(self, scene, attribute):\n","        attributeType = self.getAttributeType(attribute)\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in scene:\n","            if _obj[attributeType] == attribute:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def excludeAttribute(self, scene, obj, attributeType):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","        for _obj in scene:\n","            if _obj[\"id\"] != obj[\"id\"] and obj[attributeType] == _obj[attributeType]:\n","                filtered.append(_obj)\n","\n","        # Update the visited objects list\n","        if len(filtered) > 0:\n","            for _obj in filtered:\n","                self.updateVisited(_obj)\n","        return filtered\n","\n","    def filterLeft(self, scene, obj):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in self.scene:\n","            # if the x-coordinate of _obj is smaller than the x-coordinate of slef.currentObj,\n","            # then _obj is located to the left of self.currentObj\n","            if _obj[\"position\"][0] < obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterRight(self, scene, obj):\n","        filtered = []\n","        for _obj in self.scene:\n","            # if the x-coordinate of _obj is bigger than the x-coordinate of slef.currentObj,\n","            # then _obj is located to the right of self.currentObj\n","            if _obj[\"position\"][0] > obj[\"position\"][0] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterFront(self, scene, obj):\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in self.scene:\n","            # if the y-coordinate of _obj is smaller than the y-coordinate of slef.currentObj,\n","            # then _obj is located in front of self.currentObj\n","            if _obj[\"position\"][1] > obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterBehind(self, scene, obj):\n","        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n","        filtered = []\n","        if len(scene) == 0:\n","            return filtered\n","\n","        for _obj in scene:\n","            # if the y-coordinate of _obj is bigger than the y-coordinate of slef.currentObj,\n","            # then _obj is located behind self.currentObj\n","            if _obj[\"position\"][1] < obj[\"position\"][1] and _obj[\"id\"] != obj[\"id\"]:\n","                filtered.append(_obj)\n","        return filtered\n","\n","    def filterPosition(self, scene, obj, pos):\n","        # assert type(scene) == list, \"Excpected type list got {} instead\".format(type(scene))\n","        assert pos in [\"left\", \"right\", \"front\", \"behind\"]\n","        if pos == \"left\":\n","            filtered = self.filterLeft(scene, obj)\n","        elif pos == \"right\":\n","            filtered = self.filterRight(scene, obj)\n","        elif pos == \"front\":\n","            filtered = self.filterFront(scene, obj)\n","        elif pos == \"behind\":\n","            filtered = self.filterBehind(scene, obj)\n","\n","        return filtered\n","\n","    ###########################################################################\n","    #                           Counting questions                            #\n","    ###########################################################################\n","    def countAll(self):\n","        self.currentGrp = deepcopy(self.scene)\n","        self.groups.append(deepcopy(self.scene))\n","        return len(self.scene)\n","\n","    def countOther(self):\n","        others = self.getOther()\n","        if len(others) > 0:\n","            self.currentGrp = others\n","            self.groups.append(others)\n","        if len(others) == 1:\n","            obj = others[0]\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    break\n","            self.updateCurrentObj(obj)\n","\n","            self.updateVisited(obj)\n","        return len(others)\n","\n","    def countAllGroup(self):\n","        return len(self.currentGrp)\n","\n","    def countAttribute(self, attribute, updateCurrentObj=True):\n","        filtered = self.filterAttribute(self.scene, attribute)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            self.updateIdentifier(obj, attribute)\n","            self.updateVisited(obj)\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.groups.append(filtered)\n","        self.currentGrp = filtered\n","        return len(filtered)\n","\n","    def countAttributeGroup(self, attribute, updateCurrentObj=True):\n","        filtered = self.filterAttribute(self.currentGrp, attribute)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            self.updateIdentifier(obj, attribute)\n","            self.updateVisited(obj)\n","\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.groups.append(filtered)\n","        self.currentGrp = filtered\n","        return len(filtered)\n","\n","    def countObjRelImm(self, pos, updateCurrentObj=True):\n","        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","                self.uniqueObjFlag = True\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        return len(filtered)\n","\n","    def countObjRelImm2(self, pos):\n","        if self.uniqueObjFlag:\n","            # del self.objs[-1]\n","            self.updateCurrentObj(self.objs[-2])\n","            self.uniqueObjFlag = False\n","        return self.countObjRelImm(pos)\n","\n","    def countObjRelEarly(self, pos, earlyObjAttribute, updateCurrentObj=True):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","        filtered = self.filterPosition(self.scene, objEarly, pos)\n","        if len(filtered) == 0:\n","            return 0\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        else:\n","            self.updateCurrentObj(objEarly)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    def countObjExcludeImm(self, attributeType, updateCurrentObj=True):\n","        filtered = self.excludeAttribute(\n","            self.scene, self.currentObj, attributeType)\n","        if len(filtered) == 0:\n","            return 0\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    def countObjExcludeEarly(self, attributeType, earlyObjAttribute, updateCurrentObj=True):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n","        if len(filtered) == 0:\n","            return 0\n","\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj = _obj\n","                    new = False\n","                    break\n","            if updateCurrentObj:\n","                self.updateCurrentObj(obj)\n","            else:\n","                if new:\n","                    self.objs.append(obj)\n","        else:\n","            self.updateCurrentObj(objEarly)\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return len(filtered)\n","\n","    ###########################################################################\n","    #                           Existence questions                           #\n","    ###########################################################################\n","\n","    def existOther(self):\n","        others = self.getOther()\n","        numOther = len(others)\n","        if numOther > 0:\n","            self.currentGrp = others\n","            self.groups.append(others)\n","            for _obj in others:\n","                self.updateVisited(_obj)\n","        return \"yes\" if numOther > 0 else \"no\"\n","\n","    def existAttribute(self, attribute):\n","        filtered = self.filterAttribute(self.scene, attribute)\n","        numAttribute = len(filtered)\n","        if numAttribute == 0:\n","            return \"no\"\n","\n","        # Update the visited objects list\n","        for _obj in filtered:\n","            self.updateVisited(_obj)\n","        if len(filtered) == 1:\n","            obj = filtered[0]\n","            new = True\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    self.updateIdentifier(_obj, attribute)\n","                    new = False\n","                    break\n","            if new:\n","                self.updateIdentifier(obj, attribute)\n","                self.objs.append(obj)\n","                # self.updateCurrentObj(obj)\n","\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return \"yes\"\n","\n","    def existAttributeGroup(self, attribute):\n","        numAttributeGrp = self.countAttributeGroup(\n","            attribute, updateCurrentObj=False)\n","        return \"yes\" if numAttributeGrp > 0 else \"no\"\n","\n","    def existObjRelImm(self, pos):\n","        numObjs = self.countObjRelImm(pos, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjRelEarly(self, pos, earlyObjAttribute):\n","        numObjs = self.countObjRelEarly(\n","            pos, earlyObjAttribute, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjExcludeImm(self, attributeType):\n","        numObjs = self.countObjExcludeImm(\n","            attributeType, updateCurrentObj=False)\n","        return \"yes\" if numObjs > 0 else \"no\"\n","\n","    def existObjExcludeEarly(self, attributeType, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.excludeAttribute(self.scene, objEarly, attributeType)\n","        numObjs = len(filtered)\n","        if numObjs == 0:\n","            return \"no\"\n","        self.currentGrp = filtered\n","        self.groups.append(filtered)\n","        return \"yes\"\n","\n","    ###########################################################################\n","    #                             Seek questions                              #\n","    ###########################################################################\n","\n","    def seekAttrImm(self, attributeType):\n","        assert attributeType in self.currentObj, \"Attributre <{}> is not valid\"\n","        self.updateIdentifier(self.currentObj, self.currentObj[attributeType])\n","        return self.currentObj[attributeType]\n","\n","    def seekAttributeEarly(self, attributeType, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","        self.updateIdentifier(objEarly, objEarly[attributeType])\n","        self.updateCurrentObj(objEarly)\n","        self.updateVisited(objEarly)\n","        return objEarly[attributeType]\n","\n","    def seekAttributeRelImm(self, attributeType, pos):\n","        filtered = self.filterPosition(self.scene, self.currentObj, pos)\n","        if len(filtered) == 0:\n","            return \"none\"\n","        else:\n","            # Get the closest object to slef.obj\n","            if pos == \"left\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[-1]\n","            elif pos == \"right\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[0]\n","            elif pos == \"front\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[0]\n","            elif pos == \"behind\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","              \n","                obj = filtered[-1]\n","\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj[\"identifier\"] = _obj[\"identifier\"]\n","                    break\n","            self.updateIdentifier(obj, obj[attributeType])\n","            self.updateCurrentObj(obj)\n","            self.updateVisited(obj)\n","            return obj[attributeType]\n","\n","    def seekAttributeRelEarly(self, attributeType, pos, earlyObjAttribute):\n","        for objEarly in reversed(self.objs):\n","            if objEarly[\"identifier\"] is not None:\n","                identifiers = objEarly[\"identifier\"].split(\"-\")\n","                if earlyObjAttribute in identifiers:\n","                    break\n","            else:\n","                continue\n","\n","        filtered = self.filterPosition(self.scene, objEarly, pos)\n","        if len(filtered) == 0:\n","            return \"none\"\n","        else:\n","            # Get the closest object to slef.obj\n","            if pos == \"left\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[-1]\n","            elif pos == \"right\":\n","                filtered.sort(key=lambda x: x[\"position\"][0])\n","                obj = filtered[0]\n","            elif pos == \"front\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[0]\n","            elif pos == \"behind\":\n","                filtered.sort(key=lambda x: x[\"position\"][1])\n","                obj = filtered[-1]\n","            for _obj in self.objs:\n","                if _obj[\"id\"] == obj[\"id\"]:\n","                    obj[\"identifier\"] = _obj[\"identifier\"]\n","                    break\n","            self.updateIdentifier(obj, obj[attributeType])\n","            self.updateCurrentObj(obj)\n","            self.updateVisited(obj)\n","            return obj[attributeType]\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.241307Z","iopub.status.busy":"2024-02-13T13:47:46.241077Z","iopub.status.idle":"2024-02-13T13:47:46.267180Z","shell.execute_reply":"2024-02-13T13:47:46.266342Z","shell.execute_reply.started":"2024-02-13T13:47:46.241286Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","#import utils_m"]},{"cell_type":"markdown","metadata":{},"source":["### **Option_caption_parser**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.269255Z","iopub.status.busy":"2024-02-13T13:47:46.268426Z","iopub.status.idle":"2024-02-13T13:47:46.281274Z","shell.execute_reply":"2024-02-13T13:47:46.280562Z","shell.execute_reply.started":"2024-02-13T13:47:46.269221Z"},"trusted":true},"outputs":[],"source":["#!touch \"/kaggle/working/\" res.txt"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.282812Z","iopub.status.busy":"2024-02-13T13:47:46.282509Z","iopub.status.idle":"2024-02-13T13:47:46.316315Z","shell.execute_reply":"2024-02-13T13:47:46.315454Z","shell.execute_reply.started":"2024-02-13T13:47:46.282786Z"},"trusted":true},"outputs":[],"source":["class OptionsC():#changed optiopn class as Option_c to differentiate it with the one belong to question\n","    def __init__(self):\n","        self.parser = argparse.ArgumentParser()\n","        self.initialized = False\n","\n","    def initialize(self):\n","        self.parser.add_argument(\n","            '--mode',\n","            default=\"train\",\n","            # required=True,\n","            type=str,\n","            choices=['train', 'test'],\n","            help='The mode of the experiment')\n","\n","        self.parser.add_argument(\n","            '--run_dir',\n","            default=\"kaggle/working\",\n","            # required=True,\n","            type=str,\n","            help='The experiment directory')\n","\n","        self.parser.add_argument(\n","            '--load_checkpoint_path',\n","            default='None',\n","            type=str,\n","            help='The path the the pretrained CaptionNet')\n","\n","        self.parser.add_argument(\n","            '--res_path',\n","            default=\"kaggle/working/res.txt\",#***\n","            # required=True,\n","            type=str,\n","            help='Path where to log the predicted caption programs')\n","\n","        self.parser.add_argument(\n","            '--gpu_ids',\n","            default='0',\n","            type=str,\n","            help='Id of the gpu to be used')\n","\n","        self.parser.add_argument(\n","            '--seed',\n","            default=42,\n","            type=int,\n","            help='The seed used in training')\n","\n","        self.parser.add_argument(\n","            '--dataPathTr',\n","            default=\"/kaggle/input/caption_small/tr_cap_s.h5\", \n","            # required=True,\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n","\n","        self.parser.add_argument(\n","            '--dataPathVal',\n","            default=\"/kaggle/input/caption_small/val_cap_s.h5\",\n","            # required=True,\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n","\n","        self.parser.add_argument(\n","            '--dataPathTest',\n","            # required=True,\n","            default=\"/kaggle/input/caption_small/test_cap_s.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n","\n","        self.parser.add_argument(\n","            '--vocabPath',\n","            default=\"/kaggle/input/caption/vocab_output_caption.json\",\n","\n","            # required=True,\n","            type=str,\n","            help='Path to the generated vocabulary')\n","\n","        self.parser.add_argument(\n","            '--batch_size',\n","            default=64,\n","            type=int,\n","            help='Batch size')\n","\n","        self.parser.add_argument(\n","            '--num_workers',\n","            default=0,\n","            type=int,\n","            help='Number of workers for loading')\n","\n","        self.parser.add_argument(\n","            '--num_iters',\n","            #default=5000,\n","            default=TOTAL_ITER,\n","            type=int,\n","            help='Total number of iterations')\n","\n","        self.parser.add_argument(\n","            '--display_every',\n","            default=5,\n","            type=int,\n","            help='Display training information every N iterations')\n","\n","        self.parser.add_argument(\n","            '--debug_every',\n","            default=100,\n","            type=int,\n","            help='Display debug message every N iterations')\n","\n","        self.parser.add_argument(\n","            '--validate_every',\n","            default=VALID_EVE,\n","            type=int,\n","            help='Validate every N iterations')\n","\n","        self.parser.add_argument(\n","            '--shuffle_data',\n","            default=1,\n","            type=int,\n","            help='Activate to shuffle the training data')\n","\n","        self.parser.add_argument(\n","            '--optim',\n","            default='adam',\n","            type=str,\n","            help='The name of the optimizer to be used')\n","\n","        self.parser.add_argument(\n","            '--lr',\n","            default=1e-3,\n","            type=float,\n","            help='Base learning rate')\n","\n","        self.parser.add_argument(\n","            '--betas',\n","            default='0.9, 0.98',\n","            type=str,\n","            help='Adam optimizer\\'s betas')\n","\n","        self.parser.add_argument(\n","            '--eps',\n","            default='1e-9',\n","            type=float,\n","            help='Adam optimizer\\'s epsilon')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_marks',\n","            default='50000, 55000',\n","            type=str,\n","            help='Learing rate decay marks')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_factor',\n","            default=0.5,\n","            type=float,\n","            help='Learning rate decay factor')\n","\n","        self.parser.add_argument(\n","            '--weight_decay',\n","            default=1e-6,\n","            type=float,\n","            help='Weight decay')\n","\n","        self.parser.add_argument(\n","            '--embedDim',\n","            default=300,\n","            type=int,\n","            help='Embedding dimension')\n","\n","        self.parser.add_argument(\n","            '--hiddenDim',\n","            default=512,\n","            type=int,\n","            help='LSTM hidden dimension')\n","\n","        self.parser.add_argument(\n","            '--numLayers',\n","            default=2,\n","            type=int,\n","            help='Number of hidden LSTM layers')\n","\n","        self.parser.add_argument(\n","            '--dropout',\n","            default=0.1,\n","            type=float,\n","            help='Dropout value')\n","\n","        self.parser.add_argument(\n","            '--multiHead',\n","            default=8,\n","            type=int,\n","            help='Number of attention heads')\n","\n","        self.parser.add_argument(\n","            '--hiddenSizeHead',\n","            default=64,\n","            type=int,\n","            help='Dimension of each attention head')\n","\n","        self.parser.add_argument(\n","            '--FeedForwardSize',\n","            default=2048,\n","            type=int,\n","            help='Dimension of the feed forward layer')\n","\n","        self.parser.add_argument(\n","            '--FlatMLPSize',\n","            default=512,\n","            type=int,\n","            help='MLP flatten size')\n","\n","        self.parser.add_argument(\n","            '--FlatGlimpses',\n","            default=1,\n","            type=int,\n","            help='Number of flatten glimpses')\n","\n","        self.parser.add_argument(\n","            '--FlatOutSize',\n","            default=512,\n","            type=int,\n","            help='Final attention reduction dimension')\n","\n","        self.parser.add_argument(\n","            '--layers',\n","            default=6,\n","            type=int,\n","            help='Number of self attention layers')\n","\n","        self.parser.add_argument(\n","            '--bidirectional',\n","            default=1,\n","            type=int,\n","            help='Activate to use bidirectional LSTMs')\n","\n","        self.initialized = True\n","\n","    def parse(self):\n","        # initialize parser\n","        if not self.initialized:\n","            self.initialize()\n","       # self.opts = self.parser.parse_args()\n","        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n","\n","        # parse gpu id list\n","        str_gpu_ids = self.opts.gpu_ids.split(',')\n","        self.opts.gpu_ids = []\n","        for str_id in str_gpu_ids:\n","            if str_id.isdigit() and int(str_id) >= 0:\n","                self.opts.gpu_ids.append(int(str_id))\n","        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n","            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n","        else:\n","            print('\\n[INFO] Using cpu ...')\n","            self.opts.gpu_ids = []\n","\n","        # parse the optimizer's betas and lr decay marks\n","        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n","        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n","        for i in range(1, len(lr_decay_marks)):\n","            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n","        self.opts.lr_decay_marks = lr_decay_marks\n","\n","        # print and save options\n","        args = vars(self.opts)\n","        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n","        for k, v in args.items():\n","            print('%s: %s' % (str(k), str(v)))\n","\n","        if not os.path.isdir(self.opts.run_dir):\n","            os.makedirs(self.opts.run_dir)\n","        filename = 'opts_c.txt'\n","        file_path = os.path.join(self.opts.run_dir, filename)\n","        with open(file_path, 'wt') as fout:\n","            fout.write('| options\\n')\n","            for k, v in sorted(args.items()):\n","                fout.write('%s: %s\\n' % (str(k), str(v)))\n","        return self.opts"]},{"cell_type":"markdown","metadata":{},"source":["## **models.py**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.317924Z","iopub.status.busy":"2024-02-13T13:47:46.317554Z","iopub.status.idle":"2024-02-13T13:47:46.331393Z","shell.execute_reply":"2024-02-13T13:47:46.330647Z","shell.execute_reply.started":"2024-02-13T13:47:46.317890Z"},"trusted":true},"outputs":[],"source":["import torch\n","import math\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.332820Z","iopub.status.busy":"2024-02-13T13:47:46.332536Z","iopub.status.idle":"2024-02-13T13:47:46.341100Z","shell.execute_reply":"2024-02-13T13:47:46.340328Z","shell.execute_reply.started":"2024-02-13T13:47:46.332795Z"},"trusted":true},"outputs":[],"source":["class FC(nn.Module):\n","    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n","        super(FC, self).__init__()\n","        self.dropout_r = dropout_r\n","        self.use_relu = use_relu\n","\n","        self.linear = nn.Linear(in_size, out_size)\n","\n","        if use_relu:\n","            self.relu = nn.ReLU(inplace=True)\n","\n","        if dropout_r > 0:\n","            self.dropout = nn.Dropout(dropout_r)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","\n","        if self.use_relu:\n","            x = self.relu(x)\n","\n","        if self.dropout_r > 0:\n","            x = self.dropout(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.343229Z","iopub.status.busy":"2024-02-13T13:47:46.342939Z","iopub.status.idle":"2024-02-13T13:47:46.352697Z","shell.execute_reply":"2024-02-13T13:47:46.351797Z","shell.execute_reply.started":"2024-02-13T13:47:46.343207Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n","        super(MLP, self).__init__()\n","\n","        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n","        self.linear = nn.Linear(mid_size, out_size)\n","\n","    def forward(self, x):\n","        return self.linear(self.fc(x))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.354270Z","iopub.status.busy":"2024-02-13T13:47:46.353935Z","iopub.status.idle":"2024-02-13T13:47:46.364525Z","shell.execute_reply":"2024-02-13T13:47:46.363691Z","shell.execute_reply.started":"2024-02-13T13:47:46.354238Z"},"trusted":true},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, size, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.eps = eps\n","\n","        self.a_2 = nn.Parameter(torch.ones(size))\n","        self.b_2 = nn.Parameter(torch.zeros(size))\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","\n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.365923Z","iopub.status.busy":"2024-02-13T13:47:46.365640Z","iopub.status.idle":"2024-02-13T13:47:46.378507Z","shell.execute_reply":"2024-02-13T13:47:46.377718Z","shell.execute_reply.started":"2024-02-13T13:47:46.365901Z"},"trusted":true},"outputs":[],"source":["class MHAtt(nn.Module):\n","    def __init__(self, opts):\n","        super(MHAtt, self).__init__()\n","        self.opts = opts\n","\n","        self.linear_v = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_k = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_q = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_merge = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","\n","        self.dropout = nn.Dropout(opts.dropout)\n","\n","    def forward(self, v, k, q, mask):\n","        n_batches = q.size(0)\n","\n","        v = self.linear_v(v).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        k = self.linear_k(k).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        q = self.linear_q(q).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        atted = self.att(v, k, q, mask)\n","        atted = atted.transpose(1, 2).contiguous().view(\n","            n_batches,\n","            -1,\n","            self.opts.hiddenDim\n","        )\n","\n","        atted = self.linear_merge(atted)\n","\n","        return atted\n","\n","    def att(self, value, key, query, mask):\n","        d_k = query.size(-1)\n","\n","        scores = torch.matmul(\n","            query, key.transpose(-2, -1)\n","        ) / math.sqrt(d_k)\n","\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, -1e9)\n","\n","        att_map = F.softmax(scores, dim=-1)\n","        att_map = self.dropout(att_map)\n","\n","        return torch.matmul(att_map, value)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.380087Z","iopub.status.busy":"2024-02-13T13:47:46.379743Z","iopub.status.idle":"2024-02-13T13:47:46.396043Z","shell.execute_reply":"2024-02-13T13:47:46.395173Z","shell.execute_reply.started":"2024-02-13T13:47:46.380057Z"},"trusted":true},"outputs":[],"source":["class FFN(nn.Module):\n","    def __init__(self, opts):\n","        super(FFN, self).__init__()\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FeedForwardSize,\n","            out_size=opts.hiddenDim,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.397500Z","iopub.status.busy":"2024-02-13T13:47:46.397229Z","iopub.status.idle":"2024-02-13T13:47:46.409328Z","shell.execute_reply":"2024-02-13T13:47:46.408492Z","shell.execute_reply.started":"2024-02-13T13:47:46.397476Z"},"trusted":true},"outputs":[],"source":["class SA(nn.Module):\n","    def __init__(self, opts):\n","        super(SA, self).__init__()\n","        self.mhatt = MHAtt(opts)\n","        self.ffn = FFN(opts)\n","\n","        self.dropout1 = nn.Dropout(opts.dropout)\n","        self.norm1 = LayerNorm(opts.hiddenDim)\n","\n","        self.dropout2 = nn.Dropout(opts.dropout)\n","        self.norm2 = LayerNorm(opts.hiddenDim)\n","\n","    def forward(self, x, x_mask):\n","        x = self.norm1(x + self.dropout1(\n","            self.mhatt(x, x, x, x_mask)\n","        ))\n","\n","        x = self.norm2(x + self.dropout2(\n","            self.ffn(x)\n","        ))\n","\n","        return x"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.410844Z","iopub.status.busy":"2024-02-13T13:47:46.410483Z","iopub.status.idle":"2024-02-13T13:47:46.424386Z","shell.execute_reply":"2024-02-13T13:47:46.423578Z","shell.execute_reply.started":"2024-02-13T13:47:46.410818Z"},"trusted":true},"outputs":[],"source":["class AttFlat(nn.Module):\n","    def __init__(self, opts):\n","        super(AttFlat, self).__init__()\n","        self.opts = opts\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FlatMLPSize,\n","            out_size=opts.FlatGlimpses,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","        # FLAT_GLIMPSES = 1\n","        self.linear_merge = nn.Linear(\n","            opts.hiddenDim * opts.FlatGlimpses,\n","            opts.FlatOutSize\n","        )\n","\n","    def forward(self, x, x_mask):\n","        att = self.mlp(x)\n","        att = att.masked_fill(\n","            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n","            -1e9\n","        )\n","        att = F.softmax(att, dim=1)\n","\n","        att_list = []\n","        for i in range(self.opts.FlatGlimpses):\n","            att_list.append(\n","                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n","            )\n","\n","        x_atted = torch.cat(att_list, dim=1)\n","        x_atted = self.linear_merge(x_atted)\n","\n","        return x_atted"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.425840Z","iopub.status.busy":"2024-02-13T13:47:46.425533Z","iopub.status.idle":"2024-02-13T13:47:46.441237Z","shell.execute_reply":"2024-02-13T13:47:46.440553Z","shell.execute_reply.started":"2024-02-13T13:47:46.425807Z"},"trusted":true},"outputs":[],"source":["class QuestEncoder_1(nn.Module):\n","    \"\"\"\n","        Concat encoder\n","    \"\"\"\n","    def __init__(self, opts, textVocabSize):\n","        super(QuestEncoder_1, self).__init__()\n","        bidirectional = opts.bidirectional > 0\n","\n","        self.embedding = nn.Embedding(textVocabSize, opts.embedDim)\n","        self.lstmQ = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            bidirectional=bidirectional,\n","            batch_first=True\n","        )\n","\n","        self.lstmH = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            bidirectional=bidirectional,\n","            batch_first=True)\n","\n","        if bidirectional:\n","            opts.hiddenDim *= 2\n","            opts.hiddenSizeHead *= 2\n","            opts.FlatOutSize *= 2\n","        self.attQues = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","        self.attHist = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","\n","        self.attFlatQuest = AttFlat(opts)\n","        self.fc = nn.Linear(2 * opts.hiddenDim, opts.hiddenDim)\n","\n","    def forward(self, quest, hist):\n","        questMask = self.make_mask(quest.unsqueeze(2))\n","        histMask = self.make_mask(hist.unsqueeze(2))\n","\n","        # quest = F.tanh(self.embedding(quest))\n","        quest = self.embedding(quest)\n","\n","        quest, (_, _) = self.lstmQ(quest)\n","        questO = quest.detach().clone()\n","\n","        hist = self.embedding(hist)\n","        hist, (_, _) = self.lstmH(hist)\n","\n","        for attQ, attH in zip(self.attQues, self.attHist):\n","            quest = attQ(quest, questMask)\n","            hist = attH(hist, histMask)\n","        # (batchSize, 512)\n","        quest = self.attFlatQuest(quest, questMask)\n","\n","        # hist: (batchSize, length, 512)\n","        attWeights = torch.sum(torch.mul(hist, quest.unsqueeze(1)), -1)\n","        attWeights = torch.softmax(attWeights, -1)\n","        hist = torch.sum(torch.mul(hist, attWeights.unsqueeze(2)), 1)\n","        encOut = self.fc(torch.cat([quest, hist], -1))\n","\n","        return encOut, questO\n","\n","    # Masking\n","    def make_mask(self, feature):\n","        return (torch.sum(\n","            torch.abs(feature),\n","            dim=-1\n","        ) == 0).unsqueeze(1).unsqueeze(2)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.443176Z","iopub.status.busy":"2024-02-13T13:47:46.442560Z","iopub.status.idle":"2024-02-13T13:47:46.459810Z","shell.execute_reply":"2024-02-13T13:47:46.459093Z","shell.execute_reply.started":"2024-02-13T13:47:46.443140Z"},"trusted":true},"outputs":[],"source":["class QuestEncoder_2(nn.Module):\n","    \"\"\"\n","        Stack encoder\n","    \"\"\"\n","    def __init__(self, opts, textVocabSize):\n","        super(QuestEncoder_2, self).__init__()\n","        bidirectional = opts.bidirectional > 0\n","        self.embedding = nn.Embedding(textVocabSize, opts.embedDim)\n","        self.lstmQ = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            bidirectional=bidirectional,\n","        )\n","\n","        self.lstmH = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            bidirectional=bidirectional,\n","        )\n","        if bidirectional:\n","            opts.hiddenDim *= 2\n","\n","        self.fc = nn.Linear(2 * opts.hiddenDim, opts.hiddenDim)\n","\n","    def forward(self, quest, hist):\n","\n","        quest = F.tanh(self.embedding(quest))\n","        quest, (questH, _) = self.lstmQ(quest)\n","\n","        # concatenate the last hidden states from the forward and backward pass\n","        # of the bidirectional lstm\n","        lastHiddenForward = questH[1:2, :, :].squeeze(0)\n","        lastHiddenBackward = questH[3:4, :, :].squeeze(0)\n","\n","        # questH: (batchSize, 512)\n","        questH = torch.cat([lastHiddenForward, lastHiddenBackward], -1)\n","\n","        questO = quest.detach().clone()\n","\n","        hist = F.tanh(self.embedding(hist))\n","        numRounds = hist.size(1)\n","        histFeat = []\n","        for i in range(numRounds):\n","            round_i = hist[:, i, :, :]\n","            _, (round_i_h, _) = self.lstmH(round_i)\n","\n","            #Same as before\n","            lastHiddenForward = round_i_h[1:2, :, :].squeeze(0)\n","            lastHiddenBackward = round_i_h[3:4, :, :].squeeze(0)\n","            histFeat.append(torch.cat([lastHiddenForward, lastHiddenBackward], -1))\n","\n","        # hist: (batchSize, rounds, 512)\n","        histFeat = torch.stack(histFeat, 1)\n","        attWeights = torch.sum(torch.mul(histFeat, questH.unsqueeze(1)), -1)\n","        attWeights = torch.softmax(attWeights, -1)\n","        histFeat = torch.sum(torch.mul(histFeat, attWeights.unsqueeze(2)), 1)\n","        encOut = self.fc(torch.cat([questH, histFeat], -1))\n","        return encOut, questO"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.461483Z","iopub.status.busy":"2024-02-13T13:47:46.461051Z","iopub.status.idle":"2024-02-13T13:47:46.480360Z","shell.execute_reply":"2024-02-13T13:47:46.479664Z","shell.execute_reply.started":"2024-02-13T13:47:46.461452Z"},"trusted":true},"outputs":[],"source":["#*** ->for qiansu: copy and paste the whole class\n","class Decoder(nn.Module):\n","    def __init__(self, opts, progVocabSize, maxLen, startID=1, endID=2):\n","        super(Decoder, self).__init__()\n","        self.numLayers = opts.numLayers\n","        self.bidirectional = opts.bidirectional > 0\n","        self.maxLen = maxLen\n","        self.startID = startID\n","        self.endID = endID\n","\n","        self.embedding = nn.Embedding(progVocabSize, opts.embedDim)\n","        self.lstmProg = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=2*opts.hiddenDim if self.bidirectional else opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            #bidirectional=self.bidirectional,#???????\n","        )\n","        hiddenDim = opts.hiddenDim\n","        if self.bidirectional:\n","            hiddenDim *= 2\n","\n","        self.fcAtt = nn.Linear(2*hiddenDim, hiddenDim)\n","        self.fcOut = nn.Linear(hiddenDim, progVocabSize)\n","\n","    def initPrgHidden(self, encOut):\n","        hidden = [encOut for _ in range(self.numLayers)]\n","        hidden = torch.stack(hidden, 0).contiguous()\n","        return hidden, hidden\n","\n","    def forwardStep(self, prog, progH, questO):\n","        #**********************************************our error relates to this prog cause in our case it is not acting as tensor anymore.\n","        batchSize = prog.size(0)\n","        inputDim = questO.size(1)\n","        prog = self.embedding(prog)\n","        outProg, progH = self.lstmProg(prog, progH)\n","\n","        att = torch.bmm(outProg, questO.transpose(1, 2))\n","        att = F.softmax(att.view(-1, inputDim), 1).view(batchSize, -1, inputDim)\n","        context = torch.bmm(att, questO)\n","        # (batchSize, progLength, hiddenDim)\n","        out = F.tanh(self.fcAtt(torch.cat([outProg, context], dim=-1)))\n","\n","        # (batchSize, progLength, progVocabSize)\n","        out = self.fcOut(out)\n","        predSoftmax = F.log_softmax(out, 2)\n","        return predSoftmax, progH\n","\n","    def forward(self, prog, encOut, questO):\n","        progH = self.initPrgHidden(encOut)\n","        predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","\n","        return predSoftmax, progH\n","\n","    def sample(self, encOut, questO):\n","        batchSize = encOut.size(0)\n","        cudaFlag = encOut.is_cuda\n","        progH = self.initPrgHidden(encOut)\n","        # prog = progCopy[:, 0:3]\n","        prog = torch.LongTensor(batchSize, 1).fill_(self.startID)\n","        # prog = torch.cat((progStart, progEnd), -1)\n","        if cudaFlag:\n","            prog = prog.cuda()\n","        outputLogProbs = []\n","        outputTokens = []\n","     \n","\n","        def decode(i, output):\n","            tokens = output.topk(1, dim=-1)[1].view(batchSize, -1)\n","            #print(\"This is inside of the decode local function and this is the tockens=\", tokens)\n","            return tokens\n","\n","        for i in range(self.maxLen):\n","            predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","            prog = decode(i, predSoftmax)\n","            prog_flat = list(chain(*prog))\n","            flat_list = [item.item() for item in prog_flat]\n","\n","        #****************************************my modification\n","            outputTokens.append(flat_list)#new\n","       #print(\"lets check what is inside outputTocken\", outputTokens)    \n","       # print(\"-----------------------------------------\")\n","        return outputTokens, outputLogProbs\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.481721Z","iopub.status.busy":"2024-02-13T13:47:46.481389Z","iopub.status.idle":"2024-02-13T13:47:46.497525Z","shell.execute_reply":"2024-02-13T13:47:46.496808Z","shell.execute_reply.started":"2024-02-13T13:47:46.481689Z"},"trusted":true},"outputs":[],"source":["class SeqToSeqC(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(SeqToSeqC, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, cap, prog):\n","        encOut, capO = self.encoder(cap)\n","        predSoftmax, progHC = self.decoder(prog, encOut, capO)\n","        return predSoftmax, progHC\n","   \n","    def sample(self, cap):\n","        with torch.no_grad():\n","            encOut, capO = self.encoder(cap)\n","        outputTokens, outputLogProbs = self.decoder.sample(encOut, capO)\n","        #if not outputTokens:\n","          #  print(\"***\")\n","        # Handle the case where outputTokens is empty, for example, return a placeholder tensor\n","           # return torch.tensor([])\n","        #***************************************************************** \n","        #outputTokens = torch.stack(outputTokens, 0).transpose(0, 1)\n","        #outputTokens = torch.stack(outputTokens, dim=0).transpose(0, 1)\n","        outputTokens_t = [[row[i] for row in outputTokens] for i in range(len(outputTokens[0]))]#***transpose \n","        return outputTokens_t\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.498759Z","iopub.status.busy":"2024-02-13T13:47:46.498503Z","iopub.status.idle":"2024-02-13T13:47:46.514774Z","shell.execute_reply":"2024-02-13T13:47:46.514082Z","shell.execute_reply.started":"2024-02-13T13:47:46.498737Z"},"trusted":true},"outputs":[],"source":["class SeqToSeqQ(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(SeqToSeqQ, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, quest, hist, prog):\n","        encOut, questO = self.encoder(quest, hist)\n","        predSoftmax, progHC = self.decoder(prog, encOut, questO)\n","        return predSoftmax, progHC\n","\n","    def sample(self, quest, hist):\n","        with torch.no_grad():\n","            encOut, questO = self.encoder(quest, hist)\n","            outputTokens, outputLogProbs = self.decoder.sample(encOut, questO)\n","      \n","        outputTokens_t = [[row[i] for row in outputTokens] for i in range(len(outputTokens[0]))]#***transpose \n","        return outputTokens_t"]},{"cell_type":"markdown","metadata":{},"source":["## **optim.py**"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.520217Z","iopub.status.busy":"2024-02-13T13:47:46.519956Z","iopub.status.idle":"2024-02-13T13:47:46.524792Z","shell.execute_reply":"2024-02-13T13:47:46.523852Z","shell.execute_reply.started":"2024-02-13T13:47:46.520195Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.optim as Optim\n","from itertools import chain #***"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.526124Z","iopub.status.busy":"2024-02-13T13:47:46.525841Z","iopub.status.idle":"2024-02-13T13:47:46.538243Z","shell.execute_reply":"2024-02-13T13:47:46.537321Z","shell.execute_reply.started":"2024-02-13T13:47:46.526100Z"},"trusted":true},"outputs":[],"source":["class WarmupOptimizer(object):\n","    def __init__(self, lr_base, optimizer, data_size, batch_size):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.lr_base = lr_base\n","        self._rate = 0\n","        self.data_size = data_size\n","        self.batch_size = batch_size\n","\n","    def step(self):\n","        self._step += 1\n","\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","\n","        self.optimizer.step()\n","\n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","\n","    def rate(self, step=None):\n","        if step is None:\n","            step = self._step\n","\n","        if step <= int(self.data_size / self.batch_size * 1):\n","            r = self.lr_base * 1/2.\n","        else:\n","            r = self.lr_base\n","\n","        return r\n","\n","\n","def get_optim(opts, model, data_size, lr_base=None):\n","    if lr_base is None:\n","        lr_base = opts.lr\n","\n","    if opts.optim == 'adam':\n","        optim = Optim.Adam(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                betas=opts.betas,\n","                eps=opts.eps,\n","\n","            )\n","    elif opts.optim == 'rmsprop':\n","        optim = Optim.RMSprop(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                eps=opts.eps,\n","                weight_decay=opts.weight_decay\n","            )\n","    else:\n","        raise ValueError('{} optimizer is not supported'.fromat(opts.optim))\n","    return WarmupOptimizer(\n","        lr_base,\n","        optim,\n","        data_size,\n","        opts.batch_size\n","    )\n","\n","def adjust_lr(optim, decay_r):\n","    optim.lr_base *= decay_r\n"]},{"cell_type":"markdown","metadata":{},"source":["## **option_question_parser.py**"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.539387Z","iopub.status.busy":"2024-02-13T13:47:46.539158Z","iopub.status.idle":"2024-02-13T13:47:46.553984Z","shell.execute_reply":"2024-02-13T13:47:46.552838Z","shell.execute_reply.started":"2024-02-13T13:47:46.539366Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","#import utils_m\n","import torch"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.555796Z","iopub.status.busy":"2024-02-13T13:47:46.555340Z","iopub.status.idle":"2024-02-13T13:47:46.594508Z","shell.execute_reply":"2024-02-13T13:47:46.593685Z","shell.execute_reply.started":"2024-02-13T13:47:46.555772Z"},"trusted":true},"outputs":[],"source":["class OptionsQ():#changed optiopn class as Option_q to differentiate it with the one belong to caption\n","    def __init__(self):\n","        self.parser = argparse.ArgumentParser()\n","        self.initialized = False\n","        \n","\n","    def initialize(self):\n","        self.parser.add_argument(\n","            '--mode',\n","            default='train',#***\n","            type=str,\n","            #choices=['train', 'test_with_gt', 'test_with_pred'],\n","            help='The mode of the experiment')\n","\n","        self.parser.add_argument(\n","            '--run_dir',\n","            #required=True,\n","            default= '/kaggle/working',\n","            type=str,\n","            help='The experiment directory')\n","        #***\n","        self.parser.add_argument(\n","            '--useCuda',\n","            default=1,\n","            type=int,\n","            help='To be able to use cuda')\n","\n","        self.parser.add_argument(\n","            '--text_log_dir',\n","            #required=True,\n","            default=\"/kaggle/working/res.txt\",\n","            type=str,\n","            help='File to save the logged text')\n","\n","        self.parser.add_argument(\n","            '--questionNetPath',\n","            #default='',\n","            default = '',\n","            type=str,\n","            help='Path to the pretrained QuestionNet that will be used for testing.')\n","\n","        self.parser.add_argument(\n","            '--captionNetPath',\n","            default = '',\n","            type=str,\n","            help='Path to the pretrained CaptionNet that will be used for testing.')\n","\n","        self.parser.add_argument(\n","            '--dialogLen',\n","            default=10,\n","            type=int,\n","            help='Length of the dialogs to be used for testing. We used 10, 15, and 20 in our experiments.')\n","\n","        self.parser.add_argument(\n","            '--last_n_rounds',\n","            default=10,\n","            type=int,\n","            help='Number of the last rounds to consider in the history. We used 1, 2, 3, 4, and 10 in our experiments. ')\n","\n","        self.parser.add_argument(\n","            '--encoderType',\n","            #required=True,\n","            default=1,\n","            type=int,\n","            choices=[1, 2],\n","            help='Type of the encoder: 1 --> Concat, 2 --> Stack')\n","\n","        self.parser.add_argument(\n","            '--load_checkpoint_path',\n","            default='None',\n","            type=str,\n","            help='Path to a QestionNet checkpoint path to resume training')\n","\n","        self.parser.add_argument(\n","            '--gpu_ids',\n","            default='0',\n","            type=str,\n","            help='Id of the gpu to be used')\n","\n","        self.parser.add_argument(\n","            '--seed',\n","            default=42,\n","            type=int,\n","            help='The seed used in training')\n","\n","        self.parser.add_argument(\n","            '--dataPathTr',\n","            #required=True,\n","            default= \"/kaggle/input/Small_Tr_Val_Test_Final/train_concat_half.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n","\n","        self.parser.add_argument(\n","            '--dataPathVal',\n","            #required=True,\n","            default=\"/kaggle/input/Small_Tr_Val_Test_Final/cap_val_half.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n","\n","        self.parser.add_argument(\n","            '--dataPathTest',\n","            #required=True,\n","            default = \"/kaggle/input/Small_Tr_Val_Test_Final/test_concat_1000.h5\",\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n","\n","        self.parser.add_argument(\n","            '--scenesPath',\n","            #required=True,\n","            default=\"/kaggle/input/data/CLEVR_train_scenes.json\",\n","            \n","            type=str,\n","            help='Path to the derendered clevr-dialog scenes')\n","\n","\n","        self.parser.add_argument(\n","            '--vocabTestPath',\n","            #required=True,\n","            default = \"/kaggle/input/test_concat/vocab_output.json\",\n","            type=str,\n","            help='Path to the test vocabulary')\n","\n","\n","        \n","\n","        self.parser.add_argument(\n","            '--vocabPath',\n","            #required=True,\n","            default =  \"/kaggle/input/train_concat/vocab_output.json\",\n","            type=str,\n","            help='Path to the generated vocabulary')\n","\n","        self.parser.add_argument(\n","            '--batch_size',\n","            #default=64,\n","            default=32,\n","            type=int,\n","            help='Batch size')\n","\n","        self.parser.add_argument(\n","            '--countFirstFailueRound',\n","            default=0,\n","            type=int,\n","            help='If activated, we count the first failure round')\n","\n","        self.parser.add_argument(\n","            '--maxSamples',\n","            default=-1,\n","            type=int,\n","            help='Maximum number of training samples')\n","\n","        self.parser.add_argument(\n","            '--num_workers',\n","            default=0,\n","            type=int,\n","            help='Number of workers for loading')\n","\n","        self.parser.add_argument(\n","            '--num_iters',\n","            default=TOTAL_ITER,\n","            type=int,\n","            help='Total number of iterations')\n","\n","        self.parser.add_argument(\n","            '--display_every',\n","            default=5,\n","            type=int,\n","            help='Display training information every N iterations')\n","\n","        self.parser.add_argument(\n","            '--validate_every',\n","            default=VALID_EVE,\n","            type=int,\n","            help='Validate every N iterations')\n","\n","        self.parser.add_argument(\n","            '--shuffle_data',\n","            default=1,\n","            type=int,\n","            help='Activate to shuffle the training data')\n","\n","        self.parser.add_argument(\n","            '--optim',\n","            default='adam',\n","            type=str,\n","            help='The name of the optimizer to be used')\n","\n","        self.parser.add_argument(\n","            '--lr',\n","            default=1e-3,\n","            type=float,\n","            help='Base learning rate')\n","\n","        self.parser.add_argument(\n","            '--betas',\n","            default='0.9, 0.98',\n","            type=str,\n","            help='Adam optimizer\\'s betas')\n","\n","        self.parser.add_argument(\n","            '--eps',\n","            default='1e-9',\n","            type=float,\n","            help='Adam optimizer\\'s epsilon')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_marks',\n","            default='50000, 55000',\n","            type=str,\n","            help='Learing rate decay marks')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_factor',\n","            default=0.5,\n","            type=float,\n","            help='Learning rate decay factor')\n","\n","        self.parser.add_argument(\n","            '--weight_decay',\n","            default=1e-6,\n","            type=float,\n","            help='Weight decay')\n","\n","        self.parser.add_argument(\n","            '--embedDim',\n","            default=300,\n","            type=int,\n","            help='Embedding dimension')\n","\n","        self.parser.add_argument(\n","            '--hiddenDim',\n","            default=512,\n","            type=int,\n","            help='LSTM hidden dimension')\n","\n","        self.parser.add_argument(\n","            '--numLayers',\n","            default=2,\n","            type=int,\n","            help='Number of hidden LSTM layers')\n","\n","        self.parser.add_argument(\n","            '--dropout',\n","            default=0.1,\n","            type=float,\n","            help='Dropout value')\n","\n","        self.parser.add_argument(\n","            '--multiHead',\n","            default=8,\n","            type=int,\n","            help='Number of attention heads')\n","\n","        self.parser.add_argument(\n","            '--hiddenSizeHead',\n","            default=64,\n","            type=int,\n","            help='Dimension of each attention head')\n","\n","        self.parser.add_argument(\n","            '--FeedForwardSize',\n","            default=2048,\n","            type=int,\n","            help='Dimension of the feed forward layer')\n","\n","        self.parser.add_argument(\n","            '--FlatMLPSize',\n","            default=512,\n","            type=int,\n","            help='MLP flatten size')\n","\n","        self.parser.add_argument(\n","            '--FlatGlimpses',\n","            default=1,\n","            type=int,\n","            help='Number of flatten glimpses')\n","\n","        self.parser.add_argument(\n","            '--FlatOutSize',\n","            default=512,\n","            type=int,\n","            help='Final attention reduction dimension')\n","\n","        self.parser.add_argument(\n","            '--layers',\n","            default=6,\n","            type=int,\n","            help='Number of self attention layers')\n","\n","        self.parser.add_argument(\n","            '--bidirectional',\n","            default=1,\n","            type=int,\n","            help='Activate to use bidirectional LSTMs')\n","\n","        self.initialized = True\n","\n","    def parse(self):\n","        # initialize parser\n","        if not self.initialized:\n","            self.initialize()\n","        #self.opts = self.parser.parse_args()#***\n","        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n","        # parse gpu id list\n","        str_gpu_ids = self.opts.gpu_ids.split(',')\n","        self.opts.gpu_ids = []\n","        for str_id in str_gpu_ids:\n","            if str_id.isdigit() and int(str_id) >= 0:\n","                self.opts.gpu_ids.append(int(str_id))\n","        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n","            print('\\n[INFO] Using {} CUDA device(s) ...'.format(\n","                len(self.opts.gpu_ids)))\n","        else:\n","            print('\\n[INFO] Using cpu ...')\n","            self.opts.gpu_ids = []\n","\n","        # parse the optimizer's betas and lr decay marks\n","        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n","        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n","        for i in range(1, len(lr_decay_marks)):\n","            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n","        self.opts.lr_decay_marks = lr_decay_marks\n","\n","        # print and save options\n","        args = vars(self.opts)\n","        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n","        for k, v in args.items():\n","            print('%s: %s' % (str(k), str(v)))\n","\n","        if not os.path.isdir(self.opts.run_dir):\n","            os.makedirs(self.opts.run_dir)\n","        filename = 'opts.txt'\n","        file_path = os.path.join(self.opts.run_dir, filename)\n","        with open(file_path, 'wt') as fout:\n","            fout.write('| options\\n')\n","            for k, v in sorted(args.items()):\n","                fout.write('%s: %s\\n' % (str(k), str(v)))\n","        return self.opts\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Train_question_parser**"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:46.595891Z","iopub.status.busy":"2024-02-13T13:47:46.595596Z","iopub.status.idle":"2024-02-13T13:47:53.752279Z","shell.execute_reply":"2024-02-13T13:47:53.751452Z","shell.execute_reply.started":"2024-02-13T13:47:46.595868Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import json, torch, pickle, copy, time\n","import numpy as np\n","import argparse\n","import torch.nn as nn\n","import torch.utils.data as Data\n","from tensorboardX import SummaryWriter\n","from copy import deepcopy\n","#from clevrDialog_dataset import ClevrDialogQuestionDataset\n","import pickle\n","from tqdm import tqdm\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:53.754145Z","iopub.status.busy":"2024-02-13T13:47:53.753506Z","iopub.status.idle":"2024-02-13T13:47:53.765142Z","shell.execute_reply":"2024-02-13T13:47:53.764211Z","shell.execute_reply.started":"2024-02-13T13:47:53.754105Z"},"trusted":true},"outputs":[],"source":["class CaptionEncoder(nn.Module):\n","    def __init__(self, opts, textVocabSize):\n","        super(CaptionEncoder, self).__init__()\n","        self.embedding = nn.Embedding(textVocabSize, opts.embedDim)\n","        bidirectional = opts.bidirectional > 0\n","        self.lstmC = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","        if bidirectional:\n","            opts.hiddenDim *= 2\n","            opts.hiddenSizeHead *= 2\n","            opts.FlatOutSize *= 2\n","\n","        self.attCap = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","        self.attFlatCap = AttFlat(opts)\n","        self.fc = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","\n","    def forward(self, cap, hist=None):\n","        capMask = self.make_mask(cap.unsqueeze(2))\n","        cap = self.embedding(cap)\n","        cap, (_, _) = self.lstmC(cap)\n","        capO = cap.detach().clone()\n","\n","        for attC in self.attCap:\n","            cap = attC(cap, capMask)\n","        # (batchSize, 512)\n","        cap = self.attFlatCap(cap, capMask)\n","        encOut = self.fc(cap)\n","        return encOut, capO\n","    \n","    # Masking\n","    def make_mask(self, feature):\n","        return (torch.sum(\n","            torch.abs(feature),\n","            dim=-1\n","        ) == 0).unsqueeze(1).unsqueeze(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:53.767335Z","iopub.status.busy":"2024-02-13T13:47:53.766856Z","iopub.status.idle":"2024-02-13T13:47:53.852692Z","shell.execute_reply":"2024-02-13T13:47:53.851777Z","shell.execute_reply.started":"2024-02-13T13:47:53.767305Z"},"trusted":true},"outputs":[],"source":["class Execution:\n","    def __init__(self, optsQ, optsC):\n","        self.opts = deepcopy(optsQ)\n","        if self.opts.useCuda > 0 and torch.cuda.is_available():\n","            self.device = torch.device(\"cuda:0\")\n","            print(\"[INFO] Using GPU {} ...\".format(torch.cuda.get_device_name(0)))\n","        else:\n","            print(\"[INFO] Using CPU ...\")\n","            self.device = torch.device(\"cpu\")\n","\n","        self.loss_fn = torch.nn.NLLLoss().to(self.device)\n","\n","        print(\"[INFO] Loading dataset ...\")\n","\n","        self.datasetTr = ClevrDialogQuestionDataset(\n","            self.opts.dataPathTr, self.opts.vocabPath, \"train\", \"All tr data\")\n","\n","        self.datasetVal = ClevrDialogQuestionDataset(\n","            self.opts.dataPathVal, self.opts.vocabPath, \"val\", \"All val data\", train=False)\n","\n","        self.datasetTest = ClevrDialogQuestionDataset(\n","            self.opts.dataPathTest, self.opts.vocabTestPath, \"test\", \"All val data\", train=False)\n","        \n","\n","\n","     \n","        self.QuestionNet = constructQuestionNet(\n","            self.opts,\n","            self.datasetTr.lenVocabText,\n","            self.datasetTr.lenVocabProg,\n","            self.datasetTr.maxLenProg,\n","            #self.datasetTest.lenVocabText,#*** to solve mismatch problems\n","            #self.datasetTest.lenVocabProg,#***\n","            #self.datasetTest.maxLenProg#***\n","            )\n","\n","        if os.path.isfile(self.opts.captionNetPath):\n","            self.CaptionNet = constructCaptionNet(\n","                optsC,\n","                self.datasetTr.lenVocabText,\n","                self.datasetTr.lenVocabProg,\n","                self.datasetTr.maxLenProg,\n","                #self.datasetTest.lenVocabText,#*** \n","                #self.datasetTest.lenVocabProg,#***\n","                #self.datasetTest.maxLenProg#***\n","                )\n","            print('Loading CaptionNet from {}'.format(self.opts.captionNetPath))\n","            state_dict = torch.load(self.opts.captionNetPath)['state_dict']\n","            self.CaptionNet.load_state_dict(state_dict)\n","            self.CaptionNet.to(self.device)\n","            total_params_cap = sum(p.numel() for p in self.CaptionNet.parameters() if p.requires_grad)\n","            print(\"The caption encoder has {} trainable parameters\".format(total_params_cap))\n","\n","        self.QuestionNet.to(self.device)\n","        if os.path.isfile(self.opts.questionNetPath):\n","            print('Loading QuestionNet from {}'.format(optsQ.questionNetPath))\n","            state_dict = torch.load(self.opts.questionNetPath)['state_dict']\n","            self.QuestionNet.load_state_dict(state_dict)\n","        total_params_quest = sum(p.numel() for p in self.QuestionNet.parameters() if p.requires_grad)\n","        print(\"The question encoder has {} trainable parameters\".format(total_params_quest))\n","\n","        if \"minecraft\" in self.opts.scenesPath:\n","            self.symbolicExecutor = SymbolicExecutorMinecraft(self.opts.scenesPath)\n","        else:\n","            self.symbolicExecutor = SymbolicExecutorClevr(self.opts.scenesPath)\n","\n","        tb_path = os.path.join(self.opts.run_dir, \"tb_logdir\")\n","        if not os.path.isdir(tb_path):\n","            os.makedirs(tb_path)\n","\n","        self.ckpt_path = os.path.join(self.opts.run_dir, \"ckpt_dir\")\n","        if not os.path.isdir(self.ckpt_path):\n","            os.makedirs(self.ckpt_path)\n","        if not os.path.isdir(self.opts.text_log_dir):\n","            os.makedirs(self.opts.text_log_dir)\n","\n","        self.writer = SummaryWriter(tb_path)\n","        self.iter_val = 0\n","#***\n","        #if os.path.isfile(self.opts.dependenciesPath):\n","            #with open(self.opts.dependenciesPath, \"rb\") as f:\n","                #self.dependencies = pickle.load(f)\n","\n","    def train(self):\n","        self.QuestionNet.train()\n","\n","        # Define the multi-gpu training if needed\n","        if len(self.opts.gpu_ids) > 1:\n","            self.QuestionNet = nn.DataParallel(self.QuestionNet, device_ids=self.opts.gpu_ids)\n","\n","        # Load checkpoint if resume training\n","        if os.path.isfile(self.opts.load_checkpoint_path):\n","            print(\"[INFO] Resume trainig from ckpt {} ...\".format(\n","                self.opts.load_checkpoint_path\n","            ))\n","\n","            # Load the network parameters\n","            ckpt = torch.load(self.opts.load_checkpoint_path)\n","            print(\"[INFO] Checkpoint successfully loaded ...\")\n","            self.QuestionNet.load_state_dict(ckpt['state_dict'])\n","\n","            # Load the optimizer paramters\n","            optim = get_optim(self.opts, self.QuestionNet, len(self.datasetTr))  # , ckpt['optim'], lr_base=ckpt['lr_base'])\n","            # optim._step = int(data_size / self.__C.BATCH_SIZE * self.__C.CKPT_EPOCH)\n","            optim.optimizer.load_state_dict(ckpt['optimizer'])\n","            _iter = 0  #  ckpt['last_iter']\n","            epoch = 0  # ckpt['last_epoch']\n","\n","        else:\n","            optim = get_optim(self.opts, self.QuestionNet, len(self.datasetTr))\n","            _iter = 0\n","            epoch = 0\n","\n","        trainTime = 0\n","        bestValAcc = float(\"-inf\")\n","        bestCkp = 0\n","        # Training loop\n","        while _iter < self.opts.num_iters:\n","\n","            # Learning Rate Decay\n","            if _iter in self.opts.lr_decay_marks:\n","                adjust_lr(optim, self.opts.lr_decay_factor)\n","\n","            # Define multi-thread dataloader\n","            dataloader = Data.DataLoader(\n","                self.datasetTr,\n","                batch_size=self.opts.batch_size,\n","                shuffle=self.opts.shuffle_data,\n","                num_workers=self.opts.num_workers,\n","            )\n","\n","            # Iteration\n","            time_start = 0\n","            time_end = 0\n","            for batch_iter, (quest, hist, prog, questionRound, _) in enumerate(dataloader):\n","                time_start = time.time()\n","                if _iter >= self.opts.num_iters:\n","                    break\n","                quest = quest.to(self.device)\n","                if self.opts.last_n_rounds < 10:\n","                    last_n_rounds_batch = []\n","                    for i, r in enumerate(questionRound.tolist()):\n","                        startIdx = max(r - self.opts.last_n_rounds, 0)\n","                        endIdx = max(r, self.opts.last_n_rounds)\n","                        if hist.dim() == 3:\n","                            assert endIdx - startIdx == self.opts.last_n_rounds\n","                            histBatch = hist[i, :, :]\n","                            last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n","                        elif hist.dim() == 2:\n","                            startIdx *= 20\n","                            endIdx *= 20\n","                            histBatch = hist[i, :]\n","                            temp = histBatch[startIdx:endIdx].cpu()\n","                            if r > self.opts.last_n_rounds:\n","                                last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n","                            else:\n","                                last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n","                    hist = torch.stack(last_n_rounds_batch, dim=0)\n","                hist = hist.to(self.device)\n","                prog = prog.to(self.device)\n","                progTarget = prog.clone()\n","                optim.zero_grad()\n","\n","                predSoftmax, _ = self.QuestionNet(quest, hist, prog[:, :-1])\n","                loss = self.loss_fn(\n","                    # predSoftmax[:, :-1, :].contiguous().view(-1, predSoftmax.size(2)),\n","                    predSoftmax.contiguous().view(-1, predSoftmax.size(2)),\n","                    progTarget[:, 1:].contiguous().view(-1))\n","                loss.backward()\n","\n","                if _iter % self.opts.validate_every == 0 and _iter > 0:\n","                    valAcc = self.val()\n","                    if valAcc > bestValAcc:\n","                        bestValAcc = valAcc\n","                        bestCkp = _iter\n","                        print(\"\\n[INFO] Checkpointing model @ iter {} with val accuracy {}\\n\".format(_iter, valAcc))\n","                        state = {\n","                            'state_dict': self.QuestionNet.state_dict(),\n","                            'optimizer': optim.optimizer.state_dict(),\n","                            'lr_base': optim.lr_base,\n","                            'optim': optim.lr_base,\n","                            'last_iter': _iter,\n","                            'last_epoch': epoch,\n","                        }\n","                        # checkpointing\n","                        torch.save(\n","                            state,\n","                            os.path.join(self.ckpt_path, 'ckpt_iter' + str(_iter) + '.pkl')\n","                        )\n","\n","                # logging\n","                self.writer.add_scalar(\n","                    'train/loss',\n","                    loss.cpu().data.numpy(),\n","                    global_step=_iter)\n","\n","                self.writer.add_scalar(\n","                    'train/lr',\n","                    optim._rate,\n","                    global_step=_iter)\n","                if _iter % self.opts.display_every == 0:\n","                    time_end = time.time()\n","                    trainTime += time_end-time_start\n","\n","                    print(\"\\r[CLEVR-Dialog - %s (%d | %d)][epoch %2d][iter %4d/%4d][runtime %4f] loss: %.4f, lr: %.2e\" % (\n","                        self.datasetTr.name,\n","                        batch_iter,\n","                        len(dataloader),\n","                        epoch,\n","                        _iter,\n","                        self.opts.num_iters,\n","                        trainTime,\n","                        loss.cpu().data.numpy(),\n","                        optim._rate,\n","                    ), end='          ')\n","\n","                optim.step()\n","                _iter += 1\n","\n","            epoch += 1\n","        print(\"[INFO] Avg. epoch time: {} s\".format(trainTime / epoch))\n","        print(\"[INFO] Best model achieved val acc. {} @ iter {}\".format(bestValAcc, bestCkp))\n","\n","    def val(self):\n","        self.QuestionNet.eval()\n","\n","        total_correct = 0\n","        total = 0\n","\n","        if len(self.opts.gpu_ids) > 1:\n","            self.QuestionNet = nn.DataParallel(self.QuestionNet, device_ids=self.opts.gpu_ids)\n","        self.QuestionNet = self.QuestionNet.eval()\n","        dataloader = Data.DataLoader(\n","            self.datasetVal,\n","            batch_size=self.opts.batch_size,\n","            shuffle=True,\n","            num_workers=self.opts.num_workers,\n","            pin_memory=False\n","        )\n","        _iterCur = 0\n","        _totalCur = len(dataloader)\n","\n","        for step, (question, questionPrg, questionImgIdx, questionRounds, history, historiesProg, answer) in enumerate(dataloader):\n","            # print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","            print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","                step,\n","                int(len(dataloader)),\n","            ), end='          ')\n","\n","            question = question.to(self.device)\n","            if history.dim() == 3:\n","                caption = history.detach()\n","                caption = caption[:, 0, :]\n","                caption = caption[:, :16].to(self.device)\n","            elif history.dim() == 2:\n","                caption = history.detach()\n","                caption = caption[:, :16].to(self.device)\n","            if self.opts.last_n_rounds is not None:\n","                last_n_rounds_batch = []\n","                for i, r in enumerate(questionRounds.tolist()):\n","                    startIdx = max(r - self.opts.last_n_rounds, 0)\n","                    endIdx = max(r, self.opts.last_n_rounds)\n","                    if history.dim() == 3:\n","                        assert endIdx - startIdx == self.opts.last_n_rounds\n","                        histBatch = history[i, :, :]\n","                        last_n_rounds_batch.append(histBatch[startIdx:endIdx, :])\n","                    elif history.dim() == 2:\n","                        startIdx *= 20\n","                        endIdx *= 20\n","                        histBatch = history[i, :]\n","                        temp = histBatch[startIdx:endIdx]\n","                        if r > self.opts.last_n_rounds:\n","                            last_n_rounds_batch.append(torch.cat([torch.tensor([1]), temp, torch.tensor([2])], 0))\n","                        else:\n","                            last_n_rounds_batch.append(torch.cat([temp, torch.tensor([2, 0])], 0))\n","                history = torch.stack(last_n_rounds_batch, dim=0)\n","            history = history.to(self.device)\n","            questionPrg = questionPrg.to(self.device)\n","            questProgsToksPred = self.QuestionNet.sample(question, history)\n","            questProgsPred = decodeProg(questProgsToksPred, self.datasetVal.vocab[\"idx_prog_to_token\"])\n","\n","            targetProgs = decodeProg(questionPrg, self.datasetVal.vocab[\"idx_prog_to_token\"], target=True)\n","            #print(\"this is the value for targetProgs:\", targetProgs)\n","            #print(\"-----------------------------------------------------\")\n","            correct = [1 if pred == gt else 0 for (pred, gt) in zip(questProgsPred, targetProgs)]\n","            #print(\"lets see what is inside of the correct:\", correct)\n","            #print(\"-----------------------------------------------------\")\n","            correct = sum(correct)\n","            total_correct += correct\n","            total += len(targetProgs)\n","            self.QuestionNet.train()\n","\n","        return 100.0 * (total_correct / total)\n","\n","\n","\n","    def getPrediction(self, questProgPred, capProgPred, historyProg, imgIndex):\n","        self.symbolicExecutor.reset(imgIndex)\n","        # if round one, execute the predicted caption program first then answer the question\n","        if len(historyProg) == 1:\n","            captionFuncLabel = capProgPred[0]\n","            captionFuncArgs = capProgPred[1:]\n","\n","            questionFuncLabel = questProgPred[0]\n","            questionFuncArgs = questProgPred[1:]\n","\n","            try:\n","                _ = self.symbolicExecutor.execute(captionFuncLabel, captionFuncArgs)\n","            except Exception as e:\n","                #print(\"Error is in caption This is the first round\",e)\n","               # print(captionFuncLabel, captionFuncArgs)\n","                return \"Error\"\n","\n","                \n","\n","            try:\n","                predAnswer = self.symbolicExecutor.execute(questionFuncLabel, questionFuncArgs)\n","            except Exception as e:\n","               # print (\"Error is in question. This is the first round \",e)\n","               # print(\"The question questionFuncLabel \",questionFuncLabel)\n","               # print(\"The questionFunc Args \",questionFuncArgs)\n","               # print(self.symbolicExecutor.execute(questionFuncLabel,questionFuncArgs))\n","\n","                return \"Error\"\n","\n","        # If it is not the first round, we have to execute the program history and\n","        # then answer the question.\n","        else:\n","            questionFuncLabel = questProgPred[0]\n","            questionFuncArgs = questProgPred[1:]\n","            for prg in historyProg:\n","                # prg = prg.split(\" \")\n","                FuncLabel = prg[0]\n","                FuncArgs = prg[1:]\n","                try:\n","                    _ = self.symbolicExecutor.execute(FuncLabel, FuncArgs)\n","                except:\n","                    #print(\"Error executing in history program:\", )\n","                    return \"Error\"\n","\n","            try:\n","                predAnswer = self.symbolicExecutor.execute(questionFuncLabel, questionFuncArgs)\n","            except Exception as e:\n","                #print(\"Error executing in current program:\", e)  #\n","\n","                return \"Error\"\n","        return str(predAnswer)\n","\n","    def run(self, run_mode, epoch=None):\n","        self.set_seed(self.opts.seed)\n","        if run_mode == 'train':\n","            self.train()\n","    \n","       \n","        else:\n","            exit(-1)\n","\n","    def set_seed(self, seed):\n","        \"\"\"Sets the seed for reproducibility.\n","        Args:\n","            seed (int): The seed used\n","        \"\"\"\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        print('[INFO] Seed set to {}...'.format(seed))\n","\n","\n","def constructQuestionNet(opts, lenVocabText, lenVocabProg, maxLenProg):\n","    decoder = Decoder(opts, lenVocabProg, maxLenProg)\n","    if opts.encoderType == 1:\n","        encoder = QuestEncoder_1(opts, lenVocabText)\n","    elif opts.encoderType == 2:\n","        encoder = QuestEncoder_2(opts, lenVocabText)\n","\n","    net = SeqToSeqQ(encoder, decoder)\n","    return net\n","\n","\n","def constructCaptionNet(opts, lenVocabText, lenVocabProg, maxLenProg):\n","    decoder = Decoder(opts, lenVocabProg, maxLenProg)\n","    encoder = CaptionEncoder(opts, lenVocabText)\n","    net = SeqToSeqC(encoder, decoder)\n","    return net\n","\n","\n","def getProgHistories(progHistToks, prgIdxToToken):\n","    progHist = []\n","    temp = []\n","    for tok in progHistToks:\n","        if tok not in [0, 1, 2]:\n","            temp.append(prgIdxToToken[tok])\n","            # del progHistToks[i]\n","        if tok == 2:\n","            # del progHistToks[i]\n","            # progHist.append(\" \".join(temp))\n","            progHist.append(temp)\n","            temp = []\n","    return progHist\n","\n","\n","def getHistoriesFromStack(histToks, textIdxToToken):\n","    histories = \"\\n\"\n","    temp = []\n","    for i, roundToks in enumerate(histToks):\n","        for tok in roundToks:\n","            if tok not in [0, 1, 2]:\n","                temp.append(textIdxToToken[tok])\n","                # del progHistToks[i]\n","            if tok == 2:\n","                # del progHistToks[i]\n","                if i == 0:\n","                    histories += \" \".join(temp) + \".\\n\"\n","                else:\n","                    histories += \" \".join(temp[:-1]) + \"? | {}.\\n\".format(temp[-1])\n","                # histories.append(temp)\n","                temp = []\n","                break\n","    return histories\n","\n","\n","def getHistoriesFromConcat(histToks, textIdxToToken):\n","    histories = []\n","    temp = []\n","    for tok in histToks:\n","        if tok not in [0, 1, 2]:\n","            temp.append(textIdxToToken[tok])\n","            # del progHistToks[i]\n","        if tok == 2:\n","            # del progHistToks[i]\n","            histories.append(\" \".join(temp[:-1]) + \"? | {}\".format(temp[-1]))\n","            # histories.append(temp)\n","            temp = []\n","    return histories\n","\n","\n","def decodeProg(tokens, prgIdxToToken, target=False):\n","    #tokensBatch = tokens.tolist()\n","    if (target == True):#***\n","        tokensBatch = tokens.tolist()\n","    else:#***\n","        tokensBatch = tokens\n","    progsBatch = []\n","    for tokens in tokensBatch:\n","        prog = []\n","        for tok in tokens:\n","            if tok == 2:  # <END> has index 2\n","                break\n","            prog.append(prgIdxToToken.get(tok))\n","        if target:\n","            prog = prog[1:]\n","        # progsBatch.append(\" \".join(prog))\n","        progsBatch.append(prog)\n","    return progsBatch\n","\n","\n","def printPred(predSoftmax, gts, prgIdxToToken):\n","    assert predSoftmax.size(0) == gts.size(0)\n","    tokens = predSoftmax.topk(1)[1].squeeze(-1)\n","    tokens = tokens.tolist()\n","    gts = gts.tolist()\n","    message = \"\\n ------------------------ \\n\"\n","    for token, gt in zip(tokens, gts):\n","        message += \"Prediction: \"\n","        for tok in token:\n","            message += prgIdxToToken.get(tok) + \" \"\n","        message += \"\\n Target   : \"\n","        for tok in gt:\n","            message += prgIdxToToken.get(tok) + \" \"\n","        message += \"\\n ------------------------ \\n\"\n","    return message\n","\n","\n","def get_per_round_acc(preds, gts, penalties):\n","    res = {}\n","    for img_preds, img_gt, img_pen in zip(preds, gts, penalties):\n","        img_preds = list(img_preds)\n","        img_gt = list(img_gt)\n","        img_pen = list(img_pen)\n","        print(img_pen)\n","        for i, (pred, gt, pen) in enumerate(zip(img_preds, img_gt, img_pen)):\n","            _round = str(i + 1)\n","            if _round not in res:\n","                res[_round] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            res[_round][\"all\"] += 1\n","            if pred == gt:\n","                pen = 0.1\n","                res[_round][\"correct\"] += 0.5**pen\n","\n","    textOut = \"\\n --------------- Per round Acc --------------- \\n\"\n","    for k in res:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res[k][\"correct\"]/res[k][\"all\"]))\n","    return textOut\n","\n","\n","def get_per_question_type_acc(preds, gts, qtypes, penalties):\n","    res1 = {}\n","    res2 = {}\n","\n","    for img_preds, img_gt, img_qtypes, img_pen in zip(preds, gts, qtypes, penalties):\n","        # img_preds = list(img_preds)\n","        # img_gt = list(img_gt)\n","        img_pen = list(img_pen)\n","        for pred, gt, temp, pen in zip(img_preds, img_gt, img_qtypes, img_pen):\n","            if temp not in res1:\n","                res1[temp] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            temp_cat = temp.split(\"-\")[0]\n","            if temp_cat not in res2:\n","                res2[temp_cat] = {\n","                    \"correct\": 0,\n","                    \"all\": 0\n","                }\n","            res1[temp][\"all\"] += 1\n","            res2[temp_cat][\"all\"] += 1\n","\n","            if pred == gt:\n","                pen = 0.1 \n","                res1[temp][\"correct\"] += 0.5**pen\n","                res2[temp_cat][\"correct\"] += 0.5**pen\n","\n","    textOut = \"\\n --------------- Per question Type Acc --------------- \\n\"\n","    for k in res1:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res1[k][\"correct\"]/res1[k][\"all\"]))\n","\n","    textOut += \"\\n --------------- Per question Category Acc --------------- \\n\"\n","    for k in res2:\n","        textOut += \"{}: {} %\\n\".format(k, 100.0 * (res2[k][\"correct\"]/res2[k][\"all\"]))\n","    return textOut\n","\n","\n","def decode(tokens, prgIdxToToken, target=False):\n","    if type(tokens) != list:\n","        tokens = tokens.tolist()\n","\n","    progsBatch = []\n","    for token in tokens:\n","        prog = []\n","        for tok in token:\n","            if tok == 2:  # <END> has index 2\n","                break\n","            prog.append(prgIdxToToken.get(tok))\n","        if target:\n","            prog = prog[1:]\n","        # progsBatch.append(\" \".join(prog))\n","        progsBatch.append(prog)\n","    return progsBatch\n","\n","#if __name__ == \"__main__\":#***"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:53.854246Z","iopub.status.busy":"2024-02-13T13:47:53.853947Z","iopub.status.idle":"2024-02-13T13:47:53.924975Z","shell.execute_reply":"2024-02-13T13:47:53.923895Z","shell.execute_reply.started":"2024-02-13T13:47:53.854221Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[INFO] Using 1 CUDA device(s) ...\n","\n"," ------------------------------Opts------------------------------\n","mode: train\n","run_dir: kaggle/working\n","load_checkpoint_path: None\n","res_path: kaggle/working/res.txt\n","gpu_ids: [0]\n","seed: 42\n","dataPathTr: /kaggle/input/caption_small/tr_cap_s.h5\n","dataPathVal: /kaggle/input/caption_small/val_cap_s.h5\n","dataPathTest: /kaggle/input/caption_small/test_cap_s.h5\n","vocabPath: /kaggle/input/caption/vocab_output_caption.json\n","batch_size: 64\n","num_workers: 0\n","num_iters: 5000\n","display_every: 5\n","debug_every: 100\n","validate_every: 1000\n","shuffle_data: 1\n","optim: adam\n","lr: 0.001\n","betas: [0.9, 0.98]\n","eps: 1e-09\n","lr_decay_marks: [50000, 55000]\n","lr_decay_factor: 0.5\n","weight_decay: 1e-06\n","embedDim: 300\n","hiddenDim: 512\n","numLayers: 2\n","dropout: 0.1\n","multiHead: 8\n","hiddenSizeHead: 64\n","FeedForwardSize: 2048\n","FlatMLPSize: 512\n","FlatGlimpses: 1\n","FlatOutSize: 512\n","layers: 6\n","bidirectional: 1\n"]}],"source":["optsC = OptionsC().parse()#***"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:53.926391Z","iopub.status.busy":"2024-02-13T13:47:53.926115Z","iopub.status.idle":"2024-02-13T13:47:53.935910Z","shell.execute_reply":"2024-02-13T13:47:53.935005Z","shell.execute_reply.started":"2024-02-13T13:47:53.926354Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[INFO] Using 1 CUDA device(s) ...\n","\n"," ------------------------------Opts------------------------------\n","mode: train\n","run_dir: /kaggle/working\n","useCuda: 1\n","text_log_dir: /kaggle/working/res.txt\n","questionNetPath: \n","captionNetPath: \n","dialogLen: 10\n","last_n_rounds: 10\n","encoderType: 1\n","load_checkpoint_path: None\n","gpu_ids: [0]\n","seed: 42\n","dataPathTr: /kaggle/input/Small_Tr_Val_Test_Final/train_concat_half.h5\n","dataPathVal: /kaggle/input/Small_Tr_Val_Test_Final/cap_val_half.h5\n","dataPathTest: /kaggle/input/Small_Tr_Val_Test_Final/test_concat_1000.h5\n","scenesPath: /kaggle/input/data/CLEVR_train_scenes.json\n","vocabTestPath: /kaggle/input/test_concat/vocab_output.json\n","vocabPath: /kaggle/input/train_concat/vocab_output.json\n","batch_size: 32\n","countFirstFailueRound: 0\n","maxSamples: -1\n","num_workers: 0\n","num_iters: 5000\n","display_every: 5\n","validate_every: 1000\n","shuffle_data: 1\n","optim: adam\n","lr: 0.001\n","betas: [0.9, 0.98]\n","eps: 1e-09\n","lr_decay_marks: [50000, 55000]\n","lr_decay_factor: 0.5\n","weight_decay: 1e-06\n","embedDim: 300\n","hiddenDim: 512\n","numLayers: 2\n","dropout: 0.1\n","multiHead: 8\n","hiddenSizeHead: 64\n","FeedForwardSize: 2048\n","FlatMLPSize: 512\n","FlatGlimpses: 1\n","FlatOutSize: 512\n","layers: 6\n","bidirectional: 1\n"]}],"source":["optsQ = OptionsQ().parse()#***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T13:47:53.937454Z","iopub.status.busy":"2024-02-13T13:47:53.937160Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Using GPU Tesla T4 ...\n","[INFO] Loading dataset ...\n","The question encoder has 139784134 trainable parameters\n","[INFO] Seed set to 42...\n","Evaluation: [step   39/  40]          49)][epoch  0][iter  995/5000][runtime 170.128428] loss: 0.1096, lr: 5.00e-04          \n","[INFO] Checkpointing model @ iter 1000 with val accuracy 41.47317854283427\n","\n","Evaluation: [step   39/  40]          649)][epoch  0][iter 1995/5000][runtime 353.707362] loss: 0.0037, lr: 5.00e-04          \n","[INFO] Checkpointing model @ iter 2000 with val accuracy 49.639711769415534\n","\n","Evaluation: [step   39/  40]          649)][epoch  0][iter 2995/5000][runtime 537.297892] loss: 0.0000, lr: 5.00e-04          \n","[INFO] Checkpointing model @ iter 3000 with val accuracy 51.72137710168134\n","\n","[CLEVR-Dialog - All tr data (4995 | 54649)][epoch  0][iter 4995/5000][runtime 901.553704] loss: 0.0000, lr: 5.00e-04          "]}],"source":["exe = Execution(optsQ, optsC)#***\n","exe.run('train')"]},{"cell_type":"raw","metadata":{"tags":[]},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4223935,"sourceId":7617478,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
