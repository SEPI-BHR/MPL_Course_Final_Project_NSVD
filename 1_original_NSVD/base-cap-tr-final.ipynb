{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:01.793158Z","iopub.status.busy":"2024-02-13T17:26:01.792306Z","iopub.status.idle":"2024-02-13T17:26:01.890420Z","shell.execute_reply":"2024-02-13T17:26:01.889451Z","shell.execute_reply.started":"2024-02-13T17:26:01.793113Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","\n","%reset -f"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:01.892292Z","iopub.status.busy":"2024-02-13T17:26:01.891983Z","iopub.status.idle":"2024-02-13T17:26:06.538865Z","shell.execute_reply":"2024-02-13T17:26:06.537845Z","shell.execute_reply.started":"2024-02-13T17:26:01.892250Z"},"trusted":true},"outputs":[],"source":["#for cleaning the GPU ram\n","import torch \n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.540659Z","iopub.status.busy":"2024-02-13T17:26:06.540199Z","iopub.status.idle":"2024-02-13T17:26:06.545842Z","shell.execute_reply":"2024-02-13T17:26:06.544684Z","shell.execute_reply.started":"2024-02-13T17:26:06.540629Z"},"trusted":true},"outputs":[],"source":["# path to notebook folder, use os.path.join to concat \n","import os\n","ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[]},"source":["## **This notebook is created for the original NSVD project.** \n","### There are 4 main folders in this project as following:\n","1. Preprocess_dialogs \n","2. program generator\n","3. executor \n","4. data foldes\n","Among these folders we are going to bring number 2 to 3. "]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-12-21T13:17:18.103208Z","iopub.status.busy":"2023-12-21T13:17:18.102753Z","iopub.status.idle":"2023-12-21T13:17:18.110990Z","shell.execute_reply":"2023-12-21T13:17:18.109505Z","shell.execute_reply.started":"2023-12-21T13:17:18.103172Z"}},"source":["## **Following codes belong to different .py files inside program_genarator**"]},{"cell_type":"markdown","metadata":{},"source":["## **clevrDialog_dataset.py**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.549334Z","iopub.status.busy":"2024-02-13T17:26:06.549029Z","iopub.status.idle":"2024-02-13T17:26:06.559318Z","shell.execute_reply":"2024-02-13T17:26:06.558407Z","shell.execute_reply.started":"2024-02-13T17:26:06.549307Z"},"trusted":true},"outputs":[],"source":["# /kaggle/input/nsvd-dataset/caption"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.561104Z","iopub.status.busy":"2024-02-13T17:26:06.560745Z","iopub.status.idle":"2024-02-13T17:26:06.742576Z","shell.execute_reply":"2024-02-13T17:26:06.741775Z","shell.execute_reply.started":"2024-02-13T17:26:06.561073Z"},"trusted":true},"outputs":[],"source":["import h5py\n","import json\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.744383Z","iopub.status.busy":"2024-02-13T17:26:06.744022Z","iopub.status.idle":"2024-02-13T17:26:06.749448Z","shell.execute_reply":"2024-02-13T17:26:06.748486Z","shell.execute_reply.started":"2024-02-13T17:26:06.744346Z"},"trusted":true},"outputs":[],"source":["def invertDict(_dict):\n","    return {v: k for k, v in _dict.items()}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.750965Z","iopub.status.busy":"2024-02-13T17:26:06.750665Z","iopub.status.idle":"2024-02-13T17:26:06.761230Z","shell.execute_reply":"2024-02-13T17:26:06.760241Z","shell.execute_reply.started":"2024-02-13T17:26:06.750934Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogDataset(Dataset):\n","    def __init__(self, dataPath, vocabPath, split, indStart=0, indEnd=-1):\n","        super(ClevrDialogDataset, self).__init__()\n","        self.data = h5py.File(dataPath, \"r\")\n","        with open(vocabPath, \"r\") as f:\n","            self.vocab = json.load(f)\n","        self.vocab[\"idx_text_to_token\"] = invertDict(self.vocab[\"text_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.vocab[\"idx_prog_to_token\"] = invertDict(self.vocab[\"prog_token_to_idx\"])\n","        self.lenVocabText = len(self.vocab[\"text_token_to_idx\"])\n","        self.lenVocabProg = len(self.vocab[\"prog_token_to_idx\"])\n","\n","        self.split = split\n","        self.indStart = indStart\n","        self.indEnd = indEnd\n","        self.maxSamples = indEnd - indStart\n","        self.maxLenProg = 6\n","\n","    def __len__(self):\n","        raise NotImplementedError\n","\n","    def __getitem__(self, index):\n","        raise NotImplementedError"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.763336Z","iopub.status.busy":"2024-02-13T17:26:06.762538Z","iopub.status.idle":"2024-02-13T17:26:06.772171Z","shell.execute_reply":"2024-02-13T17:26:06.771119Z","shell.execute_reply.started":"2024-02-13T17:26:06.763308Z"},"trusted":true},"outputs":[],"source":["class ClevrDialogCaptionDataset(ClevrDialogDataset):\n","    def __init__(self, dataPath, vocabPath, split, name, indStart=0, indEnd=-1):\n","        super(ClevrDialogCaptionDataset, self).__init__(dataPath, vocabPath, split, indStart=indStart, indEnd=indEnd)\n","        self.captions = torch.LongTensor(np.asarray(self.data[\"captions\"], dtype=np.int64)[indStart: indEnd])\n","        self.captionsPrgs = torch.LongTensor(np.asarray(self.data[\"captionProgs\"], dtype=np.int64)[indStart: indEnd])\n","        self.name = name\n","\n","    def __len__(self):\n","        return len(self.captions)\n","\n","    def __getitem__(self, idx):\n","        assert idx < len(self)\n","        caption = self.captions[idx][:16]\n","        captionPrg = self.captionsPrgs[idx]\n","        return caption, captionPrg"]},{"cell_type":"markdown","metadata":{},"source":["## **models.py**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.773836Z","iopub.status.busy":"2024-02-13T17:26:06.773493Z","iopub.status.idle":"2024-02-13T17:26:06.788831Z","shell.execute_reply":"2024-02-13T17:26:06.787679Z","shell.execute_reply.started":"2024-02-13T17:26:06.773803Z"},"trusted":true},"outputs":[],"source":["import torch\n","import math\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.794592Z","iopub.status.busy":"2024-02-13T17:26:06.794234Z","iopub.status.idle":"2024-02-13T17:26:06.803382Z","shell.execute_reply":"2024-02-13T17:26:06.802330Z","shell.execute_reply.started":"2024-02-13T17:26:06.794556Z"},"trusted":true},"outputs":[],"source":["class FC(nn.Module):\n","    def __init__(self, in_size, out_size, dropout_r=0., use_relu=True):\n","        super(FC, self).__init__()\n","        self.dropout_r = dropout_r\n","        self.use_relu = use_relu\n","\n","        self.linear = nn.Linear(in_size, out_size)\n","\n","        if use_relu:\n","            self.relu = nn.ReLU(inplace=True)\n","\n","        if dropout_r > 0:\n","            self.dropout = nn.Dropout(dropout_r)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","\n","        if self.use_relu:\n","            x = self.relu(x)\n","\n","        if self.dropout_r > 0:\n","            x = self.dropout(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.804828Z","iopub.status.busy":"2024-02-13T17:26:06.804536Z","iopub.status.idle":"2024-02-13T17:26:06.815009Z","shell.execute_reply":"2024-02-13T17:26:06.813629Z","shell.execute_reply.started":"2024-02-13T17:26:06.804801Z"},"trusted":true},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, in_size, mid_size, out_size, dropout_r=0., use_relu=True):\n","        super(MLP, self).__init__()\n","\n","        self.fc = FC(in_size, mid_size, dropout_r=dropout_r, use_relu=use_relu)\n","        self.linear = nn.Linear(mid_size, out_size)\n","\n","    def forward(self, x):\n","        return self.linear(self.fc(x))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.817182Z","iopub.status.busy":"2024-02-13T17:26:06.816754Z","iopub.status.idle":"2024-02-13T17:26:06.826497Z","shell.execute_reply":"2024-02-13T17:26:06.825374Z","shell.execute_reply.started":"2024-02-13T17:26:06.817148Z"},"trusted":true},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, size, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.eps = eps\n","\n","        self.a_2 = nn.Parameter(torch.ones(size))\n","        self.b_2 = nn.Parameter(torch.zeros(size))\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","\n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.831097Z","iopub.status.busy":"2024-02-13T17:26:06.830665Z","iopub.status.idle":"2024-02-13T17:26:06.852436Z","shell.execute_reply":"2024-02-13T17:26:06.851309Z","shell.execute_reply.started":"2024-02-13T17:26:06.831058Z"},"trusted":true},"outputs":[],"source":["class MHAtt(nn.Module):\n","    def __init__(self, opts):\n","        super(MHAtt, self).__init__()\n","        self.opts = opts\n","\n","        self.linear_v = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_k = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_q = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","        self.linear_merge = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","\n","        self.dropout = nn.Dropout(opts.dropout)\n","\n","    def forward(self, v, k, q, mask):\n","        n_batches = q.size(0)\n","\n","        v = self.linear_v(v).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        k = self.linear_k(k).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        q = self.linear_q(q).view(\n","            n_batches,\n","            -1,\n","            self.opts.multiHead,\n","            self.opts.hiddenSizeHead\n","        ).transpose(1, 2)\n","\n","        atted = self.att(v, k, q, mask)\n","        atted = atted.transpose(1, 2).contiguous().view(\n","            n_batches,\n","            -1,\n","            self.opts.hiddenDim\n","        )\n","\n","        atted = self.linear_merge(atted)\n","\n","        return atted\n","\n","    def att(self, value, key, query, mask):\n","        d_k = query.size(-1)\n","\n","        scores = torch.matmul(\n","            query, key.transpose(-2, -1)\n","        ) / math.sqrt(d_k)\n","\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, -1e9)\n","\n","        att_map = F.softmax(scores, dim=-1)\n","        att_map = self.dropout(att_map)\n","\n","        return torch.matmul(att_map, value)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.856333Z","iopub.status.busy":"2024-02-13T17:26:06.855680Z","iopub.status.idle":"2024-02-13T17:26:06.869229Z","shell.execute_reply":"2024-02-13T17:26:06.868132Z","shell.execute_reply.started":"2024-02-13T17:26:06.856300Z"},"trusted":true},"outputs":[],"source":["class FFN(nn.Module):\n","    def __init__(self, opts):\n","        super(FFN, self).__init__()\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FeedForwardSize,\n","            out_size=opts.hiddenDim,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.871258Z","iopub.status.busy":"2024-02-13T17:26:06.870897Z","iopub.status.idle":"2024-02-13T17:26:06.880963Z","shell.execute_reply":"2024-02-13T17:26:06.879961Z","shell.execute_reply.started":"2024-02-13T17:26:06.871221Z"},"trusted":true},"outputs":[],"source":["class SA(nn.Module):\n","    def __init__(self, opts):\n","        super(SA, self).__init__()\n","        self.mhatt = MHAtt(opts)\n","        self.ffn = FFN(opts)\n","\n","        self.dropout1 = nn.Dropout(opts.dropout)\n","        self.norm1 = LayerNorm(opts.hiddenDim)\n","\n","        self.dropout2 = nn.Dropout(opts.dropout)\n","        self.norm2 = LayerNorm(opts.hiddenDim)\n","\n","    def forward(self, x, x_mask):\n","        x = self.norm1(x + self.dropout1(\n","            self.mhatt(x, x, x, x_mask)\n","        ))\n","\n","        x = self.norm2(x + self.dropout2(\n","            self.ffn(x)\n","        ))\n","\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.883403Z","iopub.status.busy":"2024-02-13T17:26:06.882548Z","iopub.status.idle":"2024-02-13T17:26:06.895873Z","shell.execute_reply":"2024-02-13T17:26:06.894877Z","shell.execute_reply.started":"2024-02-13T17:26:06.883365Z"},"trusted":true},"outputs":[],"source":["class AttFlat(nn.Module):\n","    def __init__(self, opts):\n","        super(AttFlat, self).__init__()\n","        self.opts = opts\n","\n","        self.mlp = MLP(\n","            in_size=opts.hiddenDim,\n","            mid_size=opts.FlatMLPSize,\n","            out_size=opts.FlatGlimpses,\n","            dropout_r=opts.dropout,\n","            use_relu=True\n","        )\n","        # FLAT_GLIMPSES = 1\n","        self.linear_merge = nn.Linear(\n","            opts.hiddenDim * opts.FlatGlimpses,\n","            opts.FlatOutSize\n","        )\n","\n","    def forward(self, x, x_mask):\n","        att = self.mlp(x)\n","        att = att.masked_fill(\n","            x_mask.squeeze(1).squeeze(1).unsqueeze(2),\n","            -1e9\n","        )\n","        att = F.softmax(att, dim=1)\n","\n","        att_list = []\n","        for i in range(self.opts.FlatGlimpses):\n","            att_list.append(\n","                torch.sum(att[:, :, i: i + 1] * x, dim=1)\n","            )\n","\n","        x_atted = torch.cat(att_list, dim=1)\n","        x_atted = self.linear_merge(x_atted)\n","\n","        return x_atted"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.898219Z","iopub.status.busy":"2024-02-13T17:26:06.897536Z","iopub.status.idle":"2024-02-13T17:26:06.911540Z","shell.execute_reply":"2024-02-13T17:26:06.910562Z","shell.execute_reply.started":"2024-02-13T17:26:06.898186Z"},"trusted":true},"outputs":[],"source":["class CaptionEncoder(nn.Module):\n","    def __init__(self, opts, textVocabSize):\n","        super(CaptionEncoder, self).__init__()\n","        self.embedding = nn.Embedding(textVocabSize, opts.embedDim)\n","        bidirectional = opts.bidirectional > 0\n","        self.lstmC = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","        if bidirectional:\n","            opts.hiddenDim *= 2\n","            opts.hiddenSizeHead *= 2\n","            opts.FlatOutSize *= 2\n","\n","        self.attCap = nn.ModuleList([SA(opts) for _ in range(opts.layers)])\n","        self.attFlatCap = AttFlat(opts)\n","        self.fc = nn.Linear(opts.hiddenDim, opts.hiddenDim)\n","\n","    def forward(self, cap, hist=None):\n","        capMask = self.make_mask(cap.unsqueeze(2))\n","        cap = self.embedding(cap)\n","        cap, (_, _) = self.lstmC(cap)\n","        capO = cap.detach().clone()\n","\n","        for attC in self.attCap:\n","            cap = attC(cap, capMask)\n","        # (batchSize, 512)\n","        cap = self.attFlatCap(cap, capMask)\n","        encOut = self.fc(cap)\n","        return encOut, capO\n","    \n","    # Masking\n","    def make_mask(self, feature):\n","        return (torch.sum(\n","            torch.abs(feature),\n","            dim=-1\n","        ) == 0).unsqueeze(1).unsqueeze(2)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.913509Z","iopub.status.busy":"2024-02-13T17:26:06.913175Z","iopub.status.idle":"2024-02-13T17:26:06.928039Z","shell.execute_reply":"2024-02-13T17:26:06.926933Z","shell.execute_reply.started":"2024-02-13T17:26:06.913467Z"},"trusted":true},"outputs":[],"source":["from itertools import chain # needed for preprocessing the output of the local decode function -> added by Sepi"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.930784Z","iopub.status.busy":"2024-02-13T17:26:06.929738Z","iopub.status.idle":"2024-02-13T17:26:06.952663Z","shell.execute_reply":"2024-02-13T17:26:06.951534Z","shell.execute_reply.started":"2024-02-13T17:26:06.930744Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, opts, progVocabSize, maxLen, startID=1, endID=2):\n","        super(Decoder, self).__init__()\n","        self.numLayers = opts.numLayers\n","        self.bidirectional = opts.bidirectional > 0\n","        self.maxLen = maxLen\n","        self.startID = startID\n","        self.endID = endID\n","\n","        self.embedding = nn.Embedding(progVocabSize, opts.embedDim)\n","        self.lstmProg = nn.LSTM(\n","            input_size=opts.embedDim,\n","            hidden_size=2*opts.hiddenDim if self.bidirectional else opts.hiddenDim,\n","            num_layers=opts.numLayers,\n","            batch_first=True,\n","            # bidirectional=self.bidirectional,\n","        )\n","        hiddenDim = opts.hiddenDim\n","        if self.bidirectional:\n","            hiddenDim *= 2\n","\n","        self.fcAtt = nn.Linear(2*hiddenDim, hiddenDim)\n","        self.fcOut = nn.Linear(hiddenDim, progVocabSize)\n","\n","    def initPrgHidden(self, encOut):\n","        hidden = [encOut for _ in range(self.numLayers)]\n","        hidden = torch.stack(hidden, 0).contiguous()\n","        return hidden, hidden\n","\n","    def forwardStep(self, prog, progH, questO):\n","        #**********************************************our error relates to this prog cause in our case it is not acting as tensor anymore.\n","        batchSize = prog.size(0)\n","        inputDim = questO.size(1)\n","        prog = self.embedding(prog)\n","        outProg, progH = self.lstmProg(prog, progH)\n","\n","        att = torch.bmm(outProg, questO.transpose(1, 2))\n","        att = F.softmax(att.view(-1, inputDim), 1).view(batchSize, -1, inputDim)\n","        context = torch.bmm(att, questO)\n","        # (batchSize, progLength, hiddenDim)\n","        out = F.tanh(self.fcAtt(torch.cat([outProg, context], dim=-1)))\n","\n","        # (batchSize, progLength, progVocabSize)\n","        out = self.fcOut(out)\n","        predSoftmax = F.log_softmax(out, 2)\n","        return predSoftmax, progH\n","\n","    def forward(self, prog, encOut, questO):\n","        progH = self.initPrgHidden(encOut)\n","        predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","\n","        return predSoftmax, progH\n","\n","    def sample(self, encOut, questO):\n","        batchSize = encOut.size(0)\n","        cudaFlag = encOut.is_cuda\n","        progH = self.initPrgHidden(encOut)\n","        # prog = progCopy[:, 0:3]\n","        prog = torch.LongTensor(batchSize, 1).fill_(self.startID)\n","        # prog = torch.cat((progStart, progEnd), -1)\n","        if cudaFlag:\n","            prog = prog.cuda()\n","        outputLogProbs = []\n","        outputTokens = []\n","     \n","\n","        def decode(i, output):\n","            tokens = output.topk(1, dim=-1)[1].view(batchSize, -1)\n","            return tokens\n","\n","        for i in range(self.maxLen):\n","            predSoftmax, progH = self.forwardStep(prog, progH, questO)\n","            prog = decode(i, predSoftmax)\n","            prog_flat = list(chain(*prog))\n","            flat_list = [item.item() for item in prog_flat]\n","            outputTokens.append(flat_list)#new\n","        return outputTokens, outputLogProbs\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.954401Z","iopub.status.busy":"2024-02-13T17:26:06.954070Z","iopub.status.idle":"2024-02-13T17:26:06.969239Z","shell.execute_reply":"2024-02-13T17:26:06.968046Z","shell.execute_reply.started":"2024-02-13T17:26:06.954375Z"},"trusted":true},"outputs":[],"source":["class SeqToSeqC(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(SeqToSeqC, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, cap, prog):\n","        encOut, capO = self.encoder(cap)\n","        predSoftmax, progHC = self.decoder(prog, encOut, capO)\n","        return predSoftmax, progHC\n","   \n","    def sample(self, cap):\n","        with torch.no_grad():\n","            encOut, capO = self.encoder(cap)\n","        outputTokens, outputLogProbs = self.decoder.sample(encOut, capO)\n","\n","        outputTokens_t = [[row[i] for row in outputTokens] for i in range(len(outputTokens[0]))]\n","        #return outputTokens\n","        return outputTokens_t"]},{"cell_type":"markdown","metadata":{},"source":["## **optim.py**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.971221Z","iopub.status.busy":"2024-02-13T17:26:06.970855Z","iopub.status.idle":"2024-02-13T17:26:06.983572Z","shell.execute_reply":"2024-02-13T17:26:06.982353Z","shell.execute_reply.started":"2024-02-13T17:26:06.971195Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.optim as Optim"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:06.985050Z","iopub.status.busy":"2024-02-13T17:26:06.984678Z","iopub.status.idle":"2024-02-13T17:26:07.003191Z","shell.execute_reply":"2024-02-13T17:26:07.002396Z","shell.execute_reply.started":"2024-02-13T17:26:06.985011Z"},"trusted":true},"outputs":[],"source":["class WarmupOptimizer(object):\n","    def __init__(self, lr_base, optimizer, data_size, batch_size):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.lr_base = lr_base\n","        self._rate = 0\n","        self.data_size = data_size\n","        self.batch_size = batch_size\n","\n","    def step(self):\n","        self._step += 1\n","\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","\n","        self.optimizer.step()\n","\n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","\n","    def rate(self, step=None):\n","        if step is None:\n","            step = self._step\n","\n","        if step <= int(self.data_size / self.batch_size * 1):\n","            r = self.lr_base * 1/2.\n","        else:\n","            r = self.lr_base\n","\n","        return r\n","\n","\n","def get_optim(opts, model, data_size, lr_base=None):\n","    if lr_base is None:\n","        lr_base = opts.lr\n","\n","    if opts.optim == 'adam':\n","        optim = Optim.Adam(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                betas=opts.betas,\n","                eps=opts.eps,\n","\n","            )\n","    elif opts.optim == 'rmsprop':\n","        optim = Optim.RMSprop(\n","                filter(lambda p: p.requires_grad, model.parameters()),\n","                lr=0,\n","                eps=opts.eps,\n","                weight_decay=opts.weight_decay\n","            )\n","    else:\n","        raise ValueError('{} optimizer is not supported'.fromat(opts.optim))\n","    return WarmupOptimizer(\n","        lr_base,\n","        optim,\n","        data_size,\n","        opts.batch_size\n","    )\n","\n","def adjust_lr(optim, decay_r):\n","    optim.lr_base *= decay_r\n"]},{"cell_type":"markdown","metadata":{},"source":["## **option_caption_parser.py**"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:07.006678Z","iopub.status.busy":"2024-02-13T17:26:07.005249Z","iopub.status.idle":"2024-02-13T17:26:07.024783Z","shell.execute_reply":"2024-02-13T17:26:07.023598Z","shell.execute_reply.started":"2024-02-13T17:26:07.006645Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import torch\n","#import utils_m"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:07.026834Z","iopub.status.busy":"2024-02-13T17:26:07.026482Z","iopub.status.idle":"2024-02-13T17:26:07.036079Z","shell.execute_reply":"2024-02-13T17:26:07.034938Z","shell.execute_reply.started":"2024-02-13T17:26:07.026802Z"},"trusted":true},"outputs":[],"source":["#TOTAL_ITER = 5000\n","TOTAL_ITER = 5000\n","VALID_EVE = 1000\n","#VALID_EVE = 1000"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:07.039784Z","iopub.status.busy":"2024-02-13T17:26:07.037768Z","iopub.status.idle":"2024-02-13T17:26:07.082283Z","shell.execute_reply":"2024-02-13T17:26:07.081316Z","shell.execute_reply.started":"2024-02-13T17:26:07.039747Z"},"trusted":true},"outputs":[],"source":["class Options_c():#changed optiopn class as Option_c to differentiate it with the one belong to question\n","    def __init__(self):\n","        self.parser = argparse.ArgumentParser()\n","        self.initialized = False\n","\n","    def initialize(self):\n","        self.parser.add_argument(\n","            '--mode',\n","            default=\"train\",\n","            # required=True,\n","            type=str,\n","            choices=['train', 'test'],\n","            help='The mode of the experiment')\n","\n","        self.parser.add_argument(\n","            '--run_dir',\n","            default=\"kaggle/working\",\n","            # required=True,\n","            type=str,\n","            help='The experiment directory')\n","\n","        self.parser.add_argument(\n","            '--load_checkpoint_path',\n","            default=None,\n","            type=str,\n","            help='The path the the pretrained CaptionNet')\n","\n","        self.parser.add_argument(\n","            '--res_path',\n","            default=\"kaggle/working/res.txt\",#***\n","            # required=True,\n","            type=str,\n","            help='Path where to log the predicted caption programs')\n","\n","        self.parser.add_argument(\n","            '--gpu_ids',\n","            default='0',\n","            type=str,\n","            help='Id of the gpu to be used')\n","\n","        self.parser.add_argument(\n","            '--seed',\n","            default=42,\n","            type=int,\n","            help='The seed used in training')\n","\n","        self.parser.add_argument(\n","            '--dataPathTr',\n","            # required=True,\n","            default = '/kaggle/input/Small_Tr_Val_Test_Final/cap_tr_half.h5',\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed training data')\n","\n","        self.parser.add_argument(\n","            '--dataPathVal',\n","            default = '/kaggle/input/Small_Tr_Val_Test_Final/cap_val_half.h5',\n","            # required=True,\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed validation data')\n","\n","        self.parser.add_argument(\n","            '--dataPathTest',\n","            # required=True,\n","            default ='/kaggle/input/Small_Tr_Val_Test_Final/cap_test_75000.h5',\n","            type=str,\n","            help='Path to the h5 file of the Clevr-Dialog preprocessed test data')\n","\n","        self.parser.add_argument(\n","            '--vocabPath',\n","            default = '/kaggle/input/caption/vocab_output_caption.json',\n","\n","            # required=True,\n","            type=str,\n","            help='Path to the generated vocabulary')\n","\n","        self.parser.add_argument(\n","            '--batch_size',\n","            default=64,\n","            type=int,\n","            help='Batch size')\n","\n","        self.parser.add_argument(\n","            '--num_workers',\n","            default=0,\n","            type=int,\n","            help='Number of workers for loading')\n","\n","        self.parser.add_argument(\n","            '--num_iters',\n","            #default=5000,\n","            default=TOTAL_ITER,\n","            type=int,\n","            help='Total number of iterations')\n","\n","        self.parser.add_argument(\n","            '--display_every',\n","            default=5,\n","            type=int,\n","            help='Display training information every N iterations')\n","\n","        self.parser.add_argument(\n","            '--debug_every',\n","            default=100,\n","            type=int,\n","            help='Display debug message every N iterations')\n","\n","        self.parser.add_argument(\n","            '--validate_every',\n","            default=VALID_EVE,\n","            type=int,\n","            help='Validate every N iterations')\n","\n","        self.parser.add_argument(\n","            '--shuffle_data',\n","            default=1,\n","            type=int,\n","            help='Activate to shuffle the training data')\n","\n","        self.parser.add_argument(\n","            '--optim',\n","            default='adam',\n","            type=str,\n","            help='The name of the optimizer to be used')\n","\n","        self.parser.add_argument(\n","            '--lr',\n","            default=1e-3,\n","            type=float,\n","            help='Base learning rate')\n","\n","        self.parser.add_argument(\n","            '--betas',\n","            default='0.9, 0.98',\n","            type=str,\n","            help='Adam optimizer\\'s betas')\n","\n","        self.parser.add_argument(\n","            '--eps',\n","            default='1e-9',\n","            type=float,\n","            help='Adam optimizer\\'s epsilon')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_marks',\n","            default='50000, 55000',\n","            type=str,\n","            help='Learing rate decay marks')\n","\n","        self.parser.add_argument(\n","            '--lr_decay_factor',\n","            default=0.5,\n","            type=float,\n","            help='Learning rate decay factor')\n","\n","        self.parser.add_argument(\n","            '--weight_decay',\n","            default=1e-6,\n","            type=float,\n","            help='Weight decay')\n","\n","        self.parser.add_argument(\n","            '--embedDim',\n","            default=300,\n","            type=int,\n","            help='Embedding dimension')\n","\n","        self.parser.add_argument(\n","            '--hiddenDim',\n","            default=512,\n","            type=int,\n","            help='LSTM hidden dimension')\n","\n","        self.parser.add_argument(\n","            '--numLayers',\n","            default=2,\n","            type=int,\n","            help='Number of hidden LSTM layers')\n","\n","        self.parser.add_argument(\n","            '--dropout',\n","            default=0.1,\n","            type=float,\n","            help='Dropout value')\n","\n","        self.parser.add_argument(\n","            '--multiHead',\n","            default=8,\n","            type=int,\n","            help='Number of attention heads')\n","\n","        self.parser.add_argument(\n","            '--hiddenSizeHead',\n","            default=64,\n","            type=int,\n","            help='Dimension of each attention head')\n","\n","        self.parser.add_argument(\n","            '--FeedForwardSize',\n","            default=2048,\n","            type=int,\n","            help='Dimension of the feed forward layer')\n","\n","        self.parser.add_argument(\n","            '--FlatMLPSize',\n","            default=512,\n","            type=int,\n","            help='MLP flatten size')\n","\n","        self.parser.add_argument(\n","            '--FlatGlimpses',\n","            default=1,\n","            type=int,\n","            help='Number of flatten glimpses')\n","\n","        self.parser.add_argument(\n","            '--FlatOutSize',\n","            default=512,\n","            type=int,\n","            help='Final attention reduction dimension')\n","\n","        self.parser.add_argument(\n","            '--layers',\n","            default=6,\n","            type=int,\n","            help='Number of self attention layers')\n","\n","        self.parser.add_argument(\n","            '--bidirectional',\n","            default=1,\n","            type=int,\n","            help='Activate to use bidirectional LSTMs')\n","\n","        self.initialized = True\n","\n","    def parse(self):\n","        # initialize parser\n","        if not self.initialized:\n","            self.initialize()\n","       # self.opts = self.parser.parse_args()\n","        self.opts, unknown = self.parser.parse_known_args()#this is added by me to fix the error of command line arguments.\n","\n","        # parse gpu id list\n","        str_gpu_ids = self.opts.gpu_ids.split(',')\n","        self.opts.gpu_ids = []\n","        for str_id in str_gpu_ids:\n","            if str_id.isdigit() and int(str_id) >= 0:\n","                self.opts.gpu_ids.append(int(str_id))\n","        if len(self.opts.gpu_ids) > 0 and torch.cuda.is_available():\n","            print('\\n[INFO] Using {} CUDA device(s) ...'.format(len(self.opts.gpu_ids)))\n","        else:\n","            print('\\n[INFO] Using cpu ...')\n","            self.opts.gpu_ids = []\n","\n","        # parse the optimizer's betas and lr decay marks\n","        self.opts.betas = [float(beta) for beta in self.opts.betas.split(',')]\n","        lr_decay_marks = [int(m) for m in self.opts.lr_decay_marks.split(',')]\n","        for i in range(1, len(lr_decay_marks)):\n","            assert lr_decay_marks[i] > lr_decay_marks[i-1]\n","        self.opts.lr_decay_marks = lr_decay_marks\n","\n","        # print and save options\n","        args = vars(self.opts)\n","        print('\\n ' + 30*'-' + 'Opts' + 30*'-')\n","        for k, v in args.items():\n","            print('%s: %s' % (str(k), str(v)))\n","\n","        if not os.path.isdir(self.opts.run_dir):\n","            os.makedirs(self.opts.run_dir)\n","        filename = 'opts_c.txt'\n","        file_path = os.path.join(self.opts.run_dir, filename)\n","        with open(file_path, 'wt') as fout:\n","            fout.write('| options\\n')\n","            for k, v in sorted(args.items()):\n","                fout.write('%s: %s\\n' % (str(k), str(v)))\n","        return self.opts\n"]},{"cell_type":"markdown","metadata":{},"source":["## **train_caption_parser.py**"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:07.084163Z","iopub.status.busy":"2024-02-13T17:26:07.083539Z","iopub.status.idle":"2024-02-13T17:26:13.534746Z","shell.execute_reply":"2024-02-13T17:26:13.533638Z","shell.execute_reply.started":"2024-02-13T17:26:07.084135Z"},"trusted":true},"outputs":[],"source":["#from clevrDialog_dataset import ClevrDialogCaptionDataset\n","#from models import SeqToSeqC, CaptionEncoder, Decoder\n","#from optim import get_optim, adjust_lr\n","#from options_caption_parser import Options\n","import os, json, torch, pickle, copy, time\n","import numpy as np\n","import torch.nn as nn\n","import torch.utils.data as Data\n","from tensorboardX import SummaryWriter"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:13.537015Z","iopub.status.busy":"2024-02-13T17:26:13.536407Z","iopub.status.idle":"2024-02-13T17:26:13.582030Z","shell.execute_reply":"2024-02-13T17:26:13.580948Z","shell.execute_reply.started":"2024-02-13T17:26:13.536981Z"},"trusted":true},"outputs":[],"source":["import sys\n","class Execution:\n","    def __init__(self, opts):\n","        self.opts = opts\n","\n","        self.loss_fn = torch.nn.NLLLoss().cuda()\n","        print(\"[INFO] Loading dataset ...\")\n","\n","        self.dataset_tr = ClevrDialogCaptionDataset(\n","            opts.dataPathTr, opts.vocabPath, \"train\", \"Captions Tr\")\n","\n","        self.dataset_val = ClevrDialogCaptionDataset(\n","            opts.dataPathVal, opts.vocabPath, \"val\", \"Captions Val\")\n","\n","        self.dataset_test = ClevrDialogCaptionDataset(\n","           opts.dataPathTest, opts.vocabPath, \"test\", \"Captions Test\")\n","\n","        tb_path = os.path.join(opts.run_dir, \"tb_logdir\")\n","        if not os.path.isdir(tb_path):\n","            os.makedirs(tb_path)\n","\n","        self.ckpt_path = os.path.join(opts.run_dir, \"ckpt_dir\")\n","        if not os.path.isdir(self.ckpt_path):\n","            os.makedirs(self.ckpt_path)\n","\n","        self.writer = SummaryWriter(tb_path)\n","        self.iter_val = 0\n","        self.bestValAcc = float(\"-inf\")\n","        self.bestValIter = -1\n","\n","    def constructNet(self, lenVocabText, lenVocabProg, maxLenProg, ):\n","        decoder = Decoder(self.opts, lenVocabProg, maxLenProg)\n","        encoder = CaptionEncoder(self.opts, lenVocabText)\n","        net = SeqToSeqC(encoder, decoder)\n","        return net\n","\n","    def train(self, dataset, dataset_val=None):\n","        # Obtain needed information\n","        lenVocabText = dataset.lenVocabText\n","        lenVocabProg = dataset.lenVocabProg\n","        maxLenProg = dataset.maxLenProg\n","        net = self.constructNet(lenVocabText, lenVocabProg, maxLenProg)\n","\n","        net.cuda()\n","        net.train()\n","\n","        # Define the multi-gpu training if needed\n","        if len(self.opts.gpu_ids) > 1:\n","            net = nn.DataParallel(net, device_ids=self.opts.gpu_ids)\n","\n","        # Load checkpoint if resume training\n","        if self.opts.load_checkpoint_path is not None:\n","            print(\"[INFO] Resume trainig from ckpt {} ...\".format(\n","                self.opts.load_checkpoint_path\n","            ))\n","\n","            # Load the network parameters\n","            ckpt = torch.load(self.opts.load_checkpoint_path)\n","            print(\"[INFO] Checkpoint successfully loaded ...\")\n","            net.load_state_dict(ckpt['state_dict'])\n","\n","            # Load the optimizer paramters\n","            optim = get_optim(self.opts, net, len(dataset), lr_base=ckpt['lr_base'])\n","            optim.optimizer.load_state_dict(ckpt['optimizer'])\n","\n","        else:\n","            optim = get_optim(self.opts, net, len(dataset))\n","        _iter = 0\n","        epoch = 0\n","\n","        # Define dataloader\n","        dataloader = Data.DataLoader(\n","            dataset,\n","            batch_size=self.opts.batch_size,\n","            shuffle=self.opts.shuffle_data,\n","            num_workers=self.opts.num_workers,\n","        )\n","        _iterCur = 0\n","        _totalCur = len(dataloader)\n","        # Training loop\n","        while _iter < self.opts.num_iters:\n","            # Learning Rate Decay\n","            if _iter in self.opts.lr_decay_marks:\n","                adjust_lr(optim, self.opts.lr_decay_factor)\n","\n","            time_start = time.time()\n","            # Iteration\n","            for caption, captionPrg in dataloader:\n","                if _iter >= self.opts.num_iters:\n","                    break\n","                caption = caption.cuda()\n","                captionPrg = captionPrg.cuda()\n","                captionPrgTarget = captionPrg.clone()\n","                optim.zero_grad()\n","\n","                predSoftmax, _ = net(caption, captionPrg)\n","\n","                loss = self.loss_fn(\n","                    predSoftmax[:, :-1, :].contiguous().view(-1, predSoftmax.size(2)),\n","                    captionPrgTarget[:, 1:].contiguous().view(-1))\n","                loss.backward()\n","\n","                # logging\n","                self.writer.add_scalar(\n","                    'train/loss',\n","                    loss.cpu().data.numpy(),\n","                    global_step=_iter)\n","\n","                self.writer.add_scalar(\n","                    'train/lr',\n","                    optim._rate,\n","                    global_step=_iter)\n","                if _iter % self.opts.display_every == 0:\n","                    print(\"\\r[CLEVR-Dialog - %s (%d/%4d)][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" % (\n","                            dataset.name,\n","                            _iterCur,\n","                            _totalCur,\n","                            epoch,\n","                            _iter,\n","                            self.opts.num_iters,\n","                            loss.cpu().data.numpy(),\n","                            optim._rate,\n","                        ), end='          ')\n","                optim.step()\n","                _iter += 1\n","                _iterCur += 1\n","\n","                if _iter % self.opts.validate_every == 0:\n","                    if dataset_val is not None:\n","                        valAcc = self.eval(\n","                            net,\n","                            dataset_val,\n","                            valid=True,\n","                        )\n","                        if valAcc > self.bestValAcc:\n","                            self.bestValAcc = valAcc\n","                            self.bestValIter = _iter\n","\n","                            print(\"[INFO] Checkpointing model @ iter {}\".format(_iter))\n","                            state = {\n","                                'state_dict': net.state_dict(),\n","                                'optimizer': optim.optimizer.state_dict(),\n","                                'lr_base': optim.lr_base,\n","                                'optim': optim.lr_base,\n","                                'last_iter': _iter,\n","                                'last_epoch': epoch,\n","                            }\n","                            # checkpointing\n","                            torch.save(\n","                                state,\n","                                os.path.join(self.ckpt_path, 'ckpt_iter' + str(_iter) + '.pkl')\n","                            )\n","                    else:\n","                        print(\"[INFO] No validation dataset available\")\n","\n","            time_end = time.time()\n","            print('Finished epoch in {}s'.format(int(time_end-time_start)))\n","            epoch += 1\n","\n","        print(\"[INFO] Training done. Best model had val acc. {} @ iter {}...\".format(self.bestValAcc, self.bestValIter))\n","\n","    # Evaluation\n","    def eval(self, net, dataset, valid=False):\n","        net = net.eval()\n","        data_size = len(dataset)\n","        dataloader = Data.DataLoader(\n","            dataset,\n","            batch_size=self.opts.batch_size,\n","            shuffle=False,\n","            num_workers=self.opts.num_workers,\n","            pin_memory=False\n","        )\n","        allPredictedProgs = []\n","        numAllProg = 0\n","        falsePred = 0\n","        for step, (caption, captionPrg) in enumerate(dataloader):\n","            print(\"\\rEvaluation: [step %4d/%4d]\" % (\n","                step,\n","                int(data_size / self.opts.batch_size),\n","            ), end='          ')\n","            sys.stdout.flush()#my shit***************************\n","            caption = caption.cuda()\n","            captionPrg = captionPrg.cuda()\n","          \n","            tokens = net.sample(caption)\n","            targetProgs = decodeProg(captionPrg, dataset.vocab[\"idx_prog_to_token\"], target=True)\n","            predProgs = decodeProg(tokens, dataset.vocab[\"idx_prog_to_token\"])\n","            predProgs = [sublist for sublist in predProgs if sublist]\n","            allPredictedProgs.extend(list(map(lambda s: \"( {} ( {} ) ) \\n\".format(s[0], \", \".join(s[1:])), predProgs)))\n","                              \n","                                \n","            numAllProg += len(targetProgs)\n","            for targetProg, predProg in zip(targetProgs, predProgs):\n","                mainMod = targetProg[0] == predProg[0]\n","                sameLength = len(targetProg) == len(predProg)\n","                sameArgs = False\n","                if sameLength:\n","                    sameArgs = True\n","                    for argTarget in targetProg[1:]:\n","                        if argTarget not in predProg[1:]:\n","                            sameArgs = False\n","                            break\n","\n","                if not (mainMod and sameArgs):\n","                    falsePred += 1\n","        val_acc = (1 - (falsePred / numAllProg)) * 100.0\n","        print(\"Acc: {}\".format(val_acc))\n","        net = net.train()\n","        if not valid:\n","            with open(self.opts.res_path, \"w\") as f:\n","                f.writelines(allPredictedProgs)\n","            print(\"[INFO] Predicted caption programs logged into {}\".format(self.opts.res_path))\n","        return val_acc\n","\n","    def run(self, run_mode):\n","        self.set_seed(self.opts.seed)\n","        if run_mode == 'train':\n","            self.train(self.dataset_tr, self.dataset_val)\n","\n","        elif run_mode == 'test':\n","            lenVocabText = self.dataset_test.lenVocabText\n","            lenVocabProg = self.dataset_test.lenVocabProg\n","            maxLenProg = self.dataset_test.maxLenProg\n","            net = self.constructNet(lenVocabText, lenVocabProg, maxLenProg)\n","\n","            print('Loading ckpt {}'.format(self.opts.load_checkpoint_path))\n","            state_dict = torch.load(self.opts.load_checkpoint_path)['state_dict']\n","            net.load_state_dict(state_dict)\n","            net.cuda()\n","            self.eval(net, self.dataset_test)\n","\n","        else:\n","            exit(-1)\n","\n","    def set_seed(self, seed):\n","        \"\"\"Sets the seed for reproducibility.\n","        Args:\n","            seed (int): The seed used\n","        \"\"\"\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        np.random.seed(seed)\n","        print('[INFO] Seed set to {}...'.format(seed))\n","\n","\n","def decodeProg(tokens, prgIdxToToken, target=False):\n","    \n","    if (target == True):\n","        tokensBatch = tokens.tolist()\n","    else:\n","        tokensBatch = tokens\n","    #print(\"want to see what happens to tokens in decodeProg\", tokensBatch)\n","    progsBatch = []\n","    for tokens in tokensBatch:\n","        #print(\"tokens inside the first for loop in decodeProg\", tokens)\n","        prog = []\n","        for tok in tokens:\n","            if tok == 2:  # <END> has index 2\n","                break\n","            \n","            prog.append(prgIdxToToken.get(tok))\n","          \n","           \n","        if target:\n","            #print(\"tuye if\")\n","            prog = prog[1:]\n","        progsBatch.append(prog)\n","    return progsBatch\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-12-26T15:48:45.283904Z","iopub.status.busy":"2023-12-26T15:48:45.283515Z","iopub.status.idle":"2023-12-26T15:48:45.292927Z","shell.execute_reply":"2023-12-26T15:48:45.291671Z","shell.execute_reply.started":"2023-12-26T15:48:45.283874Z"}},"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:13.588631Z","iopub.status.busy":"2024-02-13T17:26:13.587917Z","iopub.status.idle":"2024-02-13T17:26:13.651040Z","shell.execute_reply":"2024-02-13T17:26:13.649963Z","shell.execute_reply.started":"2024-02-13T17:26:13.588594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[INFO] Using 1 CUDA device(s) ...\n","\n"," ------------------------------Opts------------------------------\n","mode: train\n","run_dir: kaggle/working\n","load_checkpoint_path: None\n","res_path: kaggle/working/res.txt\n","gpu_ids: [0]\n","seed: 42\n","dataPathTr: /kaggle/input/Small_Tr_Val_Test_Final/cap_tr_half.h5\n","dataPathVal: /kaggle/input/Small_Tr_Val_Test_Final/cap_val_half.h5\n","dataPathTest: /kaggle/input/Small_Tr_Val_Test_Final/cap_test_75000.h5\n","vocabPath: /kaggle/input/caption/vocab_output_caption.json\n","batch_size: 64\n","num_workers: 0\n","num_iters: 5000\n","display_every: 5\n","debug_every: 100\n","validate_every: 1000\n","shuffle_data: 1\n","optim: adam\n","lr: 0.001\n","betas: [0.9, 0.98]\n","eps: 1e-09\n","lr_decay_marks: [50000, 55000]\n","lr_decay_factor: 0.5\n","weight_decay: 1e-06\n","embedDim: 300\n","hiddenDim: 512\n","numLayers: 2\n","dropout: 0.1\n","multiHead: 8\n","hiddenSizeHead: 64\n","FeedForwardSize: 2048\n","FlatMLPSize: 512\n","FlatGlimpses: 1\n","FlatOutSize: 512\n","layers: 6\n","bidirectional: 1\n"]}],"source":["##### #__name__ == \"__main__\":\n","opts = Options_c().parse()\n","\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:13.652642Z","iopub.status.busy":"2024-02-13T17:26:13.652283Z","iopub.status.idle":"2024-02-13T17:26:13.987182Z","shell.execute_reply":"2024-02-13T17:26:13.985945Z","shell.execute_reply.started":"2024-02-13T17:26:13.652606Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Loading dataset ...\n"]}],"source":["exe = Execution(opts)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:26:13.988695Z","iopub.status.busy":"2024-02-13T17:26:13.988403Z","iopub.status.idle":"2024-02-13T17:50:55.027291Z","shell.execute_reply":"2024-02-13T17:50:55.026136Z","shell.execute_reply.started":"2024-02-13T17:26:13.988670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Seed set to 42...\n","Evaluation: [step    1/   1]          ][epoch  0][iter  995/5000] loss: 0.5769, lr: 5.00e-04          Acc: 75.0\n","[INFO] Checkpointing model @ iter 1000\n","Evaluation: [step    1/   1]          )][epoch  0][iter 1995/5000] loss: 0.5720, lr: 5.00e-04          Acc: 75.80645161290323\n","[INFO] Checkpointing model @ iter 2000\n","[CLEVR-Dialog - Captions Tr (2730/2733)][epoch  0][iter 2730/5000] loss: 0.5663, lr: 5.00e-04          Finished epoch in 805s\n","Evaluation: [step    1/   1]          )][epoch  1][iter 2995/5000] loss: 0.5704, lr: 1.00e-03          Acc: 72.58064516129032\n","Evaluation: [step    1/   1]          )][epoch  1][iter 3995/5000] loss: 0.5614, lr: 1.00e-03          Acc: 75.0\n","Evaluation: [step    1/   1]          )][epoch  1][iter 4995/5000] loss: 0.5499, lr: 1.00e-03          Acc: 75.80645161290323\n","Finished epoch in 671s\n","[INFO] Training done. Best model had val acc. 75.80645161290323 @ iter 2000...\n"]}],"source":["exe.run(opts.mode)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-13T17:50:55.029371Z","iopub.status.busy":"2024-02-13T17:50:55.028815Z","iopub.status.idle":"2024-02-13T17:50:55.035083Z","shell.execute_reply":"2024-02-13T17:50:55.034095Z","shell.execute_reply.started":"2024-02-13T17:50:55.029342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Done ...\n"]}],"source":["print(\"[INFO] Done ...\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4223935,"sourceId":7618624,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
